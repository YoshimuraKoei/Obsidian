---
title:
AI: "false"
published:
created: " 2025-11-02"
description:
tags:
  - permanent-note
  - knowledge
  - sgd
---

# Chapter 3

## 3.1 確率的勾配降下法 (SGD)

### 3.1.1 勾配降下法の基礎

訓練データ $\mathcal{D}$ に対して計算される損失関数 $E(\mathbf{w})$ を $\mathbf{w}$ について最小化することが順伝播型ネットワークの学習である。
可能ながば大域的最小点 $\mathbf{w} = \arg \min_\mathbf{w} E(\mathbf{w})$ を求めたいところだが、これの複雑さからそれは一般的に不可能で、局所的な極小点 $\mathbf{w}$ を得ることしかできない。
それでもその極小点での損失の値がある程度小さければ、目的とする推論を上手く実行できる可能性がある。

非線形関数の最小化のための方法は多くあるが、ニューラルネットワークの学習では **勾配降下法 (gradient descent method)**  を用いる。
**勾配 (gradient)** は損失関数の1次微分であり、
$$
	\nabla E \equiv \frac{\partial E}{\partial \mathbf{w}} = [\frac{\partial E}{\partial w_1}m, \cdots, \frac{\partial E}{\partial w_M}]^\top
$$

というベクトルになる。 $\mathbf{w}$ の更新については、
$$
	\mathbf{w}_{t+1} = \mathbf{w} - \epsilon \nabla E
$$
である。ここで、 $\epsilon$ は $\mathbf{w}$ の更新量の大きさを定める定数で、**学習率 (learning rate)** と呼ばれる。


> [!NOTE] 学習率
> - 小さすぎると
> 	- 極小点に至る反復回数が増える
> - 大きすぎると
> 	- $E(\mathbf{w})$ の形状によって値が増大してしまうことがある
> 
> → 学習率 $\epsilon$ をどう選ぶかはかなり重要で、学習の成否を左右する。


### 3.1.2 バッチ学習から SGD へ

訓練データ $\mathcal{D}$ のすべてのサンプルに対する損失関数 $E(\mathbf{w})$ を考えた。
$$
	E(\mathbf{w}) = \sum_{n=1}^N E_n(\mathbf{w})
$$
この $E(\mathbf{w})$ の勾配を用いて $\mathbf{w}$ を更新する手法を **バッチ学習** と呼ぶ。


> [!NOTE] バッチ学習
> すべてのデータを一度に使ってモデルを更新する方法で、学習時に「データ全部が手元にある」前提。
> - 特徴
> 	- 精度が安定している
> 	- だが計算コストが重い
> 	- 大量データだと一回の更新に時間がかかる

これに対し、サンプル1つの損失 $E_n$ を使ってパラメータを更新する方法を **確率的勾配降下法 (stochastic gradient descent)** と呼ぶ。
1つのサンプル $n$ について計算される損失 $E_n(\mathbf{w})$ の勾配 $\nabla E_n$ を計算し、
$$
	\mathbf{w}_{t+1} = \mathbf{w} - \epsilon \nabla E_n
$$
のように $\mathbf{w}$ を更新していく。


> [!NOTE] 確率的勾配降下法
> 利点
> - 反復計算が望まない局所的な極小解にトラップされてしまうリスクを低減できる
> 	- $\mathbf{w}$ の更新のたびに異なる目的関数 $E_n(\mathbf{w})$ を考える
> 	- **局所解に陥ってしまっても確率的なノイズで抜けれる可能性がある**
> 
> → 反復のたびにランダムにサンプルを選ぶことで、この効果を最大化できると考えられており、「確率的」という表現はここに由来。


### 3.1.3 ミニバッチの利用


> [!NOTE] ミニバッチ学習
> バッチサイズのサンプルで損失を計算し、重みを1回更新する。そして、他のミニバッチで損失を計算し、重みを再び更新。
> 1エポックの場合、$\text{更新回数} = \text{バッチ数}$
> Eエポックの場合、$\text{更新回数} = \text{バッチ数} × E$
> 


ニューラルネットワークの学習には大きな計算コストがかかり、効率化には並列計算資源の利用が不可欠。
**サンプル1つごとに重みの更新を行うのでは計算の並列化が難しい** ので、一定数のサンプルの集合単位で重みを更新するのが現実的な選択になる。
このサンプルの集合のことを**ミニバッチ (minibatch)** と呼ぶ。

| 手法                          |更新単位|勾配の安定性|局所解からの脱出性|並列化(GPU適性)|メリット|デメリット|典型用途|
|---|---|---|---|---|---|---|---|
| **バッチ学習 (Full Batch)**      |全データ|**◎**（非常に滑らか）|**×**（揺らぎがなくハマりやすい）|**◎**（行列演算で最大効率）|・収束先が安定・理論解析しやすい|・計算が重い・大規模データで非現実的|小〜中規模データでの厳密最適化|
| **SGD (Stochastic, 1サンプル)** |1サンプル|**×**（非常にノイジー）|**◎**（揺らぎで抜けやすい）|**×**（並列化ほぼ不可）|・即時更新でオンライン学習に強い|・精度がブレやすい・GPUが全く生きない|ストリーム処理・リアルタイム学習|
| **SGD (Mini-Batch)**        |少数サンプル (例: 32〜1024)|**○**（ほどよく安定）|**○**（適度な揺らぎ）|**◎**（GPU最適）|・収束の安定性と探索性のバランス最良・実装が標準化されている|・バッチサイズの調整は必要|**ディープラーニングでの事実上の標準**|

### 3.1.4 モメンタム

SGD ではパラメータの更新ごとに異なる目的関数を考えるため、更新量がバラつく。
これを安定化し、収束性を改善するのが **モメンタム (momentum)** で、 **SGD ではほとんど常に採用される。**
モメンタムでは、重みの更新時、重みの修正量に前回の重みの修正量の何割かを加算する。

$\mathbf{v}_t \equiv \mathbf{w}_t - \mathbf{w}_{t-1}$ と書けば、ミニバッチ $\mathcal{D}_t$ に対する更新を
$$
	\mathbf{w_{t+1}} = \mathbf{w}_t - \epsilon \nabla E_t + \mu \mathbf{v}_t
$$
と定める。$\mu$ は加算の割合を制御するハイパーパラメータで、通常 $\mu = 0.5～0.9$ 程度の範囲から選ぶ。

損失関数が深い谷状の形状を持ち、かつその谷底にあまり高低差がないとき、勾配降下法は非常に効率が悪くなる。
→ 谷が深いので、谷底を少しでも外れた点では谷と直交する方向に大きな勾配が生じ、重みは毎度谷と直交する方向に修正されてしまう

モメンタムを使うと、谷の方向に沿って谷底を効率よく探索できるようになる

---
## 3.2 汎化性能と箇条適合

### 3.2.1 訓練誤差と汎化誤差

### 3.2.2 バイアス・分散トレードオフ


---
## 3.6 層出力の正規化

### 3.6.1 概要

### 3.6.2 入力の正規化

訓練データ $\mathcal{D} = \{ (x_n, y_n) \}_{n=1,...,N}$ の各 $\mathbf{x}_n$ に線形変換を施し、 $\mathbf{x}_n$ の成分ごとの平均や分散などを揃えることを、**データの正規化 (normalization)** あるいは **データの標準化 (standardization)** という。

$$
	\sigma_i \equiv \sqrt{\frac{1}{N} \sum_{n=1}^N (x_{n,i} - \bar{x}_i)^2}
$$
$$
	x_{n,i} \leftarrow \frac{x_{n,i} - \bar{x}_i}{\sqrt{\sigma_i^2 + \epsilon}}
$$

ここで、 $\epsilon$ はゼロ割を避けるための小さな数。

### 3.6.3 バッチ正規化

**バッチ正規化 (batch normalization)** は、各層の出力に対し、前項で説明した入力に対する正規化と同様の変換を適用する。
バッチ正規化では、ミニバッチ内の全サンプルに対する平均と分散を計算して用いる。
$$
	\hat{u}_j = \gamma_j \frac{u_j - \mu_j}{\sqrt{\sigma^2 + \epsilon}} + \beta_j
$$

初期値は、 $\beta_j = 0, \; \gamma_j = 1$ となる。


> [!NOTE] [バッチ正規化](https://note.com/kikaben/n/nf0dc9446dce3)
> - 問題点
> 	- パラメータ更新のたびに、同じ層に来る分布が毎回異なる → 内部共変量シフト。
> - 施策：
> 	- 目的：各層の出力を安定化させ、だが表現力も維持したい
> 	1. バッチ内の平均と標準偏差を計算
> 	2. それを使って標準化
> 	3. さらにスケールパラメータ $\gamma$ 、シフトパラメータ $\beta$ で再調整
> - $\gamma$ と $\beta$ 
> 	- これらは学習されるパラメータ
> - 「分布」について
> 	- **平均と分散によって分布は定義される (らしい)**
> 	- バッチ正規化では分布の形状までは揃えようとしていない
> - 各層同じ分布ではダメなの？
> 	- → 強い特徴も弱い特徴も、強制的に「平均0・分散1」に押しつぶされる
> 	- **特に、ReLu のメリットである「どの特徴を通し、どれを殺すか」の制御ができなくなる**


