---
title:
AI: "false"
published:
created: " 2025-11-07"
description:
tags:
  - permanent-note
  - knowledge
---

# Chapter 6

## 6.1 系列データ

系列データを扱う問題の例
1. 入力として1つの文が与えられ、それをいくつかのクラスに分類する問題
2. 発話を記録した時間信号からその発話内容を推定する **音声認識 (speech recognition)** である。
いずれの場合も、推定すべきものも系列データであり、その系列長は入力系列の長さとは異なることに注意する。

---
## 6.2 リカレントニューラルネットワーク

### 6.2.1 概要

**リカレントニューラルネットワーク (recurrent neural network)** とは、内部に（有向）閉路を持つニューラルネットワークの総称で、系列データを扱う。
- Elman ネットワーク
- Jordan ネットワーク
- 時間遅れネットワーク
- エコー状態ネットワーク
など様々なものがある。

ここでは、順伝播型ネットワークと同様の構造を持ち、ただし中間層のユニットの出力が自分自身に戻される「帰還路」を持つシンプルなものを考える。
→ この構造により、**情報を一時的に記憶し、また振る舞いを動的に変化させることが出来る。**

RNN は各時刻 $t$ につき1つの入力 $\mathbf{x}^t$ を受け取り、また同時に1つの出力 $\mathbf{y}^t$ を返す。つまり入力と同じ長さの系列を出力する。
**順伝播型ネットワークが入力1つに対し1つの出力を与える写像を表すのに対し、RNN は（少なくとも理論上）過去のすべての入力から1つの出力への写像を表す。**


### 6.2.2 順伝播の計算

系列 $\mathbf{x}^1, \mathbf{x}^2$ を RNN に順番に入力すると、対応する出力は系列 $\mathbf{y}^1, \mathbf{y}^2, \cdots$ を与える。

RNN の帰還路は、中間層の出力を自らの入力に戻すが、この間の結合は全ユニット間で存在する。
時刻 $t-1$ における中間層の任意のユニット $j'$ から時刻 $t$ における中間層の任意のユニット $j$ へ、重み $w_{jj'}$ の結合が存在する。
したがって、時刻 $t$ における中間層の各ユニットへの入力は、同時刻 $t$ にて入力層から届くものと、時刻 $t-1$ の中間層の出力をフィードバックしたものとの和
$$
	u_j^t = \sum_i w_{ji}^{(in)} x_i^t + \sum_{j'} w_{jj'} z_{j'}^{t-1}
$$
となる。中間層のバイアスは $w_{j0}^{(in)}$ ($x_0^t=1$ と固定) が与えられる (バイアスを使わないこともあるが)。
ここから中間層の出力は、活性化関数 $f$ を経由して、
$$
	z_j^t = f(u_j^t)
$$
と計算される。**RNN の活性化関数には伝統的に tanh が多く使われてきたが、ReLU も使う。**
以上をまとめると、
$$
	\mathbf{z}^t = \mathbf{f}(\mathbf{w}^{(in)} \mathbf{x}^t )
$$

