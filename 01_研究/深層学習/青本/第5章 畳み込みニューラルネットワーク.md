---
title:
AI: "false"
published:
created: " 2025-11-07"
description:
tags:
  - permanent-note
  - knowledge
---

# Chapter 5

## 5.1 単純型細胞と複雑型細胞

**畳み込みニューラルネットワーク (convolutional neural network)** は、画像分類など画像を入力とするさまざまな問題に適用可能な、順伝播型ネットワークのこと。
CNN は、畳み込みという基本的な画像処理の演算を実行する **畳み込み層 (convolution layer)** を持つことが特徴。

これまでの章で扱ったネットワークは、隣接層のユニットすべてが **全結合 (fully-connected)** されたものだった。
畳み込み層では、隣接層間の特定のユニットのみが結合を持つ。

![[PXL_20251106_152603810 1.jpg]]

**LeNet** ... CNN と同様の構造を持つネットワークを用いて、学習を誤差逆伝播法 + 勾配降下法で行うようにしたもの。
LeNet は現在の CNN の直接のルーツであり、当時、文字認識に応用されて高い認識性能を挙げることが示された。

**CNN は、画像と画像に類似した構造を持つデータを扱う問題に対して最もよく使われている。**

---
## 5.2 畳み込み


### 5.2.1 定義

画像サイズを $W \times H$ 画素とし、画素をインデックス $(i, j) (i = 0,\cdots,W-1, j = 0, \cdots, H-1)$ で表す。
画素 $(i, j)$ の画素値を $x_{ij}$ と書き、 $x_{ij}$ は負の値を含む実数値を取るとする。

**フィルタ (filter)** と呼ぶサイズの小さい画像を考え、そのサイズを $W_f \times H_f$ 画素とする。
フィルタの画素をインデックス $(p, q) (p=0,\cdots,W_f-1, q=0,\cdots,H_f-1)$ で表し、画素値を $h_{pq}$ とする。

画像の畳み込みとは、画像とフィルタ間で定義される次の積和計算
$$
	u_{ij} = \sum_{p=0}^{W_f-1} \sum_{q=0}^{H_f-1} x_{i+p, j+q} h_{pq}
$$
だがこの計算は相関と呼ぶべきで、正確には、**畳み込み (convolution)** は本来
$$
	u_{ij} = \sum_{p=0}^{W_f-1} \sum_{q=0}^{H_f-1} x_{i-p, j-q} h_{pq}
$$
という計算のこと。

### 5.2.2 畳み込みの働き

画像の畳み込みには、フィルタの濃淡パターンと類似したパターンが入力画像のどこにあるかを検出する働きがある。

### 5.2.3 パディング

畳み込みは、画像にフィルタを重ねた時、画像とフィルタの重なり合う画素どうしの積を求めて、それらの和を求める計算。

画像からフィルタがはみ出すような位置に重ねることはできないので、畳み込み結果のサイズ ($u_{ij}$ のインデックスの範囲)  は入力画像より小さくなり、
$$
	(W - 2 \lfloor W_f/2 \rfloor) \times (H - 2 \lfloor H_f/2 \rfloor)
$$
となる。ただし、 $\lfloor \cdot \rfloor$ は小数点以下を切り下げて整数化する演算子を表す。
ex. 8×8 に 3×3 のフィルタを通す → 6×6

畳み込み結果の画像が入力画像と同じサイズになるようにしたい場合は、入力画像の外側に横方向 $\lfloor W_f/2 \rfloor$ 、縦方向 $\lfloor H_f/2 \rfloor$ の縁をつけて大きくする。
この処理のことを **パディング (padding)** と呼ぶ。この縁の部分の画素値は未定なので、何らかの方法で決める必要がある。

最も一般的なのは、画素値を0にする方法で、 **ゼロパディング (zero-padding)** と呼ばれる。

### 5.2.4 ストライド

画像上のフィルタの適用位置を1画素ではなく、数画素ずつ縦横方向にズラして計算することもできる。このようなフィルタの適用位置の間隔を **ストライド (stride)** と呼ぶ。
ストライドを $s$ とするとき、出力画像の画素値は
$$
	u_{ij} = \sum_{p=0}^{W_f-1} \sum_{q=0}^{H_f-1} x_{si+p, sj+q} h_{pq}
$$
のように計算されて、出力画像サイズは約 $1/s$ 倍となる。


## 5.3 畳み込み層

一般的な埋め込み層では、3次元の配列に対し、同じく3次元の配列となるフィルタを複数、並行して畳み込む演算を行う。
そして、畳み込み層の出力も3次元の配列となる。

この3次元配列は、同じサイズ $(W \times H)$ の画像 $C$ 枚を層状に重ねたものと考えることが出来る。この層のことを **チャネル $(C=1,\cdots,C)$**  と呼ぶ。
内部の畳み込み層では、一般にもっと多くのチャネル数 $(C=16やC=256)$ などを持つ3次元配列を扱う。

![[PXL_20251107_064334528.jpg]]

$$
	u_{ijk} = \sum_{c=0}^{C-1} \sum_{p=0}^{W_f-1} \sum_{q=0}^{H_f-1} z_{i+p, j+q, c}^{(l-1)} h_{pqck} + b_k
$$

| 記号         | 形状                                                             | 内容            |
| ---------- | -------------------------------------------------------------- | ------------- |
| 入力         | $( X \in \mathbb{R}^{H \times W \times C} )$                   | 画像（縦×横×チャネル）  |
| フィルタ（カーネル） | $( W^{(k)} \in \mathbb{R}^{H_f \times W_f \times C})$          | 各出力チャネル用のフィルタ |
| 出力         | $( U \in \mathbb{R}^{H_{out} \times W_{out} \times C_{out}} )$ | 特徴マップ群        |
