---
title: 深層学習_第2章
AI: "false"
published:
created: " 2025-10-31"
description:
tags:
  - permanent-note
  - knowledge
---

# Chapter 2

## 2.1 ユニットと活性化関数

**ユニット** ... ニューラルネットワークを構成する最小の要素がユニット

ユニットは、複数の入力を受け取り、1つの入力を計算する。
例：
$$
	u = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + b
$$
各入力に異なる重みを掛けて加算したものにバイアスと呼ばれる値 $b$ を足す。

ユニットは、総入力 $u$ を**活性化関数 (activation function)** と呼ばれる関数 $f$ に入れて得られる値
$$
	z = f(u)
$$
を出力する。

複数のユニットを考え、入力とユニットの数を一般化し、 入力を $i = 1, \cdots, I$、ユニットを $j = 1, \cdots , J$ で表すｒと、各ユニット $j$ の出力は次のように計算される。

$$
	u_j = \sum_{i=1}^I w_{ji} x_i + b_j
	
$$


ユニットの総入力に適用される活性化関数にはさまざまな種類があり、目的に応じて使い分けられる。最も基本となるのが、**ReLU (rectifiled linear unit)** 。
$$
	f(u) = \max\{u, 0\}
$$


> [!NOTE] 典型的な活性化関数とその形
> このグラフ探した方が良いかも


