## Recsys2023

## Abstract

既存のCF手法はデータのノイズに弱く、推薦精度を低下させるという問題がある。この問題に対処するため、多くの先行研究では敵対的学習を用いて**ユーザー・アイテムの表現を正則化**し、汎化性能とロバスト性を向上させている。これらの手法はしばしばミニマックス最適化のフレームワークで摂動とモデルパラメータを同時に学習する。しかし、次の二つの大きな課題が残る。

  

1. なぜ摂動を加えることでモデルの汎化性能やロバスト性が向上するのかについての理論的保証が不足している点
2. ミニマックス最適化を解くのには計算コストがかかる点
3. モデルパラメータの更新に加えて、各イテレーションで摂動の更新にも追加計算が必要となるため、産業規模のデータセットにはスケールしにくい

  

この論文では、追加の計算コストをほとんど伴わずに敵対的学習を実現する、シンプルかつ効果的な手法「Sharpness-aware Collaborative Filtering(SharpCF)」を提案する。

まず既存の敵対的協調フィルタリング手法を見直し、最近提案されたSharpness-aware Minimizationとの関係を解析する。この解析により、**敵対的学習とは実質的に最適解周辺の損失が一様に低い領域（シャープネスの小さい領域）を探索することであり、それが汎化性能を高める**ことが分かる。

計算コスト削減のために、SharpCFでは「**トラジェクトリ損失**」と呼ばれる新しい損失項を導入し、現在のモデル重みと過去の重みとの整合性を測定する。実世界データセット上での実験結果から、SharpCFは敵対的学習と比較してほぼ追加コストゼロで優れた性能を達成することが示されている。

  

ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー

多くの先行研究では**敵対的学習を用いてユーザー・アイテムの表現を正則化**し、汎化性能とロバスト性を向上させている。

  

↑ どういうふうに？？想像つかぬ

  

ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー

## 1. Introduction

ほとんどのCF手法では、ユーザーとアイテムを共通の埋め込み空間にマッピングするエンコーダを学習し、さらにその埋め込みをよく表現できるよう目的関数を最適化して有益な表現を獲得します。CFベースの手法は、そのシンプルさと有効性から、**Factorization Machines [13, 22] やグラフニューラルネットワーク [14, 40]** といった形で産業界にも広く導入されています。

  

しかし、**多くの最先端CF手法はノイズの影響を受けやすく、わずかな摂動が加わるだけで性能が大きく劣化してしまうという課題があります** [4, 5, 29, 34]。実世界のデータにはしばしばノイズが含まれ、ユーザーの真の嗜好と実際のインタラクションが必ずしも一致するとは限りません。

  

この問題に対処するため、多くの先行研究では敵対的学習の原理を利用してユーザーおよびアイテムの表現を正則化する手法が提案されています [10, 15, 28, 38, 41]。これらの手法はミニマックス最適化の枠組みを採用し、敵対的な摂動とモデルパラメータを交互に学習します。たとえばAPRモデル [15] では、行列因子分解モデルに対し、ユーザーとアイテムの埋め込みベクトルに直接敵対的摂動を加える形で敵対的学習を適用しています。

  

既存の敵対的協調フィルタリング手法は有望な成果を示していますが、なお二つの大きな制約が残っています。

  

1. **敵対的摂動を加えることでモデルの汎化性能やロバスト性が向上する理由について、理論的な保証が不足している**こと。ノイズデータは本質的に元データに対して意図的に設計された敵対的摂動とは異なるため、その解釈性は未だ明確ではありません [12]。
2. **ミニマックス最適化を解くプロセスに膨大な計算コストがかかる**こと [37]。各イテレーションで、モデルパラメータを更新する「外側の最小化問題」に加えて、学習可能な摂動を更新する「内側の最大化問題」の計算が必要となるため、大規模データセットの学習には適しません。

  

このように、**より効率的で解釈可能な敵対的協調フィルタリング手法の開発**は、推薦システムの分野において依然として大きな課題となっています。

  

この研究では、上述した制約を克服するために、基本的なオプティマイザに対して追加の計算コストを伴わずに敵対的学習を可能にする、シンプルかつ効果的な手法**「Sharpness-aware Collaborative Filtering（SharpCF）」**を提案します。まず既存の敵対的協調フィルタリング手法を振り返り、近年提案されたSharpness-aware Minimization [2, 9, 11, 20] との関係を論じます。我々の解析により、**敵対的学習は最適モデルパラメータ周辺において損失が一様に低い近傍（フラットな極小点）を探索することを実質的に目指しており、これが汎化性能の向上につながる**ことが明らかになりました。

  

計算オーバーヘッドを削減するために、本手法SharpCFでは**「トラジェクトリ損失」**と呼ばれる新たな損失項を導入し、現在のモデル状態と過去のモデル状態との整合性を測定します。このトラジェクトリ損失は、**モデルがシャープな極小点へ収束するのを防ぎ、敵対的学習と同様にパラメータをフラットな領域へ導く性質を持つ**ことを示します。興味深いことに、min-max最適化を用いる既存の敵対的手法とは異なり、SharpCFは標準的な確率的勾配降下法（SGD）で訓練可能であり、計算時間を大幅に削減します。実世界データセット上での実験結果から、SharpCFは最先端の敵対的協調フィルタリング手法をほぼ追加コストなしに上回る性能を達成することが確認されました。

  

**本研究の貢献**

- 既存の敵対的協調フィルタリング手法を再検討し、最近提案された Sharpness-aware Minimization との関連性を明らかにしました。この解析により、**敵対的学習はシャープな極小点よりもフラットな極小点を好む傾向があり、それがモデルの汎化性能向上につながる**ことを示しました。
- 新たに「Sharpness-aware Collaborative Filtering（SharpCF）」を提案しました。本手法では、**現在のモデル状態と過去のモデル状態との整合性を測定する「トラジェクトリ損失」を導入することで、min-max 最適化を解く必要を排除し、追加の計算コストなしに敵対的学習を実現**します。
- 実験結果により、**SharpCF が既存の協調フィルタリング手法を上回る性能を発揮する**ことを示しました。具体的には、ベースラインである BPR に対して平均 18.1% の改善を、APR に対して平均 6.82% の改善を達成しました。また、計算時間の観点では、SharpCF は BPR と同程度の学習速度を維持し、APR の約 2 倍の高速性を実現しています。

  

ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー

>>> 本手法では、現在のモデル状態と過去のモデル状態との整合性を測定する「トラジェクトリ損失」を導入することで、min-max 最適化を解く必要を排除し、追加の計算コストなしに敵対的学習を実現します。

  

Min-Max最適化のやり方をまず知らないが、かなり面白い貢献なのでは？敵対的学習が、シャープな極小点よりもフラットな極小点を好む傾向があり、それがモデルの汎化性能向上につながるのはなんかイメージ付くな。何か一部ミスがあったとしても、精度があまり変わらないという意味で。

  

## 2. Related Work

### 2.1 Collaborative Filtering

深層ニューラルネットワークの成功を受けて、より強力なユーザー／アイテム表現を学習するニューラルCFモデルも提案されています。たとえば、Wide & Deep推薦モデル［7］は線形モデルと深層ニューラルネットワークを組み合わせ、記憶（memorization）と汎化（generalization）の両方を捉えます。Heら［16］は、ユーザー–アイテム相互作用のモデル化において内積をニューラルネットワークアーキテクチャに置き換えたニューラル協調フィルタリングモデルを提案しました。また、DeepFM［13］はファクタライゼーションマシンとニューラルネットワークを融合し、低次および高次の特徴相互作用を学習します。さらに、XDeepFM［22］は新たにクロスネットワークを導入してより複雑な特徴相互作用を捉え、xLightFM［17］は量子化技術によりファクタライゼーションマシンのメモリフットプリントを大幅に削減しています。

  

**行列因子分解に加え、グラフニューラルネットワークも近年注目を集めており、LightGCN［14］など多くのグラフベースCFモデルが提案されています。**これらのモデルは推薦タスクで大きな成功を収め、さまざまなドメインで活用されています［8, 19, 25, 32, 35, 39］。

  

しかしながら、ノイズの多いデータ（たとえば偽陽性フィードバック）は推薦性能に大きな影響を与えます。一般に、ノイズデータは人気アイテムへのバイアスを生み、正確かつ多様な推薦を難しくします［4, 29, 33, 34, 36］。この問題に対処するため、先行研究ではトレーニング時にマルチタイプのクリックやユーザーのテキストコメントなど、より多様なフィードバックを取り込む方法が検討されています。Wenら［36］はトレーニングシナリオとして「クリック完了」「クリックスキップ」「非クリック」の3種類を提案し、後者2つを負例として扱います。Julianら［24］はユーザーの潜在因子とテキストレビューを組み合わせて評価を補強しました。**しかし、追加フィードバックは多くの場面でコストがかかるか入手困難です。**そこで、**研究者らは追加情報を必要とせずにノイズフィードバックの悪影響を軽減する手段として、敵対的トレーニングの活用を試みています［3, 10, 15, 38, 41］。**

  

### 2.2 Adversarial Training

敵対的トレーニングは、推薦システムにおけるノイズデータの悪影響を緩和する有望な手法として注目されています［3, 6, 10, 15, 38, 41］。敵対的トレーニングでは、クリーンなデータと敵対的データを組み合わせてモデルを学習します。**敵対的データとは、入力データに対して最悪のケースを想定した摂動を加えて生成されるデータです［6, 12, 15］。**この手法により、モデルがこれらの摂動に対して頑健になるよう学習され、その結果、未知のデータに対する汎化能力が向上します。例えば、**APR［15］**では行列因子分解モデルにおいてユーザーおよびアイテムの埋め込みベクトルに摂動を加えることで、より頑健かつ高精度な推薦システムを実現しています。NMRN［31］はストリーミング推薦モデルに敵対的トレーニングを適用し、長期的な安定した興味と短期的な動的行動の両方を発見することを目指しています。ACAE［41］は協調オートエンコーダに敵対的トレーニングを組み合わせ、高い競争力を持つ最先端の推薦手法を上回る性能を示しました。ATF［3］では、コンテキスト対応型推薦の精度向上に敵対的トレーニングの利点を活かしています。

  

これらの手法は一般に、**ミンマックス最適化の枠組みを採用し、敵対的摂動とモデルパラメータを交互に学習します。**しかし、ミンマックス最適化を解くには基礎オプティマイザに対して計算コストが二重にかかるため、**実際の大規模データセットには適用しづらいという課題があります。**そこで近年では、高速化を図った敵対的トレーニング手法がいくつか提案されています［1, 27, 37］。たとえば FreeAT［27］は、モデル学習時に得られる勾配情報を再利用することで敵対的例の生成コストを削減しています。GradAlign［1］は摂動領域内での勾配の整合性を最大化する手法です。これらの最先端手法は高い性能を示す一方で、良好な初期化、大きなステップサイズ、サイクル学習率スケジュールなど一連のヒューリスティックな戦略に依存しており、**安定性に欠けて破滅的過学習を起こしやすいという指摘もあります［42］。**さらに、既存の高速敵対的トレーニングアルゴリズムの多くは連続値（例：画像のピクセル）に対する摂動生成を想定しており、**離散空間である情報検索タスクには適用が難しいという問題があります［15, 30］。**

  

これに対し本研究では、**現在のモデル状態と過去のモデル状態との整合性を測る新たなトラジェクトリ損失関数を提案し、ミンマックス最適化を解くことなく計算コストを削減する手法を示します。**また、このトラジェクトリ損失関数が最近提案された Sharpness-aware Minimization［2, 11, 20］と関連し、フラットな極小点を探索することでモデルの汎化性能を高めることを示しています。

  

## 3. Preminaries

### 3.1 Coillaborative Filtering

本論文では、**暗黙的フィードバック**（クリック、閲覧、コメント、購入など）からユーザーの嗜好を学習するタスクに着目します。一般に、**未観測のインタラクションは必ずしもネガティブではなく**、単にユーザーがそのアイテムを知らないだけかもしれません。協調フィルタリングの目的は、アイテムに対するユーザーの嗜好を推定することです。

  

### 3.2 Bayesian Personalized Ranking

上記の課題に対処するため、Adversarial Personalized Ranking（APR）［15］は、推薦モデルをパーソナライズされたランキング性能と敵対的摂動への耐性の両面で最適化する目的関数を設計しています。具体的には、潜在因子に対して敵対的摂動 Δ\Delta

Δ を加えたときのモデル損失を定量化するために、次のように予測スコアを定義します：

y^ui(Θ+Δ)=(eu+Δu)T(ei+Δi),\hat y_{ui}(\Theta + \Delta) = (e_u + \Delta_u)^\mathsf{T}(e_i + \Delta_i),

y

^

​ui

​(Θ+Δ)=(eu

​+Δu

​)T

(ei

​+Δi

​),

ここで摂動ベクトル Δ\Delta

Δ はそれぞれの潜在因子に対応し、たとえば Δu∈Rd\Delta_u \in \mathbb{R}^d

Δu

​∈Rd

はユーザー潜在ベクトル eue_u

eu

​ に対する摂動を表します。敵対的摂動（worst-case perturbations）はモデルに最大の影響を与えるよう設計されるため、APR ではまず次式で最適な摂動 Δadv\Delta_{\rm adv}

Δadv

​ を求めます：

Δadv=arg⁡max⁡∥Δ∥2≤ρ

LBPR(Θ^+Δ),\Delta_{\rm adv} = \underset{\|\Delta\|_2 \le \rho}{\arg\max}\; L_{\rm BPR}(\hat\Theta + \Delta),

Δadv

​=∥Δ∥2

​≤ρ

argmax

​LBPR

​(Θ

^

+Δ),

ここで ρ\rho

ρ は摂動の大きさを制御するハイパーパラメータ、∥⋅∥2\|\cdot\|_2

∥⋅∥2

​ は L2L_2

L2

​ ノルム、Θ^\hat\Theta

Θ

^

は途中のモデルパラメータを示します。

こうして得られた敵対的摂動を用いて、APR はパーソナライズドランキングの合理性と摂動耐性の両立を目指す新たな目的関数を定式化します。すなわち、BPR 損失と敵対的 BPR 損失を次のように統合して最小化します：

LAPR(Θ)=LBPR(Θ)+α⋅LBPR(Θ+Δadv),L_{\rm APR}(\Theta) = L_{\rm BPR}(\Theta) + \alpha \cdot L_{\rm BPR}(\Theta + \Delta_{\rm adv}),

LAPR

​(Θ)=LBPR

​(Θ)+α⋅LBPR

​(Θ+Δadv

​),

ここで α\alpha

α は敵対的摂動の影響度を制御する重みです。特に α=0\alpha=0

α=0 の場合は元の BPR（式(3)）に帰着するため、APR はモデルの頑健性を考慮に入れた BPR の一般化と見なせます。

式(6) に示されたこのミンマックス最適化は、モデルパラメータ Θ\Theta

Θ を最小化プレイヤー、摂動 Δ\Delta

Δ を最大化プレイヤーとみなしてゲームのように交互に更新を行い、収束を目指します。

  

しかしながら、APR には次の二点の課題が残されています。

1. **なぜ摂動を加えることでモデルの汎化性能が向上するのかについての理論的保証がないこと。**
2. **ミンマックス最適化を解くプロセスに多大な計算コストがかかること。**

これらの問題意識から、本論文では個別化ランキング学習のための新たな手法 SharpCF を提案します。**SharpCF は理論的保証を提供しつつ、APR と比較してほぼ追加計算コストゼロで学習できる**点が特徴です。

## 4. The proposed SharpCF

### 4.1 Simplify AP

  

  

  

  

ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー

### 単語

- perturb ... (人を)動揺させる
- overhead cost ... 間接的なコスト
- prone ... 傾向がある
- trajectory ... 軌跡