---
tags:
  - integrated-seminar
---


> [!PDF|red] [[2025-05-16_永井将太_総合ゼミ.pdf#page=1&selection=0,0,0,26&color=red|2025-05-16_永井将太_総合ゼミ, p.1]]
> > 双方向市場におけるマッチング最適化と共クラスタリング
> 
> 双方向市場の定義と共クラスタリングの定義を知りたい。

> [!PDF|yellow] [[2025-05-16_永井将太_総合ゼミ.pdf#page=1&selection=85,0,122,24&color=yellow|2025-05-16_永井将太_総合ゼミ, p.1]]
> > 求人プラットフォームにおける求職者の集合を U , 求人の集合を J とし，求職者 u ∈ U と求人 j ∈ J の相性を su,j とする．su,j は機械学習モデルなどによって推定することで得られる．su,j の推定方法は本研究の範囲外であり，本研究では所与のものとして扱う．
> 
> s_u,j をどのような方法で推定するかについては気になるところ。

> [!PDF|yellow] [[2025-05-16_永井将太_総合ゼミ.pdf#page=2&selection=0,3,83,1&color=yellow|2025-05-16_永井将太_総合ゼミ, p.2]]
> > マッチ数の最大化を目指す以下の最適化問題を考える． max x ∑ u∈U ∑ j∈J su,j , xu,j s.t. ∑ u∈U xu,j ≤ aj , ∀j ∈ J , ∑ j∈J xu,j ≤ bu, ∀u ∈ U, xu,j ∈ {0, 1}, ∀(u, j) ∈ U × J .
> 
> 今回考える最適化問題。x_u,jをバイナリにすることで相性の最大化を図っている。

> [!PDF|red] [[2025-05-16_永井将太_総合ゼミ.pdf#page=2&selection=119,0,148,21&color=red|2025-05-16_永井将太_総合ゼミ, p.2]]
> > この問題は最小費用流問題に帰着することで，O(|U| · |J ) の計算量で求解可能であることが知られている． プラットフォームの規模が n 倍，すなわち，|U|, |J | がそれぞれ n 倍になると，計算量は n2 倍となることから，大規模なアプリケーションへの適用が難しい．そこで本研究では，求職者と求人を共クラスタリングし， クラスタごとに最適化問題を解くことを考える
> 
> ここが現状の課題と新規性の部分。分かりやすい～～。

> [!PDF|yellow] [[2025-05-16_永井将太_総合ゼミ.pdf#page=2&selection=160,0,168,34&color=yellow|2025-05-16_永井将太_総合ゼミ, p.2]]
> > 共クラスタリング（co-clustering）とは，行列の「行」と「列」の両方に対して同時にクラスタリングを行う手法である．通常のクラスタリングでは，各行をデータ点とみなして行方向にのみクラスタリングを行うのに対し，共クラスタリングでは図 1 に示すように，行と列の両方向の構造を同時に捉えてクラスタに分割する．
> 
> これが共クラスタリングの定義。行列を使って解釈するもの。普通のクラスタリングとの違いを言語化して説明できない。

chatGPTによるクラスタリングと共クラスタリングの違い
- **標準クラスタリング**
    
    - **対象**：サンプル（行）同士の類似性に基づきグループ化
        
    - **データ**：サンプル×特徴量 の行列
        
    - **例**：顧客ごとの購買履歴（各顧客をベクトル化）をクラスタリングして顧客セグメントを作成
        
- **共クラスタリング**
    
    - **対象**：サンプル（行）と特徴量（列）の両方を同時にグループ化
        
    - **データ**：サンプル×特徴量 の行列
        
    - **例**：文書–単語行列を同時にクラスタリングし、「文書グループ」と「単語グループ」のブロック構造を抽出

> [!PDF|yellow] [[2025-05-16_永井将太_総合ゼミ.pdf#page=2&selection=169,0,175,0&color=yellow|2025-05-16_永井将太_総合ゼミ, p.2]]
> > 共クラスタリングの代表的な手法として，Spectral Co-clustering がある [1]
> 
> これを読めば共クラスタリングが分かるかも。この論文は共クラスタリング読まないと分からんな。

> [!PDF|red] [[2025-05-16_永井将太_総合ゼミ.pdf#page=3&selection=96,0,106,14&color=yellow|2025-05-16_永井将太_総合ゼミ, p.3]]
> > 本研究では，求職者と求人を共クラスタリングし，各クラスタ対して個別に最適化問題 1 を解く．しかし， 既存の共クラスタリング手法は，最適化問題 1を考慮せずにクラスタリングをしている．そのため，クラスタリングの段階で切断されてしまった求職者と求人の間に高スコアな枝が多数存在する場合，本来得られるべきマッチが失われる可能性がある
> 
> だいたいのイメージはついた。全体としての最適化問題を解きやすくするために、行(求職者)列(求人)に対して共クラスタリングを行い、そのクラスタ内で最適化問題を解こうとしている、ということか。であれば、共クラスタリングの精度がかなり大事になってくるな。



> [!PDF|yellow] [[2025-05-16_永井将太_総合ゼミ.pdf#page=7&selection=17,0,23,22&color=yellow|2025-05-16_永井将太_総合ゼミ, p.7]]
> > 参考文献 [1] Inderjit S Dhillon. Co-clustering documents and words using bipartite spectral graph partitioning. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 269–274, 2001.
> 
> 共クラスタリングに関する参考文献。今度見てみようかな。
> https://dl.acm.org/doi/pdf/10.1145/502512.502550?casa_token=shgywnaRURAAAAAA:1sBOrnIA_G65UD8PsUIFRz39qiWpFjIXaWiZWbnuf0MEdxn73Dab5YK9eDRWmv194-ChhB-fWe7YXA

