---
title: 推薦アルゴリズムの詳細
AI: "false"
published: 2025-06-10
description: 
tags:
  - permanent-note
  - recommend
  - oreilly
---
---
利用しているPythonコードの最新版
https://github.com/oreilly-japan/RecommenderSystems

データセット：MovieLens
- このデータセットは、推薦アルゴリズムを評価するベンチマークとして、研究でも実務でも多用されている。

アルゴリズムの数式についてのおすすめ
- 情報推薦システム入門：理論と実践』（共立出版、2012 年）
- 『推薦システム：統計的機械学習の理論と実践』（共立出版、2018 年）
- 『施策デザインのための機械学習入門：データ分析技術のビジネス活用における正しい考え方』（技術評論社、2021 年）
- **神嶌敏弘の「推薦システムのアルゴリズム」**
	- https://www.kamishima.net/archive/recsysdoc.pdf
		- https://github.com/tkamishima/recsysdoc
	- https://www.kamishima.net/archive/recsys.pdf ← 研究に貼られてたやつ
	- https://www.kamishima.net/jp/kaisetsu/

## 各アルゴリズムの比較

【簡単な推薦モデルを試す】
- 人気度推薦
- アソシエーションルール

【コンテンツベースで精度を高める】
- LDA
- word2vec
- 深層学習

【協調フィルタリングで精度を高める】
- 行列分解系
- 深層学習

![[Pasted image 20250610100221.png]]
![[Pasted image 20250610100402.png]]

## MovieLensのデータセット

MovieLensのデータセットは、ミネソタ大学のGroupLensと言う研究所が構築した映画の評価のデータセット。いくつか種類があるが、今回はMovieLens 10M Datasetというデータセットを使う。1000万件の映画評価値があり、ユーザーが書く映画にフリーテキストで付与した「ジブリ」「子供向け」「怖い」などのタグ情報もある。このデータセットでは、映画に対してタグ情報があり、**協調フィルタリングだけでなく、コンテンツベースの推薦アルゴリズムも手軽に実験できる。**

ダウンロード
- https://grouplens.org/datasets/movielens/10m/
#### MovieLensのデータ概要
推薦システムを作るうえでは、まずはデータの特徴を知っておくことが重要になる。データの特徴を探索的に調べていくことは、**探索的データ解析(EDA: Exploratory data analysis)** と呼ばれる。
MovieLensでは、すべての映画にタグが付与されているわけではなく、全体の7割ほどの映画にのみ付与されている。すべてのアイテムに情報が付与されていない問題は実務でもしばしば直面する。
効率良くアルゴリズムの検証を行うために、データをサンプリングして、小さなデータセットで素早く実験を繰り返し、良さそうなアルゴリズムにあたりをつけてからデータを増やして試すのが良い。
#### 評価方法
今回用いる指標はRMSE(Root Mean Squared Error)。また、**Precision@K** 、**Recall@K** というランキング指標でも推薦アルゴリズムの評価をしていく。ユーザーごとにPrecision@KとRecall@Kを計算し、各平均を評価指標として使用する。

**Precision@K**
- ユーザーにK個のアイテムをおすすめしたときに、その中に実際に好きなアイテムがどのくらいの割合であったか
	- 今回は4以上の評価値が付いたアイテムを好きなアイテムと定義
**Recall@K**
- ユーザーにK個アイテムをおすすめしたときに、ユーザーの好きなアイテム群のうち何個当てることが出来たか

RMSEより、Precision@KやRecall@Kのランキング指標の方が、直感的に推薦システムの性能が分かりやすく、実際のサービス上の推薦の仕方に即している。

## ランダム推薦

MovieLensの評価値は0.5~5.0であるため、この範囲で一様乱数を発生させて、それを予測評価値とする。ユーザー×アイテムの行列で、各セルに乱数を格納していく。

## 統計情報や特定のルールに基づく推薦

具体例
- 直近1カ月の総売り上げ数や閲覧数、ユーザーによる評価値の平均などのサービス内のデータの統計情報を使ってアイテムを並び替えてユーザーに推薦
- アイテムの価格や大きさなどといった特定の属性の順番に並び替えてユーザーに推薦
- ユーザーの年齢などの特定の属性情報に基づいて異なるアイテムを推薦

これらは、特定のユーザーに依存しない情報に基づいてアイテムを並び替えて推薦するため、**基本的にはパーソナライズを行わないアルゴリズム**である。そのため、実現は比較的容易。

このアルゴリズムによる推薦は、どのような仕組みでそのアイテムが推薦されているのかユーザーにとって分かりやすいという特徴がある。

ユーザーの属性情報に基づいて異なるアイテムを推薦する場合は、**ユーザーの属性情報に基づいてユーザーをいくつかのセグメントに分ける**ことで、それぞれのユーザーセグメントに適した推薦を行う。

ユーザーの年齢や性別、居住地などの人口統計学的なデータに基づいてアイテムを推薦することをデモグラフィックフィルタリング(demographic filtering)という。しかし、注意しなければならない点がある。まず第一に、**サービスやユーザーの性質によってはデモグラフィック情報をわざわざ入力しない、場合によっては誤った情報が入力されてしまう**場合がある。

近年その重要度を増している**公平性(fairness)の観点**から、これらのデモグラフィックデータを利用することは注意が必要。たとえば性別などはそもそもユーザーに聞くこと自体が問題となっていたりする。
例) Amazonがその採用プロセスにおいて候補者のプロフィール情報から機械学習によって会社とのマッチ度を自動で算出することでスクリーニングに利用することを行っていた。候補者の性別によって採用試験の合格率に大きな差がついているという事実が発覚し大きな問題となった。

評価数が少ないと評価値の信頼性が低いため、しきい値を導入して、一定以上の価値数がある映画に絞る。実務では、しきい値を1、10、100などの数パターンを試してみて、**定性的に最も納得感のある結果になる値に決めることが多い。** ただ、集計期間を長くしすぎると、常に上位にくるアイテムに変動がなくなる。しきい値を上げすぎても、同じような現象が起こる。**求人や小売では在庫の概念があり、人気のアイテムばかりをおすすめできない**という問題がある。

## アソシエーションルール

アソシエーションルールは、協調フィルタリングの推薦の中でも、昔から今に至るまで幅広い業界で活用されている。アソシエーションルールでは、**「アイテムAとBは同時に購入されることが多い」といった法則を見つける。** 有名な話として、おむつを買う男性はビールを買う傾向がある。このような組み合わせが分かると、店舗のレイアウトを変更したり、**マーケティングに活用したり**、それらの商品をセット商品として発売したりできる。アソシエーションルールでは、支持度(support)、確信度(confidence)、リフト値(lift)という3つの重要な概念が登場する。

#### 支持度
支持度とは、あるアイテムが全体の中で出現した割合のこと。あるアイテムの支持度は、アイテムの出現数を全データ数を割ることで計算される。

#### 確信度
確信度とは、アイテムAが出現したときに、アイテムBが出現する割合のこと。AとBの同時出現数をAの出現数で割ることで計算される。

#### リフト値
リフト値とは、アイテムAとアイテムBの出現がどのくらい相関しているかを表すもの。AとBのリフト値は、AとBの支持度をAの支持度とBの支持度を乗じたもので割ることで計算される。

アイテムAtoアイテムBの出現の仕方が互いに一切関係ない独立した場合には、リフト値は1になる。片方のアイテムの出現ともう片方の出現に正の相関がある場合は、リフト値は1より大きくなる。逆に負の相関がある場合は、リフト値は1より小さくなる。

## アプリオリアルゴリズムによる高速化

アイテムやユーザー数が大きくなると、アイテムの組み合わせ方が膨大になり、リフト値の計算が終わらなくなることがある。その問題を解決するアルゴリズムとして、アプリオリアルゴリズムが提案されている。アプリオリアルゴリズムでは、すべてのアイテムの組み合わせを計算するのではなく、**支持度がある一定以上のアイテムやシステムの組み合わせのみを計算対象とする**ことで、計算を高速化していく。推薦システム構築の際には、そのしきい値が重要なパラメータになってくる。

## ユーザー間型メモリベース法協調フィルタリング

メモリベース法では、**推薦システムが利用されるまではシステム内のユーザーのデータを蓄積するのみで予測のための計算は行わず**、推薦を行うタイミングで蓄積されたデータのうち必要なものを全て用いて予測計算を行う。

ユーザー間型メモリベース法のステップ
1. すでに得られている評価値を用いてユーザー同士の類似度を計算し、推薦を受け取るユーザーと嗜好の傾向が似ているユーザーを探し出す
2. 嗜好の傾向が似ているユーザーの評価値から、推薦を受け取るユーザーの未知のアイテムに対する予測評価値を計算する
3. 予測評価値の高いアイテムを推薦を受け取るユーザーに推薦する

ここでは、**類似度の算出にはピアソンの相関係数を利用する。**

## 回帰モデル

未知のアイテムに対する評価値を回帰問題として予測する。MovieLensの例では予測対象の評価値は0.5から5.0の0.5刻みの値となるので、これを回帰モデルで予測することになる。今回はランダムフォレストを用いて回帰をしている。

## 行列分解

行列分解は、モデルベース型の協調フィルタリングの手法。一般的に、**メモリベースの協調フィルタリングに比べて、実装の観点で少し複雑であるが、推薦の性能が良い**ことが知られている。行列分解の手法を実務で使う際には、「欠損値の取り扱い」と「評価値が明示的か暗黙的」という観点が非常に重要になってくる。

#### 特異値分解(SVD: Singular Value Decomposition)
#### 非負値行列分解(NMF: Nonnegative Matrix Factorization)
#### 明示的な評価値に対する行列分解(MF: Matrix Factorization)
目的関数が非凸であるため、一般的には解析的に解くことは難しい。この解法として、下記の二つが知られている。
- Alternating Least Square(ALS)
	- ユーザー因子行列とアイテム因子行列を交互に目的関数を最小化するように最適化していく
- Stochastic Gradient Descent(SGD)
	- 入力データをサンプリングしてそのデータ点におけるユーザー因子行列とアイテム因子行列の勾配を計算して、pとqを勾配方向に沿って更新していく。

「とあるユーザーは全体的に高めに評価する」「とあるアイテムは高めに評価されやすい」といった、バイアスを考慮したモデルも提案されている。
#### 暗黙的な評価値に対する行列分解(IMF: Implicit Matrix Factorizaton)
MFの式では観測された評価値で総和を取っていたのに対し、IMFの式ではユーザーとアイテムのすべての組み合わせで総和を取っている。暗黙的な評価では負例がない(好みでないことを示す指標がない)ために、観測されていないものを負例とみなすことで学習しようとしている。また、暗黙的な評価値とユーザーの好みを関連付けるため、信頼度を重みとして入れている。
#### BPR(Bayesian Personalized Ranking)
BPRでは、ユーザーu、暗黙的に評価したアイテムi、未観測なアイテムjの3つのデータをもとに学習していく。目的関数が特殊な形であるので、要チェック。直感的には、ユーザーuのベクトルとアイテムjのベクトルを近づけ、ユーザーuのベクトルとアイテムjのべうとるを遠ざけるように学習する。
#### FM(Factorization Machines)
ユーザーやアイテムの属性情報を使って、推薦システムの性能を上げる手法の一つ。これらの情報を使うことで、**新規のアイテムやユーザーに対して推薦ができないコールドスタート問題にも対応できるという利点がある。**

Factorization Machinesでは、1つの評価に対する情報が1行として表される。行列は評価数×特徴量数になる。特徴量はユーザーIDをOne-hot-encodingしたものとアイテムIDをOne-hot-encodingしたもの、ユーザーとアイテムの属性情報などの補助情報を繋げたものになる。

Factorization Machinesの良いところは、**特徴量同士の組み合わせも考慮することが出来る点**である。

## 自然言語処理手法の推薦システム応用

トピックモデル(LDA)やword2vecなどの自然言語処理の分野で提案された手法を推薦システムに応用する方法について書かれている。商品の説明文やユーザーのレビュー文を分析することで、**コンテンツベースの推薦として似ている商品を探し出すことが出来る。** また、これらの手法をユーザーの行動履歴に適用することで、協調フィルタリングベースの推薦も可能になる。

#### トピックモデル
単語は文章のトピックによって、使われやすさが異なる。トピックモデルでは、**1つの文章は複数のトピックから構成され、それぞれのトピックから単語が選択され文章が生成される**ことをモデル化している。今回は、トピックモデルの中でも、実務で使うことが多い潜在ディリクレ配分モデル(LDA：Latent Dirichlet Allocation)について説明がされている。

LDAを日本語の文章に適用する際には、**まずMeCabなどの形態素解析のライブラリを用いて文章を分割する。** 次に、助詞や句読点は除いて、名詞と形容詞だけを残すというような前処理を行う。その後のデータをLDAに入力すると、各トピックごとの単語分布と、文章のトピック分布が計算される。

#### LDAを利用したコンテンツベース推薦
各文章には、**トピックのベクトルが割り振られており、このベクトルを用いて、コサイン類似度などの距離計算をすることで、各アイテム同士の類似度を測ることが出来る。** これによって関連アイテム推薦システムを作成することが出来る。
MovieLensのデータにおいては、
1. 各映画に対して最も大きいスコアを持っているトピックを割り振る
2. ユーザーが直近高評価した映画を10個取得し、その中で最も多く出ていたトピックをユーザーが好きなトピックとする
3. そのトピックの中で、まだ見ていない映画を10本おすすめする
注意点は、**トピックが似ているからといって、購入や閲覧してくれるユーザー層が同じかというとそうでない場合がある**ということ。
#### LDAを利用した協調フィルタリング推薦
ユーザーの購入履歴や閲覧履歴などの行動履歴のデータは次のように表現できる。
`User1: [item1, item41, item23, item4]`
`User2: [item52, item3, item1, item9]`
**各アイテムを単語とみなして、ユーザーが行動したアイテムの集合を文章とみなす**ことでLDAを適用することが可能。

行動履歴をベースに各アイテムをまとめてくれるので、**商品の説明文では一見違いそうに見えても、実は一緒に購入されやすいアイテムを知ることが出来る。**
#### word2vec
「単語の意味はその周辺で出現している単語で決まる」という**分布仮説**がある。単語の意味をベクトルとして表現する方法の1つとして、word2vecがある。word2vecはいくつもの自然言語処理のタスクで好成績を収めており、実装も手軽であるため、実務で頻繁に使用されている。

word2vecを学習させると出力として、各単語のベクトルを得ることができ、その単語のベクトルを用いて単語の類似度を計算することが出来る。
#### word2vecを利用したコンテンツベース推薦
具体例として、**書籍のあらすじに出てくる単語のベクトルの平均をその書籍のベクトルとする。** それぞれの書籍のベクトル同士の類似度を計算することで、関連アイテムの推薦が可能になる。しかし、単純に平均を取るだけでは、よく出てくる単語と特徴的な単語が等しく扱われるために、特徴的な単語の影響度が薄いベクトルになってしまう。そこで、**tf-idfなどを手法を用いて、その文章に特徴的な単語だけを抽出して、平均のベクトルを取る方法**や、**tf-idfの重みを利用してベクトルを計算する方法**がある。他にも、SWEMと呼ばれる手法では、単語の平均ベクトルだけでなく、各次元の最大値や最小値を取り出した最大ベクトルや最小ベクトルを結合して、文章のベクトルとする。

word2vecを発展させたものとして、**doc2vec**と呼ばれる手法もある。これは、単語のベクトル化だけでなく、文章自体にもベクトルを付与してくれる。ハイパーパラメータを適切に調整すれば、word2vecよりもdoc2vecの方が複数のタスクにおいてパフォーマンスが高いことが報告されている。けれども、実務においては、word2vecのほうがリアルタイム推薦における計算速度が速く、ハイパーパラメータの調整が簡便。
#### word2vecを利用した協調フィルタリング推薦(item2vec)
ユーザーの閲覧や購買などの行動履歴をword2vecに適用する。この方法はitem2vecやprod2vecと呼ばれ、**実装の手軽さと推薦性能の高さからYahooやAirbnbなどの企業でも利用されている。** LDAのときと同じように、ユーザーの行動履歴を単語の集合とみなし、word2vecを適用する。ユーザーのベクトルの表現の仕方はいくつかあり、**直近何個のアイテムを使ってそのユーザーを表現するか**という観点などがある。どのくらい過去のデータを利用するかは、**そのビジネスにおけるユーザーの嗜好の変化の速さに依存する。**

今回紹介した手法以外にも、Bidirectional Encode Representations from Transformers(BERT)と呼ばれるモデルをユーザーの行動履歴に適用した事例も出ている。**BERTは、翻訳や文書分類、質問応答などの自然言語処理のタスクで2018年に1番の成績を収めたモデル。**

## 深層学習(Deep Learning)
深層学習は、**2010年代前半**に、コンピュータービジョンや自然言語処理などの分野で、従来の手法を大幅に超える性能を出したことで注目を集めた。深層学習の推薦システムへの応用は、2015年ごろから研究が増え始めており、2016年には、RecSysでも「Deep Learning for Recommender System」というワークショップがはじめて開催された。

- 深層学習そのもの
	- ゼロから作るDeep Learning: Pythonで学ぶディープラーニングの理論と実装
- 深層学習を活用した推薦システム
	- Deep Learning based Recommender System: A Survey and New Perspectives
#### 深層学習を活用した推薦システム
深層学習を推薦システムに活用する方法は、実務においては主に次の2種類がある。
1. **画像や文章などの非構造データからの特徴量抽出器としての活用**
2. **複雑なユーザー行動とアイテム特徴量のモデリング**
##### 画像や文章などの非構造データからの特徴量抽出器としての活用
モデルは、多層のレイヤー構造になっており、分類問題などのタスクを解くために必要な特徴が、各レイヤーで抽出されていく。すなわち、**余分な情報を削り、タスクを解くのに必要な情報にレイヤーを通して圧縮している**と考えれる。
今までのコンテンツベースの推薦システムでは、画像や音楽、動画、テキストに関しては、カテゴリ情報やタグ情報をもとに推薦を行ってきた。**タグ情報は、人手で付けることも多く、カテゴリやタグの粒度や網羅性が適切でない場合もあり、** それを元にした推薦システムの精度は良くなかった。
深層学習を活用することで、**カテゴリやタグ情報ではなく、アイテムのコンテンツ自体の類似度を計算して、** 推薦することが出来る。
##### 複雑なユーザー行動とアイテム特徴量のモデリング
推薦システムにおける深層学習の強みは主に次の2つ。
1. **非線形データのモデリング**
2. **時系列データのモデリング**
###### 非線形データのモデリング
行列分解(Matrix Factorization)は、ユーザーのアイテムをベクトルで表現し、その内積を利用するというもので、**線形なモデリングとなっている。** 深層学習を組み込むことで、ユーザーの複雑な行動を表現することが可能。
**Neural Collaborative Filtering**という手法は、Matrix Factorizationを深層学習化したもので、このアーキテクチャは**今までのMatrix Factorizationを包括する一般化したフレームワーク**になる。
![[Pasted image 20250615022232.png]]

**DeepFMは、Factorization Machinesを深層学習化した手法。** アイテムやユーザーの特徴量に対して、特徴量エンジニアリングが必要なく、そのままモデルに入力することが出来る。
![[Pasted image 20250615022439.png]]

**Googleが発表したWide and Deepという手法について紹介。** これは、ネットワークがWideパートとDeepパートの2つから構成されている。図の左側のWideパートでは、アイテムやユーザーの特徴量を入力として1層の線形モデルを介している。このパートでは、よく共起するような特徴量の組み合わせを学習することが可能。一方、右側のDeepパートでは、Embeddingの層を組み込み、多層にすることでより一般化した抽象的な表現を取得することができる。
###### 時系列データのモデリング
**RNN(Recurrent Newural Network)** や**LSTM(Long Short-Term Memory)** をはじめとする系列の情報の取り扱いに長けた手法が提案されている。RNNやLSTMは、自然言語処理の分野で提案された手法で、単語列を入力すると、次に生成されそうな単語を教えてくれる。
近年では、YouTubeやSpotifyをはじめとしてユーザー単位ではなくてセッションごとに推薦することの需要が高まっており、これらの系列情報に特化した深層学習の手法が活用されている。
#### 実務での深層学習の活用
##### 特徴量抽出器としての活用
実務で使う際には、**学習済みモデルを探し、** それを自社のアイテムに適用して、特徴量を抽出する。画像の場合であれば、ImageNetなどで学修したモデルを使うことで、各アイテムの画像を数百次元のベクトルとして出力できる。
文章の場合は、Wikipediaなどのデータで学修されたword2vecやBERTのモデルを使用することができる。
学習済みモデルを選ぶ際は、自社のデータに類似するデータで学習したモデルがあれば、それを使うことがおすすめ。
##### 予測モデルとしての活用
深層学習は万能で性能が高く見えるかもしれないが、**実務で使用する際には注意が必要。** 2019年のRecsysのベストペーパー「Are We Really Making Progress? A Worrying Analysis of Recent Neural Recommendation Approaches」と言う論文では、**近年提案された深層学習の推薦システムのほとんどが、単純なk近傍の推薦システムをハイパーパラメータチューニングしたものよりも精度が悪い**という衝撃の内容を報告している。
最新の論文に載っている手法だからといって、実務で同じ性能を出すとは限らず、**古典的な手法をチューニングしたほうが精度が高いこともある。**
これから推薦システムを導入しようとしている場合には、**まずは古典的な手法を検証したうえで、深層学習の使用を検討する**と良い。深層学習は、説明性が低いという課題もある。

## バンディットアルゴリズム

強化学習の分野において、
- 探索
	- 新しい知識を増やすために新しい行動を起こす
- 活用
	- すでに得られている知識を用いて、利益を大きくするような行動

一般に、ユーザーの行動量には上限があるため、探索量と活用量をあわせた回数にも制限があり、探索と活用にはトレードオフの関係がある。これを**探索と活用のジレンマ**という。いかに探索と活用を効率的に行い、サービスにおける利益を最大化するかというテーマは、推薦システムの分野において近年盛んに取り組みが行われており、なかでも**多腕バンディット問題**という枠組みの中で研究が進んでいる。

多腕バンディットの目的は大きく分けて2つある。1つ目は、**ある一定期間で、累積利益の最大化(cumulative reward maximizaton)または累積リグレットの最小化(cumulative regret minimazation)** を目指す目的。一般的にこちらを指すことが多い。2つ目は、**効率的かつ正確に利益が最大となる腕を識別する目的で、最適腕識別(best arm identification)** と呼ばれる。

代表的な多腕バンディットのアルゴリズム
- ε-greedy アルゴリズム
- UCBアルゴリズム
- トンプソン抽出

バンディットアルゴリズムについて詳しく知りたい場合
- バンディット問題の理論とアルゴリズム
- ウェブ最適化ではじめる機械学習：A/Bテスト、メタヒューリティクス、バンディットアルゴリズムからベイズ最適化まで
- A Survey on Contextual Multi-armed Bandit, https://arxiv.org/abs/1508.03326