---
title: 実システムへの組み込み
AI: "false"
published: 2025-06-15
description: 
tags:
  - permanent-note
  - recommend
  - oreilly
---
---
## システム概要

#### バッチ推薦とリアルタイム推薦
- バッチ推薦
	- モデルの学習から予測までの処理を決められた時刻に一括で行う
- リアルタイム推薦
	- 特徴量の抽出/更新をユーザーのクリックなどをトリガーとしてリアルタイムに随時行い、予測もユーザーのリクエスト時にリアルタイムに行う方式の推薦
バッチ推薦とリアルタイム推薦は、サービスにおけるアイテムやユーザー情報のフレッシュネスの要求レベルに応じて使い分ける。**フレッシュネスの要求**とは、新しいアイテム、ユーザー情報、ユーザー行動データなどが利用可能になった時点(たとえば、データベースに最初に格納された時点)から、実際に推薦に活用されるまでの時間差がどれほど小さく要求されるかを表す。

フレッシュネスの要求レベルが...
- 日次・時間レベル → バッチ推薦
- 分・秒単レベル → リアルタイム推薦
#### 代表的な推薦システム概要
###### 概要推薦
概要推薦は、新規順や人気順でアイテムを表示するもの。データベースに直接アクセスするため、リアルタイム性を考慮した推薦を行うことが出来る。例えば人気度順に集計を行いたい場合、バッチ型のシステム構成を取るのが一般的。
###### 関連アイテム推薦
関連アイテム推薦の一つの方法は、事前に類似度の計算を行い、類似するアイテム群をデータベースに保存し結果を返却すること。
###### パーソナライズ推薦
バッチ型のパーソナライズ推薦では、事前に各ユーザーごとにおすすめのアイテムを計算してデータベースに保存する。
近年では、**ベクトルベースのパーソナライズの活用が増えている。** この設計では、機械学習手法を用いてアイテムとユーザーの特徴をベクトル化し、データベースに保存する。
#### 多段階推薦
多くの商品、多くのユーザーを抱えるサービスにおける推薦では、システムの推薦を考慮した設計が不可欠。**システム負荷を低く保ちつつ精度の高い推薦を行うために「候補選択」「スコアリング」「リランキング」の多段階に処理を分ける工夫(多段階推薦)** がある。
この多段階の処理では、**まずは粗くアイテムの候補を絞り、アイテム候補数が少なくなった段階でよりユーザーや状況に適したアイテムを精度の高いモデルによって厳選する**といった処理を行う。
###### 候補選択
第一段階である候補選択は、**膨大なアイテムから推薦候補となるアイテムを抽出する**処理。YouTubeでは、この段階で数十億ある推薦アイテム候補を100~10,000個に削減する。この候補選択の処理は、処理の軽さが求められる。
###### スコアリング
第二段階であるスコアリングは、実際にユーザーに掲出するアイテムを選択するために、アイテムに対してスコアを与える処理。負荷の高いモデル、特に機械学習モデルによる高精度な推論を活用することが多い。
###### リランキング
最後のリランキングの処理では、スコアリングで選択されたアイテムを並び替える処理を行う。ここでは、**ランキング全体のバランスを考慮**して似通ったアイテムばかり並ばないようにする処理や、**アイテムの鮮度を考慮**して並び替える処理を行う。

#### 近似最近傍探索
ユーザーの特徴ベクトルが与えられたとき、そのベクトルに最も近いk件のアイテムを抽出する問題を考える。この問題は**最近傍探索問題**と呼ばれる有名な問題に相当する。最近傍探索における計算速度を高速化する方法の1つに、近似最近傍探索がある。一部正確性を犠牲にし、入力されたベクトルに近いベクトルを高速に探し出す方法。
主に次の2つのステップを取る。
- アイテム(ユーザー)のベクトルにインデックスを張る
- そのインデックスを用いて、ユーザーに対しておすすめのアイテムを推薦する
直感的なイメージとしては、ベクトル空間を複数の領域に分割し、それぞれのアイテムがどの領域に属するかを記録する。領域外のアイテムが、領域内のアイテムよりも類似度が高いことが起こりえるため、一部の正確性が失われる。
