

# Contrastive Learningとは

出典：[Contrastive Learning](https://proceedings.neurips.cc/paper_files/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html)
作者：_Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan_


自己教師ありContrastive Learning
1. ルールベースでデータ拡張 = Augmentation
	- Augmentation 設計が特に性能を左右する
	- 普通は論文やライブラリで決められた **ランダム変換ルール** を使う
	- SimCLR 論文では：
		- ランダムクロップ → リサイズ
		- カラージッター（明るさ・彩度・コントラスト変更）
		- ガウシアンぼかし
		- 水平反転
2. 埋め込み空間上で学習
	- 正例同士を近づけ、負例を遠ざける



---
## 🔹 記事目次案（Qiita向け）

1. **はじめに**
    - 本記事のゴール：Contrastive Learning の基礎から教師あり拡張（SupCon）まで理解できる
    - 背景：筆者はレコメンドの研究をしているが、レコメンドの分野においてContrastive Learningが出てきて再学習したく思った。
2. **Contrastive Learningとは？**
    - 基本アイデア：「似ているものを近づけ、異なるものを遠ざける」
    - 歴史的背景（2006 Hadsell → Triplet Loss → SimCLR/MoCo へ）
    - 代表的な応用分野（画像・言語・マルチモーダル）
3. **Contrastive Learningの仕組み**
    - アンカー・ポジティブ・ネガティブの定義
    - 損失関数（InfoNCE / NT-Xent）
    - データ拡張（Augmentation）の重要性
    - ハードポジティブ/ハードネガティブと暗黙的マイニング
4. **自己教師ありContrastive Learning**
    - ラベルなしで学習できる仕組み
    - SimCLR, MoCo, BYOL など代表例
    - バッチサイズやネガティブ数の重要性
5. **教師ありContrastive Learning（SupCon）**
    - 自己教師ありとの違い（1ポジティブ vs 複数ポジティブ）
    - SupCon Loss の定式化（式(2), (3)の比較と Lsup_out の優位性）
    - トリプレットロスやN-pairs Lossとの関係
    - 実験結果：ImageNetでの性能向上、ロバスト性の高さ
6. **なぜSupConが有効なのか？**
    - クラスごとのクラスタ形成
    - 勾配の安定化とハードサンプル対応
    - クロスエントロピーとの違い
7. **まとめ**
    - Contrastive Learning の基本から SupCon までを整理
    - 「教師あり拡張でさらに強力になる」ことを理解できたはず


---
## 日本語訳


https://proceedings.neurips.cc/paper_files/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf

### 3.2 コントラスト損失関数

ここまでの枠組みに基づき、ここではコントラスト損失の族を扱います。まずは自己教師ありの領域から始め、それを教師ありの領域へ適応させる方法を分析し、その中で1つの定式化が優れていることを示します。

$N$ 個のサンプルとラベルの組 $\{x_k, y_k\}_{k=1...N}$​ をランダムに抽出したとします。訓練に用いる対応するバッチは、$2N$ 個のペア $\{\tilde{x}_\ell, \tilde{y}_\ell\}_{\ell=1...2N}$ から成ります。ここで、$\tilde{x}_{2k}$​ と $\tilde{x}_{2k-1}$​ はサンプル $x_k$​ に対する2種類のランダムな拡張（いわゆる “ビュー”）であり、$\tilde{y}_{2k-1} = \tilde{y}_{2k} = y_k$​ です（$k = 1...N$）。本論文の残りの部分では、$N$ サンプルの集合を「バッチ」、$2N$ の拡張サンプル集合を「マルチビュー化されたバッチ」と呼びます。

---

#### 3.2.1 自己教師ありコントラスト損失

マルチビュー化されたバッチの中で、任意の拡張サンプルのインデックスを $i \in I \equiv \{1...2N\}$ とし、同じ元サンプルから生成されたもう一方の拡張サンプルのインデックスを $j(i)$ とします。

自己教師ありコントラスト学習（例: [3, 48, 18, 22]）において、損失は次の形を取ります：

$$
L^{\text{self}} = \sum_{i \in I} L^{\text{self}}_i = - \sum_{i \in I} \log \frac{\exp (z_i \cdot z_{j(i)} / \tau)}{\sum_{a \in A(i)} \exp (z_i \cdot z_a / \tau)} \tag{1}
$$

ここで、

- $z_\ell = Proj(Enc(\tilde{x}_\ell)) \in \mathbb{R}^{D_P}$は埋め込み表現、
- $\cdot$ は内積を表す、
- $\tau \in \mathbb{R}^+$ はスカラーの温度パラメータ、
- $A(i) \equiv I \setminus \{i\}$ はアンカー $i$ 以外のインデックス集合です。

用語として：

- インデックス $i$ は **アンカー**、
- インデックス $j(i)$ は **ポジティブ**、
- 残りの $2(N-1)$ 個のインデックス $\{k \in A(i) \setminus \{j(i)\}\}$ は **ネガティブ** と呼びます。

各アンカー $i$ に対して、**ポジティブペアは1つ、ネガティブペアは $2N - 2$個** あります。したがって、分母には合計で $2N - 1$ 個の項（ポジティブ1つとネガティブ）が含まれています。


### 3.2.2 教師ありコントラスト損失

教師あり学習の場合、式 (1) のコントラスト損失は、ラベルが存在することにより **同じクラスに複数のサンプルが存在するケース** を扱うことができません。  
ポジティブサンプルの数を任意に拡張できるように一般化する必要がありますが、その際に複数の可能な関数形が考えられます。

式 (2) と式 (3) は、式 (1) を教師ありに拡張する最も直接的な方法を示しています。

---

$$
L_{\text{sup}}^{\text{out}} = \sum_{i \in I} L_{\text{out,i}}^{\text{sup}} = \sum_{i \in I} \frac{-1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)} \tag{2}
$$
$$
L_{\text{sup}}^{\text{in}} = \sum_{i \in I} L_{\text{in,i}}^{\text{sup}} = - \sum_{i \in I} \log \left\{ \frac{1}{|P(i)|} \sum_{p \in P(i)} \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)} \right\} \tag{3}
$$

---

ここで、

- $P(i) \equiv \{p \in A(i) : \tilde{y}_p = \tilde{y}_i\}$ は、マルチビュー化されたバッチの中で $i$ と同じラベルを持つ **すべてのポジティブサンプルのインデックス集合**（ただし $i$ 自身は除く）。
- $|P(i)|$ はその要素数（ポジティブの数）。

違いは次の通り：

- **式 (2)**: ポジティブに対する和を **log の外側** に置いている。
- **式 (3)**: ポジティブに対する和を **log の内側** に置いている。

両方の損失関数には、以下のような望ましい性質があります。

##### 任意個数のポジティブへの一般化

式 (2), (3) の大きな構造上の変化は、式 (1) と比べて、任意のアンカーに対してマルチビュー化されたバッチ内の **すべてのポジティブ**（拡張によるペアだけでなく、同じラベルを持つ他のサンプルも含む）が分子に寄与する点です。  
もしバッチサイズがクラス数 $C$ に比べて十分に大きいランダム生成バッチであれば、平均して $N/C$ 個の追加項が分子に含まれることになります。教師あり損失は、同じクラスに属するすべてのサンプルに対して近接した表現をエンコーダに学習させるため、式 (1) から得られるよりも頑健な表現空間のクラスタリングを実現します（第4節の実験で示されています）。

##### ネガティブが多いほどコントラスト効果が増す

式 (2), (3) はどちらも、式 (1) のコントラスト損失の分母にある **ネガティブに対する総和** を保持しています。  
これは主に **ノイズコントラスト推定 (NCE)** や **N-pair loss** [13, 45] から動機付けられており、ネガティブ（雑音）サンプルを増やすことでシグナルとノイズを区別する能力が向上する、という考え方です。  
この性質は自己教師ありコントラスト学習における表現学習にとって重要であり、多くの研究 [18, 15, 48, 3] で、ネガティブ数を増やすほど性能が向上することが示されています。

##### ハードポジティブ／ネガティブ・マイニングの内在的能力

正規化された表現とともに式 (1) を用いると、損失が持つ勾配構造により、**暗黙的なハードポジティブ／ネガティブ・マイニング** が自然に生じます。

- ハードポジティブ／ネガティブ（アンカーと引き続き強く対比させることで大きく学習効果が得られるもの）からの勾配寄与は大きい。
- 一方で、イージーポジティブ／ネガティブ（アンカーと対比させても学習効果が小さいもの）からの寄与は小さい。

さらに、ハードポジティブに対しては、ネガティブ数が増えるにつれてその効果が（漸近的に）強まります。式 (2) と (3) はこの有用な性質を保持しつつ、すべてのポジティブに一般化します。

この暗黙的な性質により、コントラスト損失は **トリプレットロス [42] など多くの損失で必要となる「明示的なハードマイニング」** を避けることができます。これは繊細で重要な要素ですが、コントラスト損失では自動的に得られるという点で有利です。

なお、この暗黙的な性質は教師あり・自己教師ありの両方のコントラスト損失に共通して現れますが、本研究の導出はこの性質を初めて明確に示したものです。損失の勾配からこの性質を導く完全な証明は補足資料に記載しています。


> [!NOTE] ハードマイニング
> - **ハードポジティブ**: アンカーと同じクラスだけど「距離が遠い」サンプル
> - **ハードネガティブ**: アンカーと違うクラスだけど「距離が近い」サンプル
> - 例:
> 	- 「犬」と「狼」は見た目が似てる → ハードネガティブ
> 	- 「犬」の中でも柴犬とグレートデーンは大きさが違って見える → ハードポジティブ
> - ハードポジティブの場合
> 	- 類似度が小さいので分子が小さくなり、損失が大きくなる
> - ハードネガティブの場合
> 	- 類似度が大きいので分母が大きくなり、損失が大きくなる
> - 従来手作業で行っていたハードマイニングが自動で行えるという意味で、**暗黙的なハードマイニングと称している。**

しかし、この2種類の損失関数の定式化は同値ではありません。log 関数は凹関数であるため、イェンセンの不等式 [23] より

$$
L_{\text{sup}}^{\text{out}} \leq L_{\text{sup}}^{\text{in}}​
$$

が成り立ちます。したがって、一見すると $L_{\text{sup}}^{\text{in}}$​ の方が優れた教師あり損失関数である（$L_{\text{sup}}^{\text{out}}$​ を上から抑えているので）と結論づけたくなります。

しかし、この結論は理論的には支持されません。表1では、ResNet-50 [17] アーキテクチャを用いた場合における、バッチサイズ $N$ を変えたときの ImageNet [7] における Top-1 精度を $L_{\text{sup}}^{\text{out}}$​ と $L_{\text{sup}}^{\text{in}}$​ で比較しています。その結果、$L_{\text{sup}}^{\text{out}}$​ の方が $L_{\text{sup}}^{\text{in}}$​ よりも有意に高い性能を達成しました。

我々は、この差は勾配構造の違いに起因していると推測しています。つまり、$L_{\text{sup}}^{\text{out}}$​ では、ポジティブに対する正規化項（すなわち $1/|P(i)|$）が、マルチビュー化バッチにおいて損失に寄与するポジティブ間のバイアスを取り除く役割を果たします。これに対して、$L_{\text{sup}}^{\text{in}}$​ も同じ正規化項を含んではいますが、それが log の内部にあるため、全体の損失には単なる加法定数として寄与するにとどまり、勾配には影響しません。その結果、正規化効果が働かないため、$L_{\text{sup}}^{\text{in}}$​ の勾配はポジティブの偏りに敏感になり、学習が最適でなくなるのです。


勾配そのものの解析も、この結論を裏付けています。補足資料に示すように、埋め込み $z_i$​ に関する $L^{\text{sup}}_{\text{out},i}$ または $L^{\text{sup}}_{\text{in},i}$​ の勾配は以下の形を持ちます：

$$
\frac{\partial L^{\text{sup}}_i}{\partial z_i} = \frac{1}{\tau} \left\{ \sum_{p \in P(i)} z_p \, (P_{ip} - X_{ip}) \;+\; \sum_{n \in N(i)} z_n \, P_{in} \right\} \tag{4}
$$

ここで、

- $N(i) \equiv \{n \in A(i) : \tilde{y}_n \neq \tilde{y}_i\}$ は、マルチビュー化されたバッチの中でアンカーと異なるラベルを持つすべてのネガティブサンプルのインデックス集合。
- $P_{ix} \equiv \frac{\exp(z_i \cdot z_x / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)}$

2つの損失関数における勾配の違いは、$X_{ip}$​ の定義にあります：

$$
X_{ip} = \begin{cases} \dfrac{\exp(z_i \cdot z_p / \tau)}{\sum_{p' \in P(i)} \exp(z_i \cdot z_{p'} / \tau)} & \text{if } L^{\text{sup}}_i = L^{\text{sup}}_{\text{in},i} \\[1.2em] \dfrac{1}{|P(i)|} & \text{if } L^{\text{sup}}_i = L^{\text{sup}}_{\text{out},i} \end{cases} \tag{5}
$$

もし各 $z_p$​ を「よりバイアスの少ないポジティブ表現の平均ベクトル」$z$ に設定した場合、$X^{\text{in}}_{ip}$ は $X^{\text{out}}_{ip}$ に一致します：

$$
X^{\text{in}}_{ip} \big|_{z_p = \bar{z}} = \frac{\exp(z_i \cdot \bar{z} / \tau)}{\sum_{p' \in P(i)} \exp(z_i \cdot \bar{z} / \tau)} = \frac{\exp(z_i \cdot \bar{z} / \tau)}{|P(i)| \cdot \exp(z_i \cdot \bar{z} / \tau)} = \frac{1}{|P(i)|} = X^{\text{out}}_{ip} \tag{6}
$$

この $\frac{\partial L^{\text{sup}}_i}{\partial z_i}$​​ の形から、ポジティブの平均を使うことで得られる安定化が学習に有益であると結論づけられます。したがって本論文の残りの部分では、$L^{\text{sup}}_{\text{out}}$​ のみを考慮します。

### 3.2.3 トリプレットロスおよび N-pairs ロスとの関係

教師ありコントラスト学習は、教師あり学習で広く用いられている損失関数のひとつである **トリプレットロス [52]** と密接に関連しています。補足資料において、トリプレットロスは「ポジティブが1つ、ネガティブが1つ」という状況におけるコントラスト損失の特殊なケースであることを示しています。また、ネガティブが複数存在する場合、SupCon損失は **N-pairs ロス [45]** と等価になることを示しています。





---
# 下記記事



## 1. はじめに

いらっしゃいませ。

:::note info
- 本記事のゴール：
    - **Contrastive Learning の概要を数式アリでざっと理解 ＆ イメージを付ける**
    - Supervised Contrastive Learning との違いを理解
- 背景：
    - sequential recommendation の論文を読んでいた時に Contrastive Learning に遭遇
:::

いよいよ本題に入っていきますよ～。

Supervised Contrastive Learning の生みの親である下記の論文をもとに解説。
> 出典：[Supervised Contrastive Learning](https://proceedings.neurips.cc/paper_files/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html)
作者：_Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan_

## 2. Contrastive Learningとは？

#### 根幹にあるアイデア

**「似ているものを近づけ、異なるものを遠ざける」** 
データ間の相対的な関係を利用して表現を学習。

**1. 自己教師あり学習**
**2. 教師あり学習** ← 拡張ver.
これら2種類があるが、まず自己教師ありの方が先に出現。

この記事では、

1 → 自己教師あり Contrastive Learning
2 → 教師あり Contrastive Learning

と呼称。

#### 応用分野例

* 画像認識 (ImageNet 事前学習 → 転移学習)
* 自然言語処理 (Sentence-BERT, CLIP)
* 音声認識や動画理解
* レコメンド

## 3. Contrastive Learningの準備

#### まずデータ拡張 (Data Augmentation)

自己教師あり学習は教師なし学習に分類されるので、正解のラベルがない
→ 正解のラベルを、ルールベースでデータ拡張を行うことで作りに行く

1. $N$ 個のサンプルとラベルの組 $\lbrace x_k, y_k\rbrace\_{k=1...N}$​ をランダムに抽出。
↓
2. 訓練に用いる対応するバッチを組成。
    - $2N$ 個のペア $\lbrace \tilde{x}\_\ell, \tilde{y}\_\ell\rbrace_{\ell=1...2N}$ 

※$\tilde{x}\_{2k}$​ と $\tilde{x}\_{2k-1}$​ はサンプル $x_k$​ に対する2種類のランダムな拡張（ビュー）で、$\tilde{y}\_{2k-1} = \tilde{y}\_{2k} = y_k$​

:::note info
**ポイント：**
データ拡張をすることでラベルを生成し、教師あり学習に近づける。
:::

#### 出てくる用語

* **アンカー (Anchor)**: 基準となるサンプル
* **ポジティブ (Positive)**: アンカーと「意味的に同じ」サンプル
* **ネガティブ (Negative)**: アンカーと「異なる」サンプル

例：
- Anchor：チワワ
- Positive：柴犬
- Negative：ネコ、ウサギ

<img width="800" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3999280/f8192231-01ad-4486-a678-0005d8690b2a.png">

<img width="800" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3999280/549137de-6d07-42de-8a79-fbfc8124327c.png">

> 引用: "Supervised Contrastive Learning", Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot, A., Liu, C., Krishnan, D., (NeurIPS'20)


## 4. 自己教師ありContrastive Learning

代表的な損失関数の定式化は以下：

> $$
L^{\text{self}} = \sum_{i \in I} L^{\text{self}}\_i = - \sum_{i \in I} \log \frac{\exp (z_i \cdot z_{j(i)} / \tau)}{\sum_{a \in A(i)} \exp (z_i \cdot z_a / \tau)} \tag{1}
$$
>- $z_\ell = Proj(Enc(\tilde{x}_\ell)) \in \mathbb{R}^{D_P}$：埋め込み(Embedding)
>- 「$\cdot$」：内積
>- $\tau \in \mathbb{R}^+$：パラメータ
>- $A(i) \equiv I \setminus \{i\}$ ：アンカー $i$ 以外のインデックス集合


つまり、
- 分子：アンカーとポジティブの類似度が大 ⇒ 損失 小
- 分母：アンカーとネガティブの類似度が小 ⇒ 損失 小

**→ 分子を大きく、分母を小さくするように埋め込みを学習する仕組み**

#### ハードポジティブ／ネガティブと暗黙的マイニング

- **ハードポジティブ**: 同じクラスだが遠いサンプル
- **ハードネガティブ**: 違うクラスだが近いサンプル

- 例:
 	- 「犬」と「狼」は見た目が似てる → ハードネガティブ
 	- 「犬」の中でも柴犬とグレートデーンは違って見える → ハードポジティブ

**先ほどの 式(1) には、暗黙的なハードマイニングが含まれている。**

なぜなら、

- ハードポジティブの場合
    - 類似度が小 → 分子が小 → 損失が大
- ハードネガティブの場合
    - 類似度が大 → 分母が大 → 損失が大

となるため、**明示的なハードマイニングが不要。**

:::note
従来手作業で行っていたこともある、**ハードマイニングが自動で行える** というメリットがこの式にある (暗黙的なハードマイニング)
:::

## 5. 教師ありContrastive Learning

#### 自己教師ありとの違い

- 自己教師あり: **1サンプルにつき「1つのポジティブ」を形成**
- 教師あり: **同じクラスのサンプルすべてをポジティブにできる**

#### 損失関数の定式化

2種類ありますが、実際使われているのは(2)の方。

$$
L_{\text{sup}}^{\text{out}} = \sum_{i \in I} L_{\text{out,i}}^{\text{sup}} = \sum_{i \in I} \frac{-1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)} \tag{2}
$$

$$
L_{\text{sup}}^{\text{in}} = \sum_{i \in I} L_{\text{in,i}}^{\text{sup}} = - \sum_{i \in I} \log \lbrace \frac{1}{|P(i)|} \sum_{p \in P(i)} \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)} \rbrace \tag{3}
$$

* 式(2): log の外に和を置く ($L_{\text{sup}}^{\text{out}}$)
* 式(3): log の中に和を置く ($L_{\text{sup}}^{\text{in}}$)

→ 実験では **$L_{\text{sup}}^{\text{out}}$ の方が安定し、高性能**

#### なぜ(2)の方が高性能なのか？


> 原文：
> 我々は、この差は勾配構造の違いに起因していると推測しています。つまり、$L_{\text{sup}}^{\text{out}}$​ では、ポジティブに対する正規化項（すなわち $1/|P(i)|$）が、マルチビュー化バッチにおいて損失に寄与するポジティブ間のバイアスを取り除く役割を果たします。これに対して、$L_{\text{sup}}^{\text{in}}$​ も同じ正規化項を含んではいますが、それが log の内部にあるため、全体の損失には単なる加法定数として寄与するにとどまり、勾配には影響しません。その結果、正規化効果が働かないため、$L_{\text{sup}}^{\text{in}}$​ の勾配はポジティブの偏りに敏感になり、学習が最適でなくなるのです。

→ 平均を取ることによる正規化効果は、**logを取った後に行う方が、「損失に寄与するポジティブ間のバイアスを取り除ける」ので良い**のでは？と考えられる。

このあたりの詳しい解析が気になったら是非[論文](https://proceedings.neurips.cc/paper_files/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html)へ。

#### 補足：Triplet Loss との関係

* トリプレットロス: ポジティブ1つ＋ネガティブ1つ → SupConの特殊形
