
過去20年間で、CFレコメンデーションシステムに採用されるモデルがますます高度になるにつれて、それらに対する攻撃も変化してきました。これらの攻撃は、大きく分けて2つのパラダイムに分けられます。**AI攻撃**と**古典的なヒューリスティック攻撃**です。

1. **古典的なヒューリスティック攻撃**: これらの攻撃が従う戦略は2つのステップで構成されます。(1)悪意のあるユーザーを検知する（これは最適化問題として定式化されます）、そして(2)その問題をヒューリスティックな手法で解決する、というものです。このカテゴリに分類される攻撃は20年前にまで遡りますが、現在でも用いられています。これらの攻撃で使用される具体的な手法の多くは比較的単純に見えますが、効果的であることが証明されています。

2. **AIベースの攻撃**: この7年間で、ユーザープロファイルを偽造し、本物のユーザーの行動を模倣するためにエンドツーエンドのフレームワークを学習させる様々な攻撃が登場しました。例えば、**敵対的生成ネットワーク（GANs）** に基づくいくつかのスキームが最近提案され、ターゲットとなるシステムに影響を与えるために本物のユーザーの行動を自動的に模倣します [7, 73, 115]。もう一つの手法は、強化学習スキームにおける報酬信号を、レコメンダーモデルへのバックドアとして悪用することです [109]。

---
##### ポイズニング攻撃の増加と進化

図1が示すように、**過去7年間でレコメンデーションシステムに対する攻撃の提案数が増加しています。** 同時に、**古典的な攻撃からAIベースの攻撃への明確な移行が見られます**。この図は、Google ScholarやScopusといった主要なコンピュータサイエンスのリポジトリから計量書誌学分析を用いて抽出された、年ごとの攻撃の公開数とカテゴリを一覧にしています。調査方法の詳細はセクション1.3で提供されています。この傾向は、セキュリティ専門家によっても確認されています。AI手法を悪用する攻撃の数は、今後数年間で大幅に増加すると予想されます。

↓
【事実】
- 過去7年間でレコメンドシステムに対する攻撃の提案数が増加
- 古典的な攻撃からAIベースへの明確な移行が見られる

---
###### ポイズニング攻撃に関する論文

AIベースのポイズニング攻撃はレコメンデーションシステムに深刻な脅威をもたらしますが、これらのシステムに対する既存の攻撃に関する調査論文は、**主に古典的なヒューリスティック攻撃とその対策に焦点を当てています。** より最近の研究は、ヒューリスティック攻撃とAIベース攻撃の組み合わせを扱っています。さらに、一部の調査論文はポイズニング攻撃全般を扱っており、また特定のドメインにおけるこれらの攻撃を調査しているものもあります。しかし、**これまでレコメンデーションシステムに特化した調査論文は存在しませんでした。** 本調査論文では、レコメンデーションシステムにおける最先端の攻撃と、それらを防ぐために講じられる対策について包括的な概観を提供することで、このギャップを埋めることを目指しています。
↓
【事実】
- 既存の攻撃に関するサーベイ論文は主に古典的なヒューリスティック攻撃とその対策に焦点を当てている
- 最近の研究では、ヒューリスティック攻撃とAIベースの攻撃の組み合わせを扱っているものがある
- ポイズニング攻撃について、レコメンドシステムに特化した調査論文は存在しなかった

---
##### ポイズニング攻撃と敵対的攻撃の差分

既存のいくつかの調査論文は、レコメンデーションシステムに対する敵対的攻撃を考慮しています。**ポイズニング攻撃と敵対的攻撃にはいくつかの概念的な類似点がありますが、両者には根本的な違いがあります**（図2に示されています）。敵対的攻撃の目的は、根底にあるモデルを変更することなく、推論時にレコメンデーションシステムの出力を不正にするような敵対的サンプルを見つけることです。これらの攻撃は、入力データを操作して、攻撃中にシステムを一時的に欺き、不正確な予測や推薦を生成させます。

![[Pasted image 20250807185913.png]]

一方、**ポイズニング攻撃は、モデルのトレーニング段階で仕掛けられます。** ここでは、攻撃者がモデルのトレーニングデータに注意深く細工したデータを注入し、真のモデルを攻撃者の目標に有益な結果をもたらす攻撃モデルに根本的に変換することを目的とします。トレーニング中に悪意のあるデータを注入することで、**攻撃者はシステムの学習プロセスに偏りを与え**、その推薦を永続的に操作することを目指します。
↓
【事実】
- 敵対的攻撃
	- 推薦前にデータを若干改竄(摂動)することで、不正確な予測や推薦を生成させる
- ポイズニング攻撃
	- モデルのトレーニング段階で仕掛けることができる

---
##### ポイズニング攻撃と敵対的攻撃の具体例

より具体的な例を挙げてみましょう。ユーザーの閲覧履歴に基づいて商品を推薦するオンラインマーケットプレイスを考えてみます 。
- **敵対的攻撃 (Adversarial attack)**: 攻撃者は、特定の商品の出品内容を操作したり、ユーザーの閲覧履歴を一時的に変更したりして、特定のアイテムを宣伝する可能性があります 。これにより、そのユーザーの現在のセッション中に表示される推薦に影響が及びます 。
- **ポイズニング攻撃 (Poisoning attack)**: 攻撃者は、不正なレビューや操作された購入記録など、悪意のあるデータをシステムのトレーニングデータに注入します 。この方法により、攻撃者はモデルに特定の製品を優遇するようバイアスをかけたり、推薦のランキングを操作したりすることができ、単一のユーザーセッションだけでなく、より広範なユーザー層にわたって長期間にわたり推薦に影響を与えます 。
その結果、これら2つの異なる種類の攻撃は、それぞれ異なる目的と影響を持っています 。敵対的攻撃はポイズニング攻撃と関連していますが、本調査で扱われるポイズニング攻撃とは、ほとんどの場合、直交する **直接的な関係が薄い** ものです 。
↓
【事実】
- 敵対的攻撃
	- ログデータの改ざんによる入力値の変更
- ポイズニング攻撃
	- 悪意のあるログデータの注入による訓練妨害


---
##### このサーベイ論文の貢献

- レコメンデーションシステムにおける攻撃者が直面する特有の課題について議論し、レコメンデーションシステムへの攻撃を、機械学習やコンピュータビジョンといった関連分野の手法から区別しています 。例えば、レコメンデーションシステムは通常、ユーザーとアイテムのデータ間の相関関係を利用して推薦を生成します 。**これらの相関関係は、基盤となるモデルにある程度の堅牢性を生み出し、攻撃を困難にすることがあります 。**
- レコメンデーションシステムに対するポイズニング攻撃について、古典的なヒューリスティック攻撃とAIベースの攻撃の両方を網羅した、初の包括的なレビューを提示しています 。これらの29の攻撃を構造化して提示するために、**この研究分野全体の全体像を提供する5つの次元からなる分類法を考案しました 。**
- 特定されたポイズニング攻撃に対する**41の対策**について、広範なレビューを提示しています 。さらに、特定の攻撃に対して効果的な対策と、特定の攻撃に対して失敗する可能性が高い対策の両方を考慮して、攻撃と対策を結びつけています 。
- 主な目的を超えて、この分野における未解決の課題についても記述し、**有望な将来の研究の方向性を示して調査論文を締めくくっています 。**
- 研究者がこの分野での研究を始めることができるように、レビューしたすべての論文、研究に関連して公開されたプログラムコード、データセットを含む公開リポジトリ を構築しました。これにより、この分野に参入する研究者に、潜在的な脅威からレコメンデーションシステムを保護するための作業を支援する包括的な資料コレクションを提供しています 。


---
##### この論文の構成

- **セクション2**: レコメンデーションシステムの概要と、この分野におけるセキュリティの状況について説明します。また、ポイズニング攻撃からレコメンデーションシステムを保護する際の特有の課題についても強調します。
- **セクション3**: ポイズニング攻撃のための新しい分類法（タクソノミー）を導入し、この分類法の次元を正式に定義します。
- **セクション4**: この分類法に従って、ポイズニング攻撃に関する既存の研究をレビューし、モデルアグノスティック（モデルに依存しない）な手法とモデルイントリンシック（モデル固有の）な手法の両方を扱います。
- **セクション5**: ポイズニング攻撃を検知および防止するための対策について説明します。
- **セクション6**: 最後に、記事をセクション7で締めくくる前に、この分野における研究のギャップと将来の研究の有望な方向性について強調