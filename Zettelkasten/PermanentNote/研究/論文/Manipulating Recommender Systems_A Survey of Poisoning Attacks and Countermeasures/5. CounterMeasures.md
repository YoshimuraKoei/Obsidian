
---
##### 対策

ポイズニング攻撃への対策は、2つのサブグループに分けられます。

1. **検知手法**: ポイズニング攻撃で作成されたユーザープロファイルを特定することを目的とするアプローチ。    
2. **防御手法**: 操作されたプロファイルを明示的に特定しようとせずに、レコメンダーシステムをポイズニング攻撃に対してより堅牢にすることを目指すアプローチ。    

このセクションでは、両方のタイプの手法をレビューします。

- 次に、どの対策がどのタイプのポイズニング攻撃に効果的かについて（セクション5.3）、そして特定の攻撃に対してはうまく機能しないと予想される対策について（セクション5.4）、それぞれマッピングします。
- 最後に、セクション5.5で私たちの考察をまとめます。

↓
- 一つ目の検知手法は初見
- 二つ目の防御手法はいわゆるロバストCF


---
##### 検知手法

このセクションではまず、ポイズニング攻撃の検知に一般的に使用される**特徴量**の種類について議論します。続いて、ポイズニング攻撃を検知するためのシグナルとして最も頻繁に用いられる**特性**をレビューします。最後に、本物のユーザープロファイルと、攻撃の一環として使用されたプロファイルを区別するために提案された**実際の手法**について議論して締めくくります。

既存の検知手法は、**モデルに依存しない（model-agnostic）特徴量**または**モデルに内在する（model-intrinsic）特徴量**のいずれかに基づいています。

###### モデルに依存しない特徴量
モデルに依存しない特徴量は、使用されている攻撃モデルの種類に**関係なく**、一般的な異常行動を捉えるように設計されています。これには以下のものが含まれます。

1. **平均合意からの評価偏差 (RDMA)**: 
**特定のユーザーが多数の特定のアイテムに与えた評価が、他のユーザーの評価と比べてどれだけ平均的に乖離しているか**を示すものです。これは、それらのアイテムの評価頻度の逆数で重み付けされます。 形式的には、ユーザー $u$ がアイテム $i$ に与えた評価を $r_{u}^i$​、アイテム $i$ に与えられた評価の平均を $\bar{r_i}$ とします。$n_{r^i}$​​ はアイテム i に与えられた評価の数、$n_u$​ はユーザー $u$ が評価したアイテムの数です。 この特徴量は、以下の式で定義されます。

$$
	RMDA_u = \frac{\sum_{i=0}^{n_u} \frac{|r_u^i - \bar{r^i}|}{n_{r^i}}}{n_u}
$$
2. **平均合意からの重み付き偏差 (WDMA)**: これはRDMAの重み付き分散で、疎な（評価数が少ない）アイテムに対するユーザー評価の累積的な違いを捉えます。 上記の表記法を使い、WDMAは以下のように定式化されます。
$$
	WDMA_u = \frac{\sum_{i=0}^{n_u} \frac{|r_u^i - \bar{r^i}|}{n_{r^i}^2}}{n_u}
$$

3. **長さ分散 (LengthVar)**: これはプロファイルの長さ（そのプロファイルによって評価されたアイテムの数）の違いを測る指標です。すべてのプロファイルの平均の長さと比較して計算されます。 $n_u$​ をプロファイル $u$ の長さ（評価アイテム数）、$\bar{n_u​}$​ をすべてのプロファイルの平均の長さとすると、LengthVarは以下のように定義されます。
$$
	LengthVar_u = \frac{n_u - \bar{n_u}}{\sum_{u \in U}(n_u - \bar{n_u})^2}
$$
4. **トップ近隣ユーザーとの類似度 (DegSim)**
この特徴量は、あるユーザーが**トップk人の近隣ユーザー**とどれだけ似ているかを平均的に反映するものです。
- $k$ は近隣ユーザーの数を示します。
- $sim_{u,v}$​ は、ユーザー $u$ と $v$ の間の類似度で、例えばピアソン相関を用いて計算されます[103]。

この特徴量は以下の式で定式化されます。
$$
	DegSim_u = \frac{\sum_{v=1}^k sim_{u,v}}{k}
$$
###### モデルに内在する特徴量

**モデルに依存しない特徴量**には多くの利点があるものの、特に本物のユーザーが異常な行動を示した場合、本物のプロファイルと悪意のあるプロファイルを区別する能力はそれほど高くないことが証明されています [113]。この問題に対処するため、さまざまな**モデルに内在する特徴量**が提案されてきました。以下では、そのような特徴量に関連する一般的で代表的な概念をいくつかレビューします。

↓
忘れていたが、普通のユーザーが異常な行動を示す場合がある。それをポイズニング攻撃と見なすのはUXが悪くなるので、その異常行動を想定したロバストなCFを構築しておく必要があるね。


1. **平均分散 (MeanVar)**
これは、悪意のあるプロファイルを構成する3つの部分に分類して測定する指標です。

- **ターゲットアイテムへの極端な評価**
- **プロファイルを埋めるための他のアイテムへの評価**（いわゆるフィラーアイテム）
- **未評価のアイテム**

この特徴量は、**「他の評価（フィラーアイテム）」と全アイテムの平均評価との間の平均分散**を計算することで推定されます。

- $P_{u,F}$​ をユーザー $u$ のフィラーアイテムの集合とします。    
- $r_{u,j}$​ をユーザー $u$ がアイテム j に与えた評価とします。
- $\bar{r_u​}$​ をユーザー $u$ がアイテムに与えた評価の平均とします。

MeanVarは以下の式で定義されます。
$$
	MeanVar = \frac{\sum_{j \in P_{u, F}}(r_{u,j} - \bar{r_u})^2}{|P_{u,F}|}
$$

2.**フィラー平均ターゲット差分モデル (FMTS)**
これは、**ターゲットとなる部分（ターゲットアイテム）の評価と、フィラー部分（フィラーアイテム）の評価との差の度合いを評価**する指標です。

- 上記と同じ表記法を使用します。
- $P_{u,T}$​ をユーザー $u$ のターゲットアイテムの集合とします。

この特徴量は以下の式で定式化されます。

(省略)


3. **フィラー平均相関 (FAC)**
この特徴量は、**プロファイル内の評価と全アイテムの平均評価との間の相関を反映**します。

- $I_u$​ をユーザー $u$ が評価したアイテムの集合とします。
- $\bar{r_i}$​ をアイテム $i$ の平均評価とします。

FACは以下の式で定義されます。

(省略)


4. **フィラー平均差分 (FMD)**
この特徴量は、**プロファイルの評価と全アイテムの平均評価の絶対差の平均値を測定**するものです。以下の式で定義されます。

(省略)



---
##### 検知特性

このサブセクションでは、Sundar et al. [113]によって開発された検知特性の基礎的なフレームワークを拡張します。彼らのフレームワークは、攻撃検知特性を以下の4つのグループに分類しています。

1. **ユーザープロファイル**
2. **ターゲット評価**
3. **フィラー評価**
4. **サイド情報**


- **ユーザープロファイル**
この最初の特性グループは、悪意のあるプロファイルと本物のプロファイルを区別するために検知手法によって使用されます。ここでは比較のために、新しい特性を追加しています。

1. **類似性（Similarity）**: あるプロファイルがその近隣のプロファイルに似ているほど、そのプロファイルが攻撃の一部として作成された可能性が高くなります。
2. **サイズ（Size）**: 攻撃のサイズ（つまり、注入されたプロファイルの数）が、ユーザープロファイル全体のセットに比べて非常に小さい場合でも、類似性の高いプロファイルの集団は攻撃を示唆します。
3. **グループ行動（Group behaviour）**: 通常、ユーザー行動には隠れた特性があります。例えば、悪意のあるユーザーのグループは、評価の分散に正の相関を持つかもしれません。このようなグループ行動は、悪意のあるユーザーを検知するための貴重な手がかりとなります。
4. **属性（Attributes）**: 本物のプロファイルと注入されたプロファイルのユーザー属性は、異なる分布に従う傾向があります。このため、統計分析手法は、異常なプロファイルを明らかにし、攻撃の検知に役立つことがよくあります。


- **ターゲット評価（Target Rating）**
ターゲット評価とは、攻撃者が**宣伝または非難しようとするアイテム**に与えられた評価のことです。ここでは、ターゲット評価に関連する2つの特性を考慮する必要があります。
1. **集合性（Crowdability）**: ポイズニング攻撃後、ターゲットアイテムの評価頻度は通常、異常に高くなります。この評価頻度の急増は、攻撃の指標となり得ます。
2. **歪んだ評価（Skewed Ratings）**: 攻撃者の究極の目標は、ターゲットアイテムに対するユーザーの態度を操作することです。そのため、偽の評価は平均評価から乖離する傾向があります。この発見は、攻撃を検知するために悪用できます。



- **フィラー評価（Filler Rating)**
フィラー評価は、前述のように、ターゲットアイテムではなく**通常のアイテム**に、攻撃の一環として割り当てられる評価です。ここでも2つの特性を考慮する必要があります。

1. **評価（Rating）**: 攻撃を偽装して類似性を最大化するために、フィラーアイテムに割り当てられる評価は、通常、現在の平均評価に近くなります。この観察に基づくと、まずフィラーアイテムの評価を評価し、次に攻撃者を特定することが良い戦略となるかもしれません。
2. **長さ（Length）**: プロファイルによって評価されたアイテムの数は、「プロファイルの長さ」として知られています。攻撃者は本物のプロファイルにできるだけ似たプロファイルを作成しようとします。しかし、**このプロファイルは通常、通常のプロファイルよりもはるかに長くなります。** したがって、プロファイルの長さは攻撃者を特定する手がかりとなり得ます。


- **サイド情報（Side Information）**
近年、ポイズニング攻撃は、ターゲットシステムを操作するために**サイド情報**に依存し始めています [110]。これにより、考慮すべき新たな特性のクラスが生まれています。

1. **共起（Co-occurrence）**: 一部のレコメンダーシステムは、ユーザーにアイテムを推奨する際の基礎として、**共起グラフ**を使用します [134]。これらのシステムでは、攻撃者が細工された共起情報をレコメンダーシステムに注入して、推奨を操作する可能性があります。
2. **ユーザー・ユーザーグラフ（User-user graph）**: ユーザー間の類似性も、悪意のあるユーザーと本物のユーザーを区別する特性となります。**グラフマイニングアルゴリズム** [152] を使用すると、グラフのノード間の類似性を計算することで、ユーザーの類似性を探索できます。ユーザーのインタラクションから生成されたこのグラフは、攻撃を検知するための貴重な視点を提供します。


---
##### 検知手法の概要

###### 教師あり学習の手法
教師あり学習の環境では、悪意のあるプロファイルと本物のプロファイルを区別するためのラベル（正解データ）が必要です。

(関連研究は省略)

もう一つの問題は**クラスの不均衡**です。

(関連研究は省略)

###### 半教師あり学習の手法
ほとんどのレコメンダーシステムでは、ラベル付けされたユーザーの数は非常に少ないのが一般的です。さらに、残りのユーザーにラベルを付ける作業は、コストがかかりすぎる上、データへのアクセスが通常制限されているため、現実的ではありません。このような状況では、**半教師あり学習**の手法が非常に効果的であることが証明されています。

(関連研究は省略)

###### 教師なし学習の手法
ラベルがまったくない場合、検知の唯一の選択肢は**教師なし学習**の手法です。

(関連研究は省略


---
##### 防御手法

###### 防御手法の定式化
防御手法は、ポイズニング攻撃の影響を軽減することを目的としています。効果的な防御策の一つに**ロバスト最適化**があります [81]。形式的には、$\mathcal{R}$ をユーザーとアイテムのインタラクション行列における観測された評価の集合とします。目的関数は以下のように定式化されます。
$$
	\mathcal{E} = \mathcal{L} + \lambda \times \mathcal{R}
$$
この定式化において、$\mathcal{L}$ は元の損失関数で、推薦された評価と実際の評価との間の予測誤差を測定します。一方、$\lambda \times \mathcal{R}$ の項は、目的関数に**正則化（regularisation）** の要素を導入し、トレーニングデータ内の観測された評価と一致する評価の生成を促進します [125]。係数 λ は、精度とシステムがポイズニング攻撃に耐える堅牢性（レジリエンス）とのバランスを決定します。
↓
- $\mathcal{R}$はロバスト性を組み込むためだろうけども、定数では...？

###### 効果的な堅牢性を達成するための課題の軽減
ほとんどの防御手法は、複数の技術を組み合わせています。

- **「オープネス（Openness）」** の問題は、**外れ値検知**、**データサニタイゼーション**、**前処理技術**によって対処されます [106]。これらの手法を通じて、操作されたデータを特定し、フィルタリングすることができます。
- もう一つの例として、**「コンセプトドリフト（Concept Drift）」** は、進化するユーザー行動に適応する**動的学習アルゴリズム**を使用することで対処されることが多いです [113]。この適応性により、システムは本物の変化と偽のユーザーを区別し、正確な推薦を維持するのに役立ちます。
- **「データの不均衡（Imbalanced data）」** は、一般的に**アンサンブル手法**によって対処されます [96]。これは、少数派のクラスにより大きな重みを割り当てたり、オーバーサンプリングまたはアンダーサンプリング技術を使用してデータセットのバランスを整えたりするものです。

攻撃を明示的に検知しようとせず、レコメンダーシステムをポイズニング攻撃に対してより堅牢にする研究も存在します。これらのアルゴリズムは、ポイズニング攻撃が悪用するレコメンダーシステムの脆弱性に対処することを目指しています。このセクションでは、その方向性の既存研究を簡単に紹介します。

(関連研究は省略)

ポイズニング攻撃の防御に関する初期の研究は、主に統計的手法やSVDベースの手法といった伝統的な分析技術に焦点を当てていました。しかし、その後のアプローチでは、GCNや差分プライバシーといったより高度な基盤が見られるようになりました。さらに、**敵対的学習**は、ユーザープロファイルのより良い表現を獲得し、システムの堅牢性を大幅に向上させる優れた機会を提供することが証明されています。


---
##### どの対策がどの攻撃に効果的か？

攻撃の可視化というアイデア [45] に基づき、私たちはどの対策がどの攻撃に効果的であるかのマッピングを作成しました。このマッピングは、攻撃の特性を捉え、それを対策、および攻撃者の戦略と能力にリンクさせています。

マッピングの結果は図6に示されています。ここでは、驚くことではありませんが、**ユーザーと評価に関連する特性**に**圧倒的に焦点が当てられている**ことがわかります。これは、これまで議論してきた多くの戦略が、実際に多数の攻撃に対してある程度の堅牢性を達成することが期待できることを示しています。

![[Pasted image 20250811212736.png]]

↓
- ユーザーと評価に関する攻撃の防御手法がほとんど


---
##### どの対策がどの攻撃に対して弱いか？

ほとんどの攻撃は、単に特定のアイテムを宣伝または非難することを目標としているわけではありません。むしろ、対策から身を隠そうとします。ポイズニング攻撃のレビュー（表2の「unnoticeable（検知されにくい）」列を参照）でこの側面はすでに考慮しましたが、ここでは図7に示すように、これらの攻撃と特定の対策をマッピングします。

図の左側の列には、**弱い対策**がリストされており、右側の列には、特定の対策に対して**耐性を持つ攻撃**が示されています。全体として、特定の攻撃に対して弱い対策はごく少数しかありません。また、これらの依存関係はそれぞれ、対応する弱点を回避する方法についての研究の機会となる点も注目に値します。
↓
- 全体として、特定の攻撃に対して弱い対策はごく少数らしい

最後に、レコメンダーシステムにおけるポイズニング攻撃に対する対策の進化の概要を提供します。図8は、近年の関連研究の数を捉えたタイムラインを示しています。この図からわかるように、対策の研究は**2019年頃に堅実な注目を集めました**が、ごく最近に発表された研究はわずかしかありません。


