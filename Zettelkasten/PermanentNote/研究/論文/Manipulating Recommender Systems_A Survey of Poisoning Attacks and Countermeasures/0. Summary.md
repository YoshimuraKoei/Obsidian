
レコメンデーションシステムは、膨大なデータの中からユーザーが特定の情報を見つけるのを助けるため、オンラインサービスに不可欠な存在となっています。しかし、既存の研究によると、レコメンデーションシステム、特に学習を伴うものはポイズニング攻撃に対して脆弱であることが示されています。

**ポイズニング攻撃**とは、攻撃者が巧妙に作成したデータをモデルのトレーニングプロセスに注入し、システムの最終的な推奨結果を操作しようとするものです。最近のAIの進歩に伴い、このような攻撃の重要性は増しています。

現状では、攻撃者がなぜこのような攻撃を仕掛けるのか、また攻撃がどの程度までモデルを損ない、どのような影響を及ぼすのかについて、完全かつ明確な全体像は把握されていません。ポイズニング攻撃に対する多くの対策が開発されていますが、それらの対策は攻撃の特性と体系的に結びついていないため、個々のリスクと対策の成功可能性を評価することは困難、あるいは不可能です。

この調査論文は、主にポイズニング攻撃とその対策に焦点を当てることで、このギャップを埋めることを目的としています。これは、主に攻撃とその検出方法に焦点を当てていたこれまでの調査とは対照的です。

徹底的な文献レビューを通じて、私たちは**ポイズニング攻撃に関する新しい分類法**を提案し、その次元を形式化し、文献に記載されている31の攻撃を整理しました。さらに、ポイズニング攻撃を検知または防止するための43の対策をレビューし、特定の種類の攻撃に対する有効性を評価しました。

この包括的な調査は、ポイズニング攻撃からレコメンデーションシステムを保護するための参照点として役立つはずです。最後に、この分野における未解決の問題と、将来の研究に向けた影響力のある方向性について議論しています。

ポイズニング攻撃に関連する豊富なリソースは、以下のリポジトリで利用できます： [https://github.com/tamlhp/awesome-recsys-poisoning](https://github.com/tamlhp/awesome-recsys-poisoning)
