
[[Disentangling Long and Short-Term Interests for Recommendation.pdf]]

---
## 論文詳細

##### 📌 CCS CONCEPTS

- **Information systems → Personalization**

##### 📌 KEYWORDS

- Recommendation
- Long and Short-Term Interests
- Self-supervised Learning
- Disentanglement Learning
##### 📌 著者

- Yu Zheng（清華大学・Kuaishouインターン時の仕事）
- Chen Gao（清華大学、corresponding author: chgao96@gmail.com）
- Jianxin Chang（Kuaishou Technology）
- Yanan Niu（Kuaishou Technology）
- Yang Song（Kuaishou Technology）
- Depeng Jin（清華大学）
- Yong Li（清華大学）

##### 📌 ジャーナル・出版情報

- **会議**: The ACM Web Conference (WWW ’22)
- **開催**: 2022年4月25–29日, Virtual Event, Lyon, France
- **出版社**: Association for Computing Machinery (ACM)
- **ISBN**: 978-1-4503-9096-5/22/04
- **DOI**: [10.1145/3485447.3512098](https://doi.org/10.1145/3485447.3512098)
- **ページ数**: 12 pages


> [!NOTE] 
> 👉 まとめると、この論文は **WWW 2022 (ACM Web Conference)** に採択されたもので、清華大学とKuaishou社の共同研究。テーマは「自己教師あり学習による長期・短期嗜好の分離と推薦への応用」です。

---
## Abstract

ユーザーの長期的・短期的な興味をモデル化することは、正確な推薦において極めて重要です。しかし、ユーザーの興味に関して手作業でアノテーションされたラベルは存在しないため、既存の手法は常にこの2つの側面を絡め取る形でモデル化しており、その結果、推薦精度や解釈可能性が劣化する可能性があります。

本論文では、この問題に対処するために、**Contrastive learning framework to disentangle Long and Short-term interests for Recommendation（CLSR）** という自己教師あり学習の枠組みを提案します。具体的には、まず2つの独立したエンコーダを設計し、それぞれ異なる時間スケールにおけるユーザーの興味を捉えます。その上で、インタラクション系列から長期的および短期的な興味の代理表現を抽出し、これをユーザー興味の擬似ラベルとします。次に、興味表現とその対応する代理表現の類似性を監督するペアワイズのコントラスト学習タスクを設計します。最後に、長期的・短期的な興味の重要度は動的に変化するため、予測のためにこれらを適応的に統合するアテンションベースのネットワークを提案します。

我々は、Eコマースと短尺動画推薦という2つの大規模実データセットで実験を行いました。実験結果は、CLSRが全ての最先端モデルを一貫して上回り、**GAUCを0.01以上改善し、NDCGを4%以上向上**させることを示しました。さらに反事実的な評価によって、CLSRが長期・短期興味の分離をより強く達成できることを実証しました。

コードとデータは以下で公開されています:  
👉 [https://github.com/tsinghua-fib-lab/CLSR](https://github.com/tsinghua-fib-lab/CLSR)

---
## 1 Introduction

情報の洪水が急速に増加する中で、レコメンダシステムは、ニュース [2]、Eコマース [51]、動画 [10, 27] など、数多くのオンラインサービスにおいて重要な役割を果たしてきました。  
具体的には、レコメンダシステムは、まずユーザーの過去のインタラクションからユーザーの興味を推定し、それからこれらの興味に合致するアイテムを検索することで、パーソナライズされたコンテンツを提供します。

しかし実際には、ユーザーの興味は、**安定した長期的な興味と動的な短期的な興味の両方を持つ傾向がある**ため、追跡することが難しいです。  
例えば、テクノロジーに精通したユーザーは、常に電子機器を閲覧したい（長期的な興味）一方で、短期間だけ服に興味を示すこともある（短期的な興味）。  
その結果として、ユーザーの長期的および短期的（LS-term）な興味を正確にモデル化し、区別することが重要です。

まず文献をレビューしましょう。  
**協調フィルタリング（CF）に基づくレコメンダ [15, 16, 23, 35, 51] は、主に長期的な興味を捉え、逐次的な特徴を無視するため、動的な短期的興味をモデル化する点で制限があります。**  
その結果として、逐次モデル [17, 41, 50, 55] が提案され、**畳み込みニューラルネットワークやリカレントニューラルネットワークを利用して、ユーザーの興味の逐次的特徴を学習します。**  
しかし、これらの手法は短期的記憶に偏り、結果として、ユーザーの最近の行動により関連するアイテムを推薦する傾向があります。

> [!NOTE] 課題感
> - CFベースのレコメンダ → 長期的な関心重視
> - CNN、RNN → 短期的な関心(逐次的特徴)重視
> 
> → 各手法は偏りが大きい

その結果として、最近では、一連のアプローチ [2, 29, 47, 48] が提案され、**CFベースのレコメンダと逐次レコメンダを組み合わせて、長期的および短期的な興味の両方をカバーしようとしています。**  
具体的には、これらのアプローチでは、行列分解のようなCFベースのモデルが長期的興味のために採用され、逐次モデルが短期的興味を学習するために利用されます。  
しかし、LS-term の興味が対応するモデルによって効果的に捉えられるかどうかは保証されません。なぜなら、これらの手法は学習されたLS-termの興味に明示的な監督を課していないからです。  
言い換えれば、**これらの手法において学習されたLS-termの興味は互いに絡み合う（entangled）可能性があります [28]。**


> [!NOTE] LS-term
> LS-termの興味に監督を課すことで、長期と短期のちょうど良いバランスを取ろうとしている

全体として言えば、LS-termの興味を分離することは次の課題に直面します。

- 第一に、**LS-termの興味はユーザーの嗜好のまったく異なる側面を反映**します。  
    具体的には、長期的興味は長期間安定して持続するユーザーの全体的嗜好と見なせる一方で、短期的興味は最近のインタラクションに応じて急速に進化する動的な嗜好を示します。  
    したがって、LS-termの興味の統一された表現を学習することは、こうした違いを捉えるには不十分です。逆に、両側面を別々にモデル化する方が適切です。
    
- 第二に、**LS-termの興味を学習するためのラベル付きデータを得るのは難しい**です。  
    収集された行動ログデータは常に、クリックのようなユーザーの暗黙的フィードバックしか含まないためです。  
    したがって、LS-termの興味を分離してモデル化することは、2つの側面を区別するための明示的な監督を欠いています。
    
- 最後に、**ユーザーの将来のインタラクションを予測するためには、長期的および短期的な興味の両方が考慮されるべき**です。  
    しかしながら、2種類の興味の重要性は、異なるユーザー–アイテムのインタラクションごとに変化します。  
    例えば、ユーザーが似たアイテムを**連続的に閲覧している場合は短期的興味がより重要**であり、一方で、ユーザーが**大きく異なるアイテムに切り替える場合は行動が長期的興味に大きく駆動されます。**  
    したがって、将来のインタラクションを予測するために、これら2つの側面を適応的に融合することが重要である一方、困難でもあります。
    

> [!NOTE] LS-termの課題
> 1.  LS-termの興味は全く異なるジャンルを反映するし、加えて異なる性質を持つ → 別々でモデル化するべき
> 2. 暗黙的FBしか含まないので、分類の正確さを学習するラベル付きデータを得るのが難しい → 明示的な監督が不可能
> 3. 連続閲覧とジャンル変更の場面を考えると、予測には長期的および短期的な興味の両方が考慮されるべき → 適応的に融合させる必要性

上記の課題に対処するために、我々は、インタラクション系列を利用して自己教師信号を構築し、LS-termの興味を分離するコントラスト学習フレームワークを提案します。  
具体的には、LS-termの興味を独立して捉えるために、我々は各インタラクションを3つのメカニズムに分解することを提案します：

- 長期的興味の表現
- 短期的興味の進化
- インタラクション予測

我々は**時間的ダイナミクスの異なる2つの独立したエンコーダを設計**し、それぞれがLS-termの興味をモデル化することで第一の課題に対処します。  
LS-termの興味に関するラベルデータの欠如という主要な課題を克服するために、我々は**自己教師あり学習** [7] を用いることを提案します。  
我々はまず、**ユーザーの全履歴インタラクションから長期的興味の代理表現**を、**最近のインタラクションから短期的興味の代理表現を抽出**します。  
そして、2つの独立したエンコーダから得られた興味表現が、それぞれ対応する代理表現とより類似するように監督します。これはコントラスト学習の形で行われます。  
既存の手法 [2, 47] が学習されたLS-termの興味に明示的な監督を課していないのとは異なり、我々の自己教師ありアプローチは、LS-termの興味のより良い分離表現を学習でき、ラベル付きデータへの依存を排除します。

> [!NOTE] Contrast Learning
> 勉強で書いた記事：https://qiita.com/noeten916523/items/453c52eb4e30d4971844

分離された興味表現を得た後、我々はアテンションベースの融合ネットワークを設計し、予測のためにこれら2つの側面を適応的に統合します。これが最後の課題を解決します。

我々は2つの実世界データセットにおいて本手法の推薦性能を評価しました。実験結果は、CLSRが最先端（SOTA）の手法を上回る大幅な改善を達成することを示しています。具体的には、**AUC**および**GAUC**は0.02以上改善し、**NDCG**は10.7%以上改善しました。これは既存研究 [39, 47] によって有望な向上と見なされる値です。  
さらに、自己教師あり分離設計の有効性を調査するために、我々は履歴インタラクション系列を介入して長期的または短期的興味を遮断する反事実的評価を行いました。その結果、CLSRはSOTA手法に比べて一貫してより強いLS-termの興味の分離を達成することを実証しました。

まとめると、本論文の主な貢献は次のとおりです：

- 我々はユーザーの長期的および短期的な興味の異なるダイナミクスを強調し、**両要因を分離することが正確な推薦にとって重要である**ことを初めて指摘しました。
- 我々はLS-termの興味を別々に捉えるためのコントラスト学習フレームワークを提案しました。分離された表現は、元のインタラクション系列から構築された代理表現と比較することで自己教師あり学習されます。さらに、アテンションベースの融合ネットワークを設計し、LS-termの興味を適応的に統合してインタラクションを予測します。
- 我々は実世界データセットで広範な実験を行いました。実験結果は、提案するCLSRがSOTA手法に対して大幅な改善を達成することを検証しました。さらに反事実分析により、CLSRがはるかに強力なLS-termの興味の分離を達成できることを示しました。

本論文の残りの構成は以下の通りです。まず第2節で問題を定式化し、第3節で提案手法を紹介します。その後、第4節で実験を行い、第5節で関連研究をレビューします。最後に第6節で本論文をまとめます。

---
## 2 Problem Formulation

M をユーザー数とし、$\{x^u\}_{u=1}^M$ をすべてのユーザーに対するインタラクション系列とします。  
各系列 $x^u = [x^u_1, x^u_2, ..., x^u_{T_u}]$ は、対応するインタラクションのタイムスタンプに従って並べられたアイテムのリストを表します。  
ここで $T^u$ はユーザー $u$ のインタラクション履歴の長さを表し、各アイテム $x^u_t$​は、 $[1, N]$ に属します。ここで $N$ はアイテム数を示します。

ユーザーのインタラクション履歴 $x^u$ は、長期的および短期的な興味の両方を反映するため、レコメンダシステムはまず $x^u$ からLS-termの興味を学習し、それからこの2つの側面に基づいて将来のインタラクションを予測します。

したがって、推薦のためにLS-termの興味を学習する問題を次のように定式化できます：

- **入力**: すべてのユーザーに対する履歴インタラクション系列 $\{x^u\}_{u=1}^M$​。
- **出力**: ユーザーがあるアイテムをクリックするかどうかの確率を推定する予測モデル（長期的および短期的な興味の両方を考慮）。


> [!NOTE] E2E モデル
> 入力：履歴インタラクション系列 $\{ x^u \}_{u=1}^M$
> 出力：長期的および短期的興味の両方を考慮した上での、ユーザーが各アイテムをクリックする確率

---
## 3 Methodology

本節では、提案する **長期的および短期的興味のためのコントラスト学習フレームワーク（CLSR）** について詳しく説明します。

### 3.1 User Interests Modeling

ユーザーのLS-termの興味は、時間に対するダイナミクスが大きく異なるため、それらを統一された表現で表すのではなく、別々にモデル化する方が適切です。  具体的には、長期的興味は比較的安定しており、短期的興味は動的で頻繁に変化します。  
同時に、各インタラクションは、長期的興味と短期的興味の両方、さらにターゲットアイテムによって決定されます。

したがって、我々はユーザー興味のモデリングを次の3つの独立したメカニズムとして定式化することを提案します：

$$
\zeta = 
\begin{cases} 
	U_l = f_1(U), \\ U_s^{(t)} = f_2(U_s^{(t-1)}, V^{(t-1)}, Y^{(t-1)}, U), \\ Y^{(t)} = f_3(U_l, U_s^{(t)}, V^{(t)}, U), 
\end{cases}
$$


> [!NOTE] アイデア
> 二つ目の式、**一つ前のインタラクションしか考慮していない**のが気になる

ここで、$f_1, f_2, f_3$​ は、それぞれユーザー $U$ の長期的興味 ($U_l$​)、短期的興味 ($U_s^{(t)}$​)、およびアイテム $V^{(t)}$ とのインタラクション ($Y^{(t)}$) の基礎関数を表します。  
現在および直前のタイムスタンプは、それぞれ $t$ および $t-1$ と表記します。  
なお、$U$ はユーザープロファイルを表し、ユーザーIDとインタラクション履歴 $x^u$ を含みます。

提案するユーザー興味モデリング $\zeta$ は、各インタラクションを以下の3つのメカニズムに分解します：

- $f_1$​: 長期的興味の表現    
- $f_2$​: 短期的興味の進化
- $f_3$​: インタラクション予測

これは図1に簡単に示されています。以下にそれぞれの詳細を説明します。

![[Pasted image 20250928112827.png]]

- **長期的興味の表現（式(1)）**  
    長期的興味はユーザー嗜好の全体的な視点を反映し、したがって安定しており、直近のインタラクションにあまり影響されません。  
    言い換えれば、長期的興味は全ての履歴インタラクション系列から推測できるため、履歴 $x^u$ を含む $U$ を $f_1$​ の入力に含めます。
    
- **短期的興味の進化（式(2)）**  
    短期的興味は、ユーザーが推奨されたアイテムと継続的にインタラクションするにつれて進化します [50]。  
    例えば、ユーザーはアイテムをクリックした後に新しい興味を持つこともあれば、徐々に特定の興味を失うこともあります。  
    つまり、短期的興味は時間依存の変数であり、したがって式(2)では、時刻 $t$ における短期的興味 $U_s^{(t)}$​ は、時刻 $t-1$ における短期的興味 $_s^{(t-1)}$​ から再帰的に進化し、直前のインタラクション $Y^{t-1}$ とアイテム $V^{(t-1)}$ によって影響を受けます。
    
- **インタラクション予測（式(3)）**  
    将来のインタラクションを予測する際に、長期的興味と短期的興味のどちらが重要な役割を果たすかは、ターゲットアイテム $V^{(t)}$ やユーザー $U$ の履歴 $x^u$ など、様々な要因に依存します [47]。  
    したがって、我々は $U_l$​ と $U_s^{(t)}$​ を $V^{(t)}$ と $U$ に応じて適応的に融合し、インタラクションを正確に予測します。


> [!NOTE] 疑問
> インタラクション予測については、 $U$ は必要なのか？

LS-termの興味を分離するということは、$U_l$​ が長期的興味だけを捉え、$U_s$​ が純粋な短期的興味をモデル化することを意味します。  
このような分離は、解釈可能で制御可能な推薦を実現するのに有用です。なぜなら、融合の重みを調整することで、それぞれの側面の重要性を追跡し、調整できるからです。  
一方で、LS-termの興味を効果的に調整するには、学習された表現が望ましい側面の情報だけを含む必要があります。

簡単な線形の例として、推薦モデルがLS-termの興味を次のように絡めてしまう場合を考えます：

$$
U'_l = 0.6 U_l + 0.4 U_s,\quad U'_s = 0.4 U_l + 0.6 U_s \tag{4}
$$
ここで $U'_l$​ と $U'_s$​ は学習された絡み合った興味です。  
もし融合の重み（LS-termの興味の重要性）がそれぞれ 0.8 と 0.2 である場合、実際の融合された興味は次のように計算されます：

$$
U'_{fuse} = 0.8 U'_l + 0.2 U'_s = 0.56 U_l + 0.44 U_s \tag{5}
$$
これは、望ましい興味とは大きく異なります。

しかし、LS-termの興味を分離することは難しいです。なぜなら、$U_l$​ や $U_s$​ に対応するラベル付きデータが存在しないからです。  
ここで我々は、自己教師あり学習によって強い分離を達成できるコントラスト学習フレームワークについて詳述します。

### 3.2 Our Self-supervised Implementation

本節では、まず $f_1$​ と $f_2$​ を実装するために2つの独立したエンコーダを提供し、LS-termの興味の表現を学習します。  
次に、自己教師あり学習による分離を達成するために設計したコントラストタスクを導入します。  
最後に、$f_3$​ を実現するために、アテンション技術に基づく適応的融合モデルを紹介します。  
CLSRの概要は図2に示されています。

![[Pasted image 20250913122904.png]]

#### 3.2.1 LS-termの興味のためのクエリベクトル生成

最近の研究 [2, 29, 47, 48] に触発され、これらは2つの異なるモデルを用いてLS-termの興味を別々に学習します。  我々は、2つの独立したアテンションエンコーダ $\phi$ と $\psi$ を設計し、それぞれが2つの側面を捉えるようにしました。

まず、LS-termの興味のためのクエリベクトルを次のように生成します：

$$
q^u_l = \text{Embed}(u), \tag{6}
$$
$$
q^{u,t}_s = \text{GRU}(\{x^u_1, \cdots, x^u_t\}), \tag{7}
$$

ここで、 **我々はルックアップ埋め込みテーブルとGated Recurrent Unit (GRU) [9] を使用し、時間に応じた異なるダイナミクスを捉えます。**
埋め込み類似度に追加の自己教師あり制約を課すために、すべての埋め込みは同じ意味空間に属する必要があります。  
したがって、アイテムの履歴系列をアテンションエンコーダのキーとして使用し、その結果得られるLS-termの興味表現は次のように、同じアイテム埋め込み空間に存在します：

$$
u^t_l = \phi(q^u_l, \{x^u_1, \cdots, x^u_t\}), \tag{8}
$$
$$
u^t_s = \psi(q^{u,t}_s, \{x^u_1, \cdots, x^u_t\}), \tag{9}
$$

ここで $u^t_l$​ と $u^t_s$​ はLS-termの興味の学習された表現です。  
次に、LS-termの興味のために提案するエンコーダを紹介します。

> [!NOTE] Query / Key / Value
> 長期クエリも短期クエリも最初はランダムなベクトル。学習して磨かれていき、そのユーザーの嗜好を表すベクトルになる。
> クエリと、候補リストを渡して候補のなかで類似度を重みづけ → 嗜好ベクトル $u^t_l, u^t_s$ を作成

> [!NOTE] 流れ
> クエリが $q$ で、キーがアイテム履歴系列 $\{ x^u_1, \cdots , x^u_t\}$
> 「どの履歴がクエリにとって重要か？」を計算

#### 3.2.2 長期的興味エンコーダ

図2 (B) は、提案する長期的興味エンコーダ$\phi$ を示しています。  
我々はアテンションプーリングを用いて長期的興味の表現を抽出します。  
各アイテム $x^u_j$​ のアテンションスコアは次のように計算できます：

$$
v_j = W_l E(x^u_j), \tag{10}
$$
$$
\alpha_j = \tau_l \big( v_j \parallel q^u_l \parallel (v_j - q^u_l) \parallel (v_j \cdot q^u_l) \big), \tag{11}
$$
$$
a_j = \frac{\exp(\alpha_j)}{\sum_{i=1}^t \exp(\alpha_i)}, \tag{12}
$$

ここで、$W_l$​ は変換行列、$\tau_l$​ は多層パーセプトロン（MLP）ネットワーク、$\parallel$ は埋め込みの連結を表します。

最終的に学習された長期的興味表現は、上記のアテンションネットワークによって計算された重みに基づく全履歴インタラクションの加重和として表され、次のように定式化されます：

$$
u^t_l = \sum_{j=1}^t a_j \cdot E(x^u_j). \tag{13}
$$


> [!NOTE] 
> 先ほどの $\phi$ の中身がこの節で説明されている。


#### 3.2.3 短期的興味エンコーダ

ユーザーインタラクションの逐次的パターンは短期的興味のモデリングにおいて極めて重要であるため、我々はリカレントニューラルネットワーク（RNN）の上にもう一つのアテンションネットワークを利用します。

具体的には、履歴アイテムの埋め込みをRNNモデルに入力し、その出力をキーとして用います。これは次のように定式化されます：

$$
\{o^u_1, ..., o^u_t\} = \rho(\{E(x^u_1), ..., E(x^u_t)\}), \tag{14}
$$
$$
v_j = W_s o^u_j, \tag{15}
$$

ここで、$W_s$​ は変換行列、$\rho$ はRNNモデルを表します。

第4節では、LSTM [18]、GRU [9]、Time4LSTM [47] を含むRNNモデルの異なる実装を評価する実験を行います。

式(18) および (19) と同様に、我々は $q^{u,t}_s$ をクエリベクトルとして使用し、アテンションスコア $b_k$​ を得ます。  
その後、短期的興味の学習された表現は次のように計算できます：

$$
u^t_s = \sum_{j=1}^t b_j \cdot o^u_j. \tag{16}
$$


> [!NOTE] Title
> RNNだけなら：
> - 全部を時系列で混ぜて「平均的な短期表現」を作る
> 
> RNN＋アテンションなら：
> - クエリが「スポーツモード」なら (1) と (3) に強い重み
> - クエリが「旅行モード」なら (4) に強い重み
> - 「洗剤（2）」は無視される


#### 3.2.4 Self-supervised Disentanglement of LS-Term Interests

前述したように、長期的興味はユーザーの嗜好の全体的なビューを提供し、履歴インタラクション全体を要約します。一方で、短期的興味は時間とともに動的に進化し、最近のインタラクションを反映します。  
したがって、我々はインタラクション系列そのものからLS-termの興味の代理（proxies）を得ることができ、それを用いて2つの興味エンコーダを監督することが可能です。

具体的には、**全インタラクション履歴の平均表現を長期的興味の代理とし、直近の $k$ 個のインタラクションの平均表現を短期的興味の代理**とします。形式的には、時刻 $t$ におけるユーザー $u$ のLS-termの興味の代理は次のように計算できます：

$$
p^{u,t}_l = \text{MEAN}(\{x^u_1, \cdots, x^u_t\}) = \frac{1}{t} \sum_{j=1}^t E(x^u_j), \tag{17}
$$

$$
p^{u,t}_s = \text{MEAN}(\{x^u_{t-k+1}, \cdots, x^u_t\}) = \frac{1}{k} \sum_{j=1}^k E(x^u_{t-j+1}), \tag{18}
$$

ここで、$E(x)$ はアイテム $x$ の埋め込みを意味します。

なお、系列が短い場合には長期・短期を区別する必要がないため、系列長が閾値 $l_t$​ を超える場合にのみ代理を計算します [26]。この閾値 $l_t$​ と直近行動系列の長さ $k$ は我々の手法におけるハイパーパラメータです。  
さらに、ここでは単純さのため平均プーリングを使用しており、その性能は十分に良い結果となります。実際、我々の自己教師ありパラダイムは、より複雑な代理の設計を利用することも可能ですが、それは将来の課題とします。

**代理がラベルとして機能する**ことで、我々はそれらを用いてLS-termの興味の分離を監督できます。具体的には、エンコーダの出力と代理の間でコントラスト学習を行い、学習されたLS-termの興味表現が、反対の代理よりも対応する代理に類似するように求めます。図2 (A) にコントラストタスクを示します。形式的には、次の4つのコントラストタスクがあります：

$$
\text{sim}(u^t_l, p^{u,t}_l) > \text{sim}(u^t_l, p^{u,t}_s), \tag{19}
$$
$$
\text{sim}(p^{u,t}_l, u^t_l) > \text{sim}(p^{u,t}_l, u^t_s), \tag{20}
$$
$$
\text{sim}(u^t_s, p^{u,t}_s) > \text{sim}(u^t_s, p^{u,t}_l), \tag{21}
$$
$$
\text{sim}(p^{u,t}_s, u^t_s) > \text{sim}(p^{u,t}_s, u^t_l), \tag{22}
$$

ここで、式(19)–(20) は長期的興味を監督し、式(21)–(22) は短期的興味を監督します。また $\text{sim}(\cdot,\cdot)$ は埋め込み類似度を測定します。

長期的興味のモデリングを例にとると、式(19)は学習された長期的興味表現 $u^t_l$​ が、短期的代理 $p^{u,t}_s$​ よりも長期的代理 $p^{u,t}_l$​ に近くなるよう促します。一方、式(20)は $u^t_l$​ が短期的興味表現 $u^t_s$​ よりも長期的代理 $p^{u,t}_l$​ に近くなるように求めます。

このように、エンコーダ出力と**代理の類似性に基づく4つの対称的なコントラストタスク**を設けることで、LS-termの興味モデリングに自己教師ありの監督を加えることができ、既存の非教師あり手法と比較してより強い分離を実現できます。

我々は、式(19)–(22) のコントラスト学習を実現するために、**Bayesian Personalized Ranking (BPR)** [35] と **triplet loss** に基づく2つのペアワイズ損失関数を実装しました。形式的には、埋め込み類似度を捉えるために内積とユークリッド距離を用いた2つの損失関数は次のように計算されます：

$$
L_{bpr}(a, p, q) = \sigma(\langle a, q \rangle - \langle a, p \rangle), \tag{23}​$$
$$
L_{tri}(a, p, q) = \max\{d(a, p) - d(a, q) + m, 0\}, \tag{24}
$$

ここで $\sigma$ はsoftplus活性化関数、$\langle \cdot, \cdot \rangle$ は2つの埋め込みの内積、$d$ はユークリッド距離、$m$ は正のマージン値を表します。  
BPRとtriplet lossの両方は、アンカー $a$ が負のサンプル $q$ よりも正のサンプル $p$ に近づくように設計されています。

したがって、LS-termの興味の自己教師あり分離のためのコントラスト損失は次のように計算できます：

$$
L^{u,t}_{con} = f(u_l, p_l, p_s) + f(p_l, u_l, u_s) + f(u_s, p_s, p_l) + f(p_s, u_s, u_l), \tag{25}
$$

ここで、興味表現および代理の添字の時刻 t は省略しており、f は $L_{bpr}$​ または $L_{tri}$​ のいずれかです。


> [!NOTE] BPR loss と triplet loss
> 恐らく両方実装して、二種類の実験結果があるはず

**備考.** ユーザーのLS-termの興味は、ある程度互いに重なり合う場合もあります。例えば、あるユーザーがEコマースアプリケーションで服だけを購入する場合、長期的興味と短期的興味は一貫する傾向があります。  
したがって、学習された分離された要因を互いに異なるよう強制する独立性制約を追加する既存の分離推薦アプローチ [43, 49] とは異なり、我々はそのような正則化項を含めません。  
我々は、LS-termの興味の学習された表現が対応する代理と類似するようにのみ監督します。これが、逆のエンコーダと代理間の類似性に対して過度に強い罰則を課す **InfoNCE** [33] のような損失関数を使用しない理由でもあります。

まとめると、我々は2つの独立したエンコーダ$\phi$ と $\psi$ を実装し、それぞれLS-termの興味の表現を学習します。  
LS-termの興味の分離を達成するために、我々は履歴インタラクション系列から代理を計算します。さらに、2つのエンコーダが望ましい側面のみを捉えるよう導くために、コントラスト学習損失関数を提案し、自己教師ありの方法で分離を実現します。

#### 3.2.5 Adaptive Fusion for Interaction Prediction

自己教師あり学習によって得られた分離された表現を用いたとしても、2つの側面をどのように統合してインタラクションを予測するかは依然として課題です。  
単純なアグリゲータ（例えば和や連結）は、LS-termの興味の寄与が固定されていると仮定しますが、これは多くの場合において成り立ちません。

**実際、長期的興味と短期的興味のどちらがより重要であるかは、履歴系列に依存します。**  
例えば、ユーザーが同じカテゴリのアイテムを連続して閲覧している場合は、主に短期的興味によって駆動されます。  
一方で、LS-termの興味の重要性はターゲットアイテムにも依存します。  
例えば、スポーツ愛好者は、たとえいくつかの本を閲覧した後であっても、長期的興味によって推奨された自転車をクリックするかもしれません。

したがって、**我々はアグリゲータの入力として履歴系列とターゲットアイテムの両方を含めます。** ここで履歴系列はGRUで圧縮されます。  
提案するアテンションベースの適応的融合モデルは図2 (D) に示されており、LS-termの興味の重要性を動的に決定して $u^t_l$​ と $u^t_s$​ を統合します。

形式的には、最終的な融合された興味は次のように得られます：

$$
h^u_t = \text{GRU}(\{E(x^u_1), ..., E(x^u_t)\}), \tag{26}
$$
$$
\alpha = \sigma \big( \tau_f ( h^u_t \parallel E(x^u_{t+1}) \parallel u^t_l \parallel u^t_s ) \big), \tag{27}
$$
$$
u^t = \alpha \cdot u^t_l + (1 - \alpha) \cdot u^t_s, \tag{28}
$$

ここで、$\sigma$ はシグモイド活性化関数、$\tau_f$​ は融合のためのMLPです。  
$\alpha$ は履歴インタラクション、ターゲットアイテム、ユーザーのLS-termの興味に基づいて推定された融合重みを表します。


> [!NOTE] Title
> (27)の式はなぜ $E(x_{t+1}^u)$ なんだろうか。


インタラクションを予測するために、我々は図2 (E) に示された広く用いられる2層MLP [47] を使用します。  
その後、ユーザー $u$ とアイテム $v$ に対して、時刻 $t+1$ における推定スコアは次のように予測されます：

$$
\hat{y}^{t+1}_{u,v} = \text{MLP}(u^t \parallel E(v)). \tag{29}
$$

既存研究 [47] の設定に従い、我々は負の対数尤度損失関数を次のように用います：

$$
L^{u,t}_{rec} = - \frac{1}{N} \sum_{v \in O} \Big( y^{t+1}_{u,v} \log(\hat{y}^{t+1}_{u,v}) + (1 - y^{t+1}_{u,v}) \log(1 - \hat{y}^{t+1}_{u,v}) \Big), \tag{30}
$$

ここで $O$ は、1つの正例アイテム $x^u_{t+1}$​ と $N-1$ 個のサンプリングされた負例アイテムから構成される訓練ペアの集合です。

**我々は2つの目的に基づくマルチタスク学習によってモデルをエンドツーエンドで訓練します。**  
具体的には、目的をバランスするためのハイパーパラメータ $\beta$ を伴う結合損失関数は次のように定式化されます：

$$
L = \sum_{u=1}^M \sum_{t=1}^{T^u} \Big( L^{u,t}_{rec} + \beta L^{u,t}_{con} \Big) + \lambda \|\Theta\|^2, \tag{31}
$$

ここで $\lambda \|\Theta\|^2$ は過学習に対処するための $L_2$​ 正則化を表します。

我々の実装の計算複雑性は $\mathcal{O}((M+N)d + Q)$ であり、ここで $Q$ はMLPおよびGRUの複雑性を示します。これは最先端手法であるSLi-Rec [47] と同等です。

---
## 4 Experiments

提案するコントラスト学習フレームワークの有効性を確認するために、我々は以下の研究課題に答えることを目的とします：

- **RQ1:** 提案フレームワークは最先端の推薦モデルと比較してどのような性能を示すか？
- **RQ2:** CLSR は既存の非教師ありベースラインに対して、より強力なLS-termの興味の分離を達成できるか？
- **RQ3:** CLSR における各コンポーネントはどのような効果を持つか？

#### データセット

我々は、実世界のEコマースおよび動画プラットフォームから収集した2つのデータセット（Taobao¹ と Kuaishou²）で実験を行います。  
2つのデータセットの基本統計量は表1にまとめられており、Average Length はユーザーインタラクション系列の平均長を示します。  
データセットの詳細は付録A.1に記します。

![[Pasted image 20251002142235.png]]

#### ベースラインと評価指標

我々は CLSR を最先端の手法と比較します。

- 長期的興味モデリングに関しては、**NCF [16]**, **DIN [51]**, **LightGCN [14]** を含めます。
- 短期的興味モデリングに関しては、**Caser [41]**, **GRU4REC [17]**, **DIEN [50]**, **SASRec [20]**, **SURGE [6]** を比較対象とします。
- さらに、LS-term の興味モデリングにおける最先端モデルである **SLi-Rec [47]** も含めます。

我々は、2つの広く採用されている精度指標 **AUC** と **GAUC [51]**、および一般的に使われる2つのランキング指標 **MRR** と **NDCG@K** を用いてモデルを評価します。  
ベースライン、実装、ハイパーパラメータの詳細は付録A.2–A.3に記します。

### 4.1 全体的な性能比較（RQ1）

我々は、採用した2つのデータセットにおける全体的な性能を表2に示します。  
結果から、以下の観察が得られます：

![[Pasted image 20250913171803.png]]

- **短期モデルは一般的に長期モデルより優れている。**  
    長期モデルはユーザーインタラクションの時間的パターンを捉えられないため、その性能はかなり低いです。  
    結果から、Taobao データセットでは NCF、DIN、LightGCN の AUC はすべて 0.8 未満であり、Kuaishou データセットでは 0.7 未満です。  
    一方で、短期モデルは多くの場合、長期モデルを上回ります。  
    例えば、SURGE は両方のデータセットにおける最良のベースラインであり、これはグラフ畳み込み伝播とグラフプーリングを用いてユーザー興味のダイナミクスを捉えています。  
    短期モデルの優れた性能は、ユーザーインタラクションの逐次パターンを捉える能力から生じています。  
    実際に我々はインタラクション系列を分析し、平均して 31%以上のインタラクションアイテムが直前のアイテムと同じカテゴリであることを発見しました。  
    これは逐次パターンを裏付けるものであり、短期モデルの優れた性能を説明します。
    
- **LS-term の興味を共同でモデル化することは、常に性能向上をもたらすわけではない。**  
    SLi-Rec は、両方の LS-term の興味をモデル化する最先端手法です。  
    しかし、両側面が絡み合ってしまい、モデルの冗長性を増加させ、精度の低下につながります。  
    結果は、SLi-Rec が異なる指標やデータセットにおいて一貫して有効ではないことを示しています。  
    例えば、SLi-Rec は Taobao データセットにおいて AUC に関して最良のベースラインですが、そのランキング性能は GRU4REC よりも約 10% 劣っています。  
    これは、明示的な監督なしに LS-term の興味を分離することは不十分であることを示しています。
    
- **LS-term の興味を分離してモデル化することは、顕著な改善を達成できる。**  
    CLSR はベースラインを大きく上回る進展を示しました。  
    具体的には、CLSR は最先端手法に対して、Taobao データセットで GAUC を約 0.005（p値 < 0.001）、Kuaishou データセットで 0.01（p値 < 0.05）改善しました。  
    さらに、NDCG は Taobao データセットで約 5% 改善しました。  
    一貫した顕著な進歩は、LS-term の興味を分離することが正確な推薦にとって重要であることを示しています。

SLi-Rec と CLSR はどちらも明示的に LS-term の興味をモデル化します。しかし、**CLSR が最良の性能を達成する一方で、SLi-Rec は精度が劣っています。**  
我々は、その理由が SLi-Rec が LS-term の興味を絡めてしまい、モデルの内部依存性を増加させ、それが性能の低下につながるからであると主張します。  
それとは対照的に、CLSR は自己教師あり学習の助けを借りて LS-term の興味を分離します。  
この節では、CLSR がより強力な LS-term の興味の分離を実際に達成していることを経験的に示します。

#### 4.2.1 片側興味の性能

CLSR では、我々は LS-term の興味に対して2つの独立した表現を利用します。  
したがって、それぞれの側面が望まれる単一の側面だけを捉えることが重要です。

各側面の有効性を評価するために、我々は CLSR および SLi-Rec において、一方の興味のみを保持し、もう一方を破棄します。  
2つのデータセットにおける結果は図3に示されており、すべての場合において CLSR が SLi-Rec を上回っていることが観察されます。

![[Pasted image 20250913172056.png]]

具体的には、Taobao データセットでは、短期的興味と両側面を用いた場合において、CLSR は SLi-Rec に対して AUC を約0.03 改善しました。  
Kuaishou データセットでは、長期的興味、短期的興味、および両側面において、それぞれ約0.1、0.2、0.4 の AUC 改善が見られます。  
これは、CLSR が両方の LS-term の興味に対して、より意味のある表現を獲得していることを示しています。

さらに、両手法とも両データセットにおいて、LS-term の興味を組み合わせることは、片側の興味だけを用いる場合よりも良い性能を達成します。  
これはまた、正確な推薦のために長期的興味と短期的興味の両方をモデル化するという我々の動機を裏付けています。

---

#### 4.2.2 反事実評価

基盤となる要因の分離された表現を学習することは、特に異なる要因の重要性が変化するときに非常に有用です [37, 38, 49]。  
例えば、Taobao データセットにおける購入（お金のコスト）、Kuaishou データセットにおける「いいね」（時間のコスト）のようなより高いコストを伴う行動は、ユーザーの長期的興味によってより駆動される傾向があります。  
一方で、**両データセットにおけるクリックのような低コストの行動は、より短期的興味を示す**ことが既存研究で認められています [11]。

したがって、CLSR が LS-term の興味の分離を達成しているかどうかを調査するために、我々は異なる興味の重要性が変化する反事実評価を設計しました。  
具体的には、クリックデータで十分に訓練されたモデルを用いて、クリックされたアイテムと購入/「いいね」されたアイテムの両方を予測します。このとき LS-term の興味の重要性は異なります。

購入/「いいね」行動はより長期的興味を反映するため、クリックを予測する場合よりも、購入/「いいね」を予測する場合において、長期的興味の重要性が高いはずです。  
言い換えれば、モデルが購入/「いいね」行動を予測するとき、2つの側面を融合する際の長期的興味のアテンション重み、すなわち $\alpha$、はクリック行動を予測する場合よりも大きいことが期待されます。

表3は、クリックされたアイテムおよび購入/「いいね」されたアイテムに対するAUCと $\alpha$ の平均を示しています。我々は以下の知見を得ました：

![[Pasted image 20250913172619.png]]

- **CLSR はすべての行動において SLi-Rec を上回る。**  
    クリックデータで学習されたモデルを用いて購入/「いいね」を予測することは困難ですが、CLSR の AUC は SLi-Rec よりも 0.03 以上有意に大きいです。  
    一方で、CLSR の平均 $\alpha$ はすべての場合においてかなり低く、Kuaishou データセットで平均 $\alpha$ が 0.7 を超える SLi-Rec とは対照的です。  
    実際、CLSR における低い $\alpha$ は、表2 の知見とも一致しており、短期的興味が長期的興味よりも重要であることを示しています。これは、CLSR において LS-term の興味がうまく分離されていることを意味します。  
    逆に、SLi-Rec における高い $\alpha$ は、学習された長期的興味表現が望ましくない短期的興味の情報を多く含んでいることを示しており、すなわち2つの側面が絡み合っていることを意味します。
    
- **購入/「いいね」はクリックよりも長期的興味をより反映するため、購入/「いいね」を予測するときの $\alpha$ はクリックよりも大きいはずである。**  
    Taobao データセットでは、CLSR の購入行動における $\alpha$ はクリックよりも約4% 大きいです。  
    しかし、SLi-Rec では、購入における $\alpha$ がクリックよりも 6%以上小さいです。  
    Kuaishou データセットでは、SLi-Rec と CLSR の両方で「いいね」における $\alpha$ はクリックよりも大きいですが、CLSR の α\alphaα の相対的増加は SLi-Rec の2倍以上です（+9.06% vs. +3.91%）。  
    これは、CLSR がより強力な LS-term の興味の分離を達成していることをさらに裏付けます。

さらに、我々は、インタラクション系列を2つのプロトコル（shuffle と truncate）で再配置することにより、長期的または短期的興味が遮断された特殊なケースにおける評価も行いました（図4に示す）。詳細は以下の通りです：

- **Shuffle:** 履歴系列をランダムにシャッフルします。このプロトコルでは短期的興味が除去されます。
- **Truncate:** 初期の履歴を破棄し、最近の履歴のみを利用します。したがって長期的興味が弱められます。

![[Pasted image 20250913172841.png]]

表4は、2つのデータセットにおける shuffle プロトコル下での結果を示しています。  
シャッフル操作は短期的興味を遮断するため、このプロトコル下では**クリック行動の予測は元の場合よりもはるかに困難となり、一方で購入行動の予測は比較的容易になります。**  
表4と表3を比較すると、この期待と一貫していることが観察されます。

![[Pasted image 20250913172641.png]]

具体的には、SLi-Rec と CLSR の両方で、クリック予測タスクの AUC は 0.04 以上低下し、購入/「いいね」予測タスクの AUC は約0.02 向上しました。  
一方で、CLSR は SLi-Rec に対して、クリック予測の AUC を 0.04 以上改善し、購入予測の MRR を 30%以上改善しました。  
短期的興味がこのプロトコル下で無効化されているにもかかわらず、CLSR は LS-term の興味が分離され、長期的興味が依然として機能するため、より良い性能を達成できます。

さらに、図5(a) には、履歴系列の利用可能長さ $k$ を変化させた場合の truncate プロトコル下における CLSR の結果を示します。  
我々は、購入予測の性能が $k$ の増加とともに大幅に改善することを観察しました。  
一方で、クリック予測の性能は、$k$ が大きくなるにつれて増加はかなり緩やかです。  
この観察結果は、短期的興味は直近の履歴を掘り下げることで効果的に捉えられる一方で、長期的興味に関しては履歴全体を考慮することが不可欠である、という我々の仮定を裏付けます。

さらに、図5(b) には truncate プロトコル下で長期的興味表現のみを用いた場合の性能を示します。  
$k$ が大きくなるにつれて購入予測の精度が急激に向上する一方で、クリック予測の精度はほとんど変化しません。  
**クリックと購入タスクの異なる傾向は、学習された長期的興味表現が望ましい興味のみを捉え、短期的興味を蒸留している**ことを確認します。

まとめると、 LS-term の興味を明示的にモデル化する SLi-Rec と CLSR を比較することで、2つの側面の分離こそが推薦性能向上の理由であることを経験的に示しました。  
さらに、非教師ありの方法で LS-term の興味を分離することは不十分であり、CLSR は自己教師あり学習によってラベルデータ欠如という課題を効果的に克服していることを確認しました。

### 4.3 アブレーションとハイパーパラメータ研究

#### 4.3.1 コントラスト学習

LS-term の興味に対する学習表現と代理の類似性に基づくコントラストタスクは、既存の非教師あり手法よりも強力な分離を達成する助けとなります。  
我々はアブレーションスタディを行い、CLSR の性能をコントラスト損失 $L_{con}$​ の有無で比較しました。  
さらに、短期的興味エンコーダ ψ\psiψ を DIEN に置き換えた場合の性能も評価しました。

図6(a) は Kuaishou データセットにおける結果を示しています。  
コントラストタスクを除去すると CLSR の GAUC が 0.01 以上低下することが分かり、これは自己教師あり学習の必要性を裏付けています。  
一方で、自己教師ありを加えることで DIEN の性能も大幅に改善され、CLSR が既存の推薦モデルに対して LS-term の興味を分離する汎用的なフレームワークとして機能できることを意味します。

また、我々は $L_{con}$​ の異なる損失重みの下での性能も調査しました。  
図6(b) は Kuaishou データセットでの結果を示しており、0.1 が最適値であることが観察されました。  
過度に大きな $\beta$ は主タスクであるインタラクション予測と矛盾し、精度の低下を招く可能性があります。

---

#### 4.3.2 LS-term の興味の適応的融合

CLSR では、ターゲットアイテムと履歴系列に応じて LS-term の興味を適応的に統合することを提案しました。  
ここでは、この適応的融合が有効であるかどうかを検証します。

具体的には、2つの側面を統合する際に固定された $\alpha$ を使用する静的バージョンと比較しました。  
図7は2つのデータセットにおける推薦性能を示しており、破線は適応的融合の性能を表しています。

結果から、適応的融合は固定されたあらゆる値の α\alphaα を上回ることが分かります。  
これらの結果は、LS-term の興味の適応的融合の必要性を裏付けており、我々が提案するアテンションベースのネットワークがこの目的を成功裏に達成していることを示しています。

**結論として、** 我々は広範な実験を行い、提案する CLSR モデルの優れた性能を示しました。  
反事実的評価は、LS-term の興味がうまく分離されていることを実証しました。  
さらに実験結果の詳細は付録 A.4 に記載されています。

---
## 5 Related Work

#### LS-Term Interests Modeling in Recommendation

従来のマルコフ連鎖ベースの手法 [36] および先進的な深層学習モデル [17, 20, 24, 25, 30, 40, 41, 50, 55] は、LS-term の興味を区別することができません。なぜなら、統一された表現ではユーザーの興味を完全に捉えるには不十分だからです。  
したがって、いくつかの手法 [2, 11, 19, 29, 47, 48] が提案され、LS-term の興味を明示的に区別しました。

例えば、Zhao ら [48] は、長期的興味のために行列分解を用い、短期的興味のために RNN を使用しました。  
Yu ら [47] は、短期的興味のために LSTM の変種を開発し、長期的興味のために非対称 SVD [22] を採用しました。  
しかし、これらのアプローチは、**学習された興味表現に対して監督を課していない**ため、LS-term の興味が分離される保証はありません。

既存の非教師ありアプローチとは異なり、我々は長期的および短期的興味のより強力な分離を達成する自己教師あり手法を提案します。

---

#### Self-supervised Learning in Recommendation

自己教師あり学習 [4, 7, 8, 12, 13] は、最近いくつかの推薦アルゴリズム [32, 45, 46, 52] に採用されました。  
例えば、Zhou ら [52] は相互情報最大化に基づく自己教師あり逐次レコメンダを開発しました。  
また、Ma ら [32] は潜在的な意図プロトタイプによって逐次エンコーダを監督することを提案しました。

しかし、これらの手法は、**正確な推薦にとって重要である長期的興味と短期的興味の違いを無視**しています。  
我々の論文では、推薦のために長期的および短期的興味を分離する自己教師あり学習手法を設計しました。

---

#### Disentanglement in Recommendation

推薦における分離表現学習は、最近までほとんど未開拓でした [31, 42, 43, 49]。  
Ma ら [31] は、変分オートエンコーダに基づいてユーザーの複数の嗜好を学習することを提案しました。  
Wang ら [42] は、知識グラフを利用して異なるユーザーの意図を学習し、それらが互いに異なるように正則化しました。

しかし、これらの研究の多くは、ラベル付きデータの欠如、すなわち非教師あり分離であるため、学習された複数の表現に特定の意味を付与することができず、無効であることが示されています [28]。

本論文では、元のインタラクション系列から抽出した学習表現と興味の代理の間にコントラストタスクを設計することで、自己教師ありによって分離を実現することを提案します。

## 6 Conclusion and Future Work

本論文では、コントラスト学習フレームワーク CLSR を用いて、推薦における長期的および短期的な興味を分離することを提案しました。  
2つの大規模データセットに対する広範な実験と反事実的評価により、CLSR が最先端のベースラインを一貫して上回り、顕著な改善を達成することを示しました。

さらに重要な点として、我々は経験的に、非教師ありの LS-term 興味モデリングは両側面が容易に絡み合い、むしろ性能を悪化させる可能性があることを示しました。  
自己教師あり学習の助けを借りることで、CLSR は LS-term の興味を効果的に分離し、はるかに優れた性能を達成できます。

将来の課題として、CLSR は非常に汎用的なフレームワークであるため、容易に拡張可能です。  
例えば、他のエンコーダや代理の設計を探求することができます。  
また、提案手法を産業システムに展開することも、もう一つの重要な将来の課題です。

---

### 謝辞（ACKNOWLEDGMENTS）

本研究は、中国の国家重点研究開発計画（2020AAA0106000）の助成を一部受けています。  
また、中国国家自然科学基金（61972223, U1936217, 61971267, U20B2060）の助成も一部受けています。

---
## Appendix

### A.1 Datasets

我々は実験を行うために2つのデータセットを使用します。1つは公開されているEコマースデータセット、もう1つは産業レベルの短尺動画データセットです。これらは最先端の逐次推薦モデル SURGE [6] においても採用されています。いずれも数百万規模であり、実世界のアプリケーションから収集されたものです。採用したデータセットの詳細は以下の通りです。

- **Taobao³.**  
    このデータセット [54] は、中国最大のEコマースプラットフォームから収集され、推薦研究のベンチマークデータセットとして広く用いられています [34, 53, 54]。  
    2017年11月25日から12月3日までのユーザー行動（クリック、カート、購入）を含んでいます。  
    我々はクリックデータを使用し、非アクティブなエンティティを除外するために 10-core 設定を採用しました。  
    推薦性能を評価するために、12月1日までのすべてのインスタンスを訓練データとして使用します。12月2日のインスタンスを検証用に使用し、12月3日のインスタンスで最終性能を評価します。
    
- **Kuaishou⁴.**  
    この産業データセットは、中国最大級の短尺動画プラットフォームの1つである Kuaishou アプリから収集されました。ユーザーは他のユーザーがアップロードした短尺動画を閲覧できます。  
    我々は 2020年10月22日から10月28日までのログのサブセットを抽出しました。  
    データセットには、短尺動画とのユーザーインタラクション（クリック、いいね、フォロー（購読）、転送）が含まれています。  
    我々はクリックデータを使用し、データ品質を保証するために 10-core 設定を採用しました。  
    最初の6日間のインスタンスを訓練セットとし、最後の日のインスタンスを検証用（12時まで）とテスト用（12時以降）に分けて使用しました。
    

表5は、分割後の2つのデータセットの統計量を示しています。

![[Pasted image 20250913173855.png]]

### A.2  Baselines

我々は、提案手法を以下の競合するレコメンダと比較します：

- **NCF [16]:**  
    この手法は、行列分解と多層パーセプトロンを組み合わせて、ユーザーインタラクションの非線形性を捉える、最先端の汎用レコメンダです。
- **DIN [51]:**  
    この手法は、アテンション機構を用いて履歴インタラクション系列を集約します。アテンション重みはターゲットアイテムに基づいて計算されます。
- **LightGCN [14]:**  
    この手法は最先端のGCNベースのレコメンダであり、近傍集約を利用して協調フィルタリング効果を捉えます。
- **Caser [41]:**  
    この手法はアイテム系列を画像とみなし、畳み込みネットワークを用いて逐次パターンを抽出します。
- **GRU4REC [17]:**  
    この手法は、RNNをセッションベースの推薦システムに初めて適用したアプローチであり、修正されたミニバッチ学習とランキング損失を用います。
- **DIEN [50]:**  
    この手法は DIN を改良し、アテンションと GRU を組み合わせてユーザー興味の逐次パターンをモデル化し、興味の進化も考慮に入れます。
- **SASRec [20]:**  
    この手法は最先端の逐次推薦モデルであり、自己アテンションを利用して逐次的な嗜好を捉えます。
- **SURGE [6]:**  
    この手法は最先端の推薦アプローチであり、グラフ畳み込みネットワーク（GCN）を利用して逐次インタラクションからユーザー興味をモデル化します。
- **SLi-Rec [47]:**  
    この手法は最先端のアルゴリズムであり、非対称SVDを用いて長期的興味を捉え、修正されたLSTMを用いて短期的興味をモデル化します。

### A.3 Implementation Details

我々はすべてのモデルを、TensorFlow [1] に基づく Microsoft Recommenders フレームワーク [3] を用いて実装しました。  
オプティマイザには Adam [21] を使用しました。

埋め込みサイズ $d$ は 40 に設定しました。  
インタラクション推定には隠れサイズ [100, 64] の2層MLPを使用しました。  
MLPにはバッチ正規化を有効にし、活性化関数には ReLU を使用しました。

ユーザーインタラクション系列の最大長は、Taobao データセットでは 50、Kuaishou データセットでは 250 としました。  
我々はグリッドサーチを用いて最適なハイパーパラメータを探索しました。

提案実装における最適な設定は以下の通りです：

- L2 正則化の重み: 1×10−61 \times 10^{-6}1×10−6
- バッチサイズ: 500
- 学習率: 0.001
- $\beta$: 0.1
- $l_t$​: Taobao データセットでは 5、Kuaishou データセットでは 10
- $k$: Taobao データセットでは 3、Kuaishou データセットでは 5
- $L_{con}$: Taobao データセットでは $L_{tri}$​、Kuaishou データセットでは $L_{bpr}$

### A.4 More Studies on the Proposed Method

本節では、提案手法がいくつかの導入したハイパーパラメータの異なる値の下でどのように性能を示すかを調査する実験を行います。さらに、いくつかのコンポーネントに関する追加のアブレーションスタディも含みます。

#### Short-term Proxy $k$

提案手法では、直近の $k$ 個のインタラクションアイテムの平均プーリングを、短期的興味の代理表現として使用します。  
表6は、Taobao データセットにおける異なる $k$ の結果を示します。  
$k=1$ と設定すると、AUC を除いて性能が劣ることが観察されます。これは、短期的興味の代理として最後の1つのインタラクションのみを使用するのは適切ではないことを意味します。なぜなら、1回のインタラクションは大きな確率でノイズとなる可能性があるからです。

![[Pasted image 20250913174318.png]]

#### Interests Evolution

短期的興味は時間に対するダイナミクスの点で長期的興味と大きく異なるため、我々は式(7) において GRU を利用し、短期的興味の進化を模擬するクエリベクトルを生成します。  
我々は興味進化の効果を調査し、その結果を表7に示します。  
興味進化を除去すると、両データセットで精度が大幅に低下することが観察されました。これは、LS-term の興味の異なるセマンティクスをモデル化する必要性を確認するものです。

![[Pasted image 20250913174334.png]]

#### Study of Different Design Choices

我々はさらに CLSR における異なる設計選択肢を比較します。  
具体的には、短期的興味エンコーダおよび式(14) と (25) におけるコントラスト損失関数の異なる選択肢を調査しました。

短期的興味エンコーダ $\psi$ における RNN $\rho$ については、**LSTM [18]**, **GRU [9]**, および SLi-Rec [47] によって提案された **Time4LSTM** を比較しました。  
LconL_{con}Lcon​ に関しては、**BPR loss** と **triplet loss** を比較しました。

表8は異なる設計選択肢の結果を示しています。  
Time4LSTM が両データセットにおいて LSTM や GRU を上回っており、これは時間間隔の特徴が LS-term の興味モデリングに有用であることを示しています。LSTM や GRU はこの点を無視しています。  
コントラスト損失に関しては、どちらの損失関数も一貫して相手を上回ることはできませんでした。これは2つのデータセットのスケールの違いによって説明できます。  
実際、CLSR は非常に汎用的なフレームワークであり、多くの逐次エンコーダや損失関数を利用できます。さらなる研究は将来の課題とします。

![[Pasted image 20250913174428.png]]

#### Fusion Predictor GRU

提案するアテンション技術に基づく適応的融合モデルでは、次のインタラクションが長期的興味または短期的興味によって駆動されるかを予測するために、ターゲットアイテムと履歴系列の両方を組み込みます。  
具体的には、履歴系列を入力とする独立した GRU を採用し、その最終状態を MLP の入力として使用しました。

我々は、履歴系列を考慮することが必要であるかどうかを調査しました。表9は、Fusion Predictor GRU を有無で比較した提案手法の結果を示しています。  
Fusion Predictor GRU を除去すると推薦性能が大幅に低下することが観察され、長期的または短期的興味の重要性が履歴系列によって大きく決定されることを確認しました。

![[Pasted image 20250913174507.png]]

#### Attentive Encoder

式(11) で導入したように、提案するアテンションエンコーダは MLP を用いてアテンション重みを計算します。  
MLP の入力は、キー ベクトル、クエリ ベクトル、キーとクエリの要素ごとの差分、および積から構成されます。  
我々は MLP ベースのアテンションと単純な内積を比較しました。表10はその比較を示しています。  
結果は、MLP ベースのアテンションが内積ベースのアテンションを大きな差で上回ることを示しており、これはユーザー興味と履歴系列の関係が非線形であり、内積のような線形演算子では十分に捉えられないことを意味します。

![[Pasted image 20250913174529.png]]

#### Discrepancy Supervision

我々の提案手法では、他の研究 [43, 49] のように、LS-term の興味を互いに独立させるための追加的な差異損失を導入していません。  
なぜなら、自己教師あり学習だけで分離を達成するのに十分であると考えているからです。

実験中に、2つの興味の間に独立損失を追加してみましたが、AUC が 0.01 低下しました。これは我々の主張を裏付けます。  
また、多くの既存研究 [5, 32, 44] も独立損失を使用していないことに注意する価値があります。

#### More Counterfactual Evaluations

図8は、Kuaishou データセットにおけるクリックと「いいね」の AUC を、利用可能な履歴長 $k$ を 50 から 250 に変化させた場合について示しています。  
結果は Taobao データセットにおける図5(a) の結果と一致しています。

具体的には、「いいね」の AUC は利用可能履歴の長さに対してより敏感であり、$k$ が増加するにつれて急激に改善します。  
一方で、クリックの AUC は $k$ を増加させてもあまり改善しません。  
「いいね」がユーザーの長期的興味をより反映するため、ユーザーインタラクション系列全体にアクセスすることが必要です。  
一方で、クリックは短期的興味を多く反映しており、直近の履歴からほとんど捉えられるため、初期の履歴に遡っても追加的な改善は得られません。


![[Pasted image 20250913174633.png]]

#### Complexity

我々は1枚のGPUを用いて複雑性を比較しました。  
Taobao データセットにおける CLSR と代表的ベースラインの学習時間は表11に示されています。  
CLSR のパラメータ規模は SLi-Rec と同等であり（どちらも 4.1GB のGPUメモリを使用）、計算資源の観点からも実用的です。

![[Pasted image 20250913174719.png]]
