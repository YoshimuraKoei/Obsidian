# データポイズニング攻撃：因子分解ベース協調フィルタリングに対する攻撃

## 要約

推薦システムと協調フィルタリングシステムは、現代の情報技術と e コマースアプリケーションにおいて重要である。これらのシステムが産業界でますます普及するにつれて、その出力はビジネス意思決定に影響を与える可能性があり、敵対的攻撃者がそのようなシステムの可用性や整合性を損なうためのインセンティブを生み出している。我々は協調フィルタリングシステムに対するデータポイズニング攻撃を導入する。我々は、学習者の完全な知識を持つ強力な攻撃者が、通常のユーザー行動を模倣して検出を回避しながら、悪意のある目的を最大化するために悪意のあるデータを生成する方法を示す。完全な知識の仮定は極端に見えるが、それは協調フィルタリング手法の高度に動機付けられた攻撃に対する脆弱性の堅牢な評価を可能にする。我々は、2 つの人気のある因子分解ベース協調フィルタリングアルゴリズムに対する効率的な解決策を提示する：交互最小化定式化と核ノルム最小化法である。最後に、我々は実際のデータに対する提案アルゴリズムの有効性をテストし、潜在的な防御戦略について議論する。

## 1. 序論

協調フィルタリング（CF）は、推薦システムの最も成功したアプローチの 1 つである。CF システムは、ユーザーの過去の行動パターンに基づいて、ユーザーが好む可能性のあるアイテムを推薦する。これらのシステムは、オンライン小売、コンテンツ配信、ソーシャルネットワークなど、多くのアプリケーションで広く使用されている。

CF システムの成功により、これらのシステムの出力はビジネス意思決定に影響を与えるようになり、敵対的攻撃者がこれらのシステムを操作しようとするインセンティブを生み出している。例えば、競合他社は、自社の製品をより有利に見せるために推薦システムを操作しようとする可能性がある。

この論文では、因子分解ベース協調フィルタリングシステムに対するデータポイズニング攻撃を研究する。データポイズニング攻撃では、攻撃者は学習プロセス中に悪意のあるデータを注入し、学習されたモデルの性能を低下させることを目的とする。

## 2. 関連研究

### 2.1 協調フィルタリング

協調フィルタリングは、ユーザーの過去の行動に基づいて推薦を行う手法である。主なアプローチには以下がある：

- **メモリベース手法**：ユーザー間またはアイテム間の類似性に基づく
- **モデルベース手法**：潜在因子モデルや行列因子分解に基づく

### 2.2 敵対的機械学習

敵対的機械学習は、機械学習モデルに対する攻撃と防御を研究する分野である。主な攻撃タイプには以下がある：

- **推論時攻撃**：学習済みモデルに対する攻撃
- **学習時攻撃**：学習プロセス中の攻撃（データポイズニング）

## 3. 問題設定

### 3.1 システムモデル

我々は、ユーザー-アイテム評価行列 $R \in \mathbb{R}^{n \times m}$ を考える。ここで、$n$ はユーザー数、$m$ はアイテム数である。$R_{ij}$ は、ユーザー $i$ がアイテム $j$ に与えた評価を表す。

### 3.2 攻撃モデル

攻撃者は、学習プロセス中に悪意のあるデータを注入することを目的とする。攻撃者の目標は、特定のアイテムの推薦順位を操作することである。

## 4. 攻撃手法

### 4.1 交互最小化攻撃

交互最小化（AM）は、行列因子分解問題を解決するための一般的な手法である。AM 攻撃では、攻撃者は以下の最適化問題を解決する：

$$\min_{P,Q} \sum_{(i,j) \in \Omega} (R_{ij} - P_i^T Q_j)^2 + \lambda(\|P\|_F^2 + \|Q\|_F^2)$$

ここで、$P \in \mathbb{R}^{n \times d}$ と $Q \in \mathbb{R}^{m \times d}$ は潜在因子行列である。

### 4.2 核ノルム最小化攻撃

核ノルム最小化（NNM）は、低ランク行列補完のための別の手法である。NNM 攻撃では、攻撃者は以下の最適化問題を解決する：

$$\min_X \|X\|_* + \frac{\lambda}{2} \sum_{(i,j) \in \Omega} (R_{ij} - X_{ij})^2$$

ここで、$\|X\|_*$ は行列 $X$ の核ノルムである。

## 5. 実験結果

### 5.1 データセット

我々は、MovieLens-100K と MovieLens-1M データセットを使用して実験を行った。

### 5.2 攻撃効果

実験結果は、提案された攻撃手法が推薦システムの性能を大幅に低下させることを示している。

## 6. 防御戦略

### 6.1 異常検出

攻撃データを検出するための異常検出手法を提案する。

### 6.2 ロバスト学習

攻撃に対して堅牢な学習アルゴリズムを開発する。

## 7. 結論

この論文では、因子分解ベース協調フィルタリングシステムに対するデータポイズニング攻撃を研究した。我々は、交互最小化と核ノルム最小化の両方に対する効率的な攻撃手法を提案し、実際のデータセットでその有効性を実証した。また、潜在的な防御戦略についても議論した。

## 参考文献

[1] Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30-37.

[2] Biggio, B., & Roli, F. (2018). Wild patterns: Ten years after the rise of adversarial machine learning. Pattern Recognition, 84, 317-331.

[3] Li, B., Wang, Y., Singh, A., & Vorobeychik, Y. (2016). Data poisoning attacks on factorization-based collaborative filtering. Advances in Neural Information Processing Systems, 29, 1885-1893.
