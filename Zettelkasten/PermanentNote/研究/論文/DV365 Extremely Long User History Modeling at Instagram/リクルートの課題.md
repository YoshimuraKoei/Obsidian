
> 背景
> ● 最近の推薦/検索システムでは、超長期にわたるユーザー行動履歴の活用がトレンドとなっている 
> 	○ e.g, Instagram, LinkedIn, Pinterest, Zalando 
> ● Indeedでは、超長期のユーザー行動履歴を埋め込み（Embedding）化した特徴量を下流 の検索システムで利用することで、再ランキング（Re-ranking）性能が向上した事例が でてきた
> 	● リクルートでも、同様の取り組みができないか検討したい 
> 
> 従来のユーザ行動履歴の活用法 
> ● 集約: 過去7日、14日、90日以内の各属性のクリック数、応募数などを集計 
> ● One-hot encoding 
> 
> 従来手法の課題 
> ● 集約によって、ユーザー行動の順序情報が失われる 
> ● 各属性を個別に集約するため、ジョブと属性の関連情報が失われる 
> ● すべてのアクションを同じ重みで扱うため、ノイズが混入しやすくなる 
> ● 属性の重複排除により、強調すべき属性の重要性が薄れてしまうことがある 
> ● 「N日以内」といった古いデータの削除により、長期的な履歴情報が失われる
> 
> 取り組みのゴール 
> ● 現状の7日、14日、90日以内などのユーザー行動履歴の単純な集約やOne-hot encoding にとどまらず、すべてのユーザー行動履歴を活用し、行動ノイズを削減しつつ重要な行動が強調された埋め込みを作成することを目指す 
> ● 作成した埋め込みを推薦モデルの入力とした際に、オフラインでの性能が改善すること を確認する



> [!NOTE] 各属性を個別に集約するため、ジョブと属性の関連情報が失われる課題の解説
> 従来の集計（例：過去90日で _勤務地=東京 のクリック数_、_職種=バックエンド のクリック数_…を別々にカウント）だと、
> - **ジョブ × 属性** の共起が壊れる
> - **属性 × 属性** の共起が壊れる
> 
> **例**
> ユーザーのクリック履歴：
> - J1 = {東京, バックエンド, Python, リモート, 600万} … 3回クリック
> - J2 = {東京, バックエンド, Java, 出社, 600万} … 2回クリック
> 
> 属性別カウントだけを残すと：
> - 東京=5、バックエンド=5、Python=3、Java=2、リモート=3、出社=2、600万=5
> 
> → ここからは **「東京×バックエンド×Python×リモート」が好き** という“組み合わせ”嗜好が見えない。Ranking で候補 J4={東京, バックエンド, Java, リモート, 600万} を評価するとき、**Pythonでなくても良さそう**に見えてしまう＝誤推定の温床。
> → さらに「データサイエンス職ならリモート希望だが、バックエンドなら出社でもOK」といった **条件付き嗜好** も、個別カウントでは表現できない。


> [!NOTE] 属性の重複削除？
> **“繰り返し”や“強調度合い”を表現できない**？
> ex. 10回連続「勤務地=東京」の履歴、10回連続「勤務地=東京」 「形式=リモート」 など


- **順序情報が失われる**  
	→ ✖ **未解決**
	Multi-Slicingのなかのtime-slicingによりサブ系列に分けてはいるが、順序ごとに重みをつけるなど、順序情報を気にしているわけではない。それは長期的な履歴は時間と共に急激に変化するものではないという**安定的関心仮説**に基づく。
    
- **ジョブと属性の関連が失われる**  
    → ✅ **解決？**  
    Multi-slicingで属性ごとの系列を保持できる、さらに同一ID（job id, author id, media id）を別embedding tableで扱う設計
    
- **すべてのアクションを同じ重みで扱ってしまう**
    → ✅ **解決**  
    dwell time, watch ratio, debiased score などの **重み付き特徴量** でノイズを抑制
    
- **属性の重複排除で重要性が薄まる**  
    → 🔶 **部分的に解決**  
    embedding table sharingで特徴ごとに「学習フォーカス」を与えることで冗長性を避けつつ重要性を保持。ただし、「重複排除」という処理自体をやめているわけではないので、完全解決ではなく**改善**に近い
    
- **古いデータの削除で長期履歴が失われる**  
    → ✅ **解決**  
    7万件レベルの長期履歴をオフライン埋め込みとして保持可能。時間バケット（3日、7日、フル）も並行で利用


> [!NOTE] 研究アイデア？
> InstagramなどのSNSでの趣味・嗜好は安定的関心仮説にある程度基づいていると考えられるが、リクルートの求人・求職はそうだろうか？


- 数カ月から1年以内がメイン？
	- リクルートさん側の時間感覚が気になる、どのぐらいの長さの履歴を使いたいか
- ユーザーの関心がどう移り変わっているかの埋め込み
	- 具体的な例も聞きたい

**ネクスト**
- 実際どうやっていくのか
	- ダイナミックな埋め込みは例としてあるはずなので、取り入れてくる
	- 他のリクルートさん側が提案してくれたLinkedInやPinterestなども見てみると良いかも
	- **簡易的な既存研究の再現**
		- 他の埋め込みの論文を見てみる
		- GitHubのコードがない → ベースライン手法
- **資料をまとめて提案**：1週間以内
	- 「安定的関心仮説に基づかないダイナミックな埋め込み」
- Slackで質問事項など
	- 方向性どうか
	- データの問題
		- (公開データセットとかでも)手頃なデータセットがあるか？
- TSUBAME を使えるようにする
	- Linux 関連
	- スパコンはプログラムの実行のさせ方が違う → wiki参照
		- 無料と有料があり、有料の方で使える
		- アカウント作ったら小林先生に報告 ← 渡辺、永井さん、山尾さんに聞くと良い


 下記、リクルート側への提案書
 
---

【提案内容】
✕：安定的関心仮説に基づかないジャンルにおける、ユーザーの長期的な履歴活用のための動的な埋め込み
〇：**Indeed で精度が上がった要因(現在は不明)を DV365 に組み込む形で手法を拡張する**

- ex. 
	- ①安定的関心仮説が成り立つユーザーと成り立たないユーザーがいる？ → 安定的関心仮説の成り立つユーザー / 成り立たないユーザー の取り扱い
	- ②属性の中で、安定的関心仮説が成り立つ属性(または組み合わせ)がある？ → 成り立つ属性 / 成り立たない属性 の取り扱い
	- ③データが増えたことによりモデリング性能が向上したから？ → 長期的な履歴活用法はMetaを組み込んだうえで、他の課題に取り組むことで新規性を出す

【背景】
Metaの論文：DV365 Extremely Long User History Modeling at Instagram
では**安定的関心仮説に基づいたユーザーの超長期的な履歴の活用**を行っていた。具体的には、オフライン学習において70,000件の履歴を全て等しく扱うことで安定的な関心をユーザー埋め込みによって捉えることで、リアルタイム推薦での精度を上昇させていた。

> [!NOTE] DV365の簡単な流れ
> 1. 各ユーザーの最大70,000件規模の履歴をルールベースでマルチスライシングし、200個の部分系列(特徴量)を作る
> 2. 各部分系列に対してプーリングを行うことで1本の代表ベクトルに変
> 3. Funnel Summarization Arch(FSA)と言う仕組みで圧縮し、最終的な埋め込みを作成
> 	- Funnel Transformer と LCE(Linear Compressed Embedding) の並列処理
> 4. 下流モデルをバックボーンとしてFSAの部分を学習

![[Pasted image 20250827105508.png]]

この研究をリクルートさん側の課題に当てはめると...

> 1. 集約によって、ユーザー行動の順序情報が失われる 
> 2. 各属性を個別に集約するため、ジョブと属性の関連情報が失われる 
> 3. すべてのアクションを同じ重みで扱うため、ノイズが混入しやすくなる 
> 4. 属性の重複排除により、強調すべき属性の重要性が薄れてしまうことがある 
> 5. 「N日以内」といった古いデータの削除により、長期的な履歴情報が失われる

これらのうち、
1 → 未解決：スライシングで集計するのみ
2 → 未解決：スライシングで集計するのみ
3 → **解決？**：重み付き特徴量を定義できる
4 → **解決**：スライシングで集計する際、重複を排除せず集計できる
5 → **解決**：根本の問題
となると思われる。

【質問・相談事項】
超長期的な履歴の活用について、「Indeedの方で超長期的な履歴を活用することで精度が上がった事例があったから」というモチベーションだと認識したが...

- **Indeed における ｢超長期的期間｣ が実際どれくらいの期間を想定しているか**
- **安定的関心仮説が成り立たなそうに見える設定で超長期的履歴を考慮してなぜ性能が改善されたのかの解釈**
- データセットについて：使えそうな手ごろなデータセットがあるか(公開データセットとかでも)

