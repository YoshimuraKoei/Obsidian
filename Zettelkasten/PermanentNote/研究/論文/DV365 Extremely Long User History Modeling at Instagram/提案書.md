---
aliases:
---

[[DV365 Extremely Long User History Modeling at Instagram.pdf]]
[[Zettelkasten/PermanentNote/研究/論文/DV365 Extremely Long User History Modeling at Instagram/日本語訳+補足|日本語訳+補足]]

【提案内容】
✕：安定的関心仮説に基づかないジャンルにおける、ユーザーの長期的な履歴活用のための動的な埋め込み
〇：**Indeed で精度が上がった要因(現在は不明)を DV365 に組み込む形で手法を拡張する**

- ex. 
	- ①安定的関心仮説が成り立つユーザーと成り立たないユーザーがいる？ → 安定的関心仮説の成り立つユーザー / 成り立たないユーザー の取り扱い
	- ②属性の中で、安定的関心仮説が成り立つ属性(または組み合わせ)がある？ → 成り立つ属性 / 成り立たない属性 の取り扱い
	- ③データが増えたことによりモデリング性能が向上したから？ → 長期的な履歴活用法はMetaを組み込んだうえで、他の課題に取り組むことで新規性を出す

【背景】
Metaの論文：DV365 Extremely Long User History Modeling at Instagram
では**安定的関心仮説に基づいたユーザーの超長期的な履歴の活用**を行っていた。具体的には、オフライン学習において70,000件の履歴を全て等しく扱うことで安定的な関心をユーザー埋め込みによって捉えることで、リアルタイム推薦での精度を上昇させていた。

> [!NOTE] DV365の簡単な流れ
> 1. 各ユーザーの最大70,000件規模の履歴をルールベースでマルチスライシングし、200個の部分系列(特徴量)を作る
> 2. 各部分系列に対してプーリングを行うことで1本の代表ベクトルに変換
> 3. Funnel Summarization Arch(FSA)と言う仕組みで圧縮し、最終的な埋め込みを作成
> 	- Funnel Transformer と LCE(Linear Compressed Embedding) の並列処理
> 4. 下流モデルをバックボーンとしてFSAの部分を学習

![[Pasted image 20250827105508.png]]

この研究をリクルートさん側の課題に当てはめると...

> 1. 集約によって、ユーザー行動の順序情報が失われる 
> 2. 各属性を個別に集約するため、ジョブと属性の関連情報が失われる 
> 3. すべてのアクションを同じ重みで扱うため、ノイズが混入しやすくなる 
> 4. 属性の重複排除により、強調すべき属性の重要性が薄れてしまうことがある 
> 5. 「N日以内」といった古いデータの削除により、長期的な履歴情報が失われる

これらのうち、
1 → 未解決：スライシングで集計するのみ
2 → 未解決：スライシングで集計するのみ
3 → **解決？**：重み付き特徴量を定義できる
4 → **解決**：スライシングで集計する際、重複を排除せず集計できる
5 → **解決**：根本の問題
となると思われる。

【質問・相談事項】
超長期的な履歴の活用について、「Indeedの方で超長期的な履歴を活用することで精度が上がった事例があったから」というモチベーションだと認識したが...

- **Indeed における ｢超長期的期間｣ が実際どれくらいの期間を想定しているか**
	- 現状：90日前 → 
	- なんとなく見る需要、就職の意思関係なく
	- 競合調査
	- **短期的な人たちと長期的な人たち向けでいいとこどり**
- **安定的関心仮説が成り立たなそうに見える設定で超長期的履歴を考慮してなぜ性能が改善されたのかの解釈**
	- 2%改善と大きい
	- → 使っていない情報を使えている？特徴量頑張るよりも効果が大きそう
	- 長期的な履歴を扱えるようにしておきたい
- データセットについて：使えそうな手ごろなデータセットがあるか(公開データセットとかでも)
	- 公開
		- [Yahooのランキングのヤツ]([https://huggingface.co/datasets/YahooResearch/Yahoo-Learning-to-Rank-Challenge](https://huggingface.co/datasets/YahooResearch/Yahoo-Learning-to-Rank-Challenge))
		- MovieLens?
		- 学会コンペ系(Recsys, KDD)
		- Industry以外の探す
	- 実データ
		- ホットペッパーなど
	- 特徴量
		- ユーザーID
		- 閲覧商品
		- タイムスタンプ(期間)



---
- dynamic / static 
	- 安定仮説が成り立たない or 成り立つ
	- 直近の特徴量抽出
	- 動的な興味の変化に適応する既存のレコメンドシステム
		- long-term vs short-term preference(interest) うまく取り入れる
		- temporal

ネクスト
- データセットを探す
- 手法を考える = 良いとこどり


[https://www.sciencedirect.com/science/article/pii/S147403462200221X](https://www.sciencedirect.com/science/article/pii/S147403462200221X)
[https://dl.acm.org/doi/abs/10.1145/3485447.3512098](https://dl.acm.org/doi/abs/10.1145/3485447.3512098)
[https://dl.acm.org/doi/abs/10.1145/3079628.3079670](https://dl.acm.org/doi/abs/10.1145/3079628.3079670)

https://dl.acm.org/doi/pdf/10.1145/3485447.3512098

![[Pasted image 20250912175023.png]]

WebConf

コード：
https://github.com/tsinghua-fib-lab/CLSR

次回MTGまでに
- 取り入れることが出来るか？
- データセットどうか？


やること
- データセットはリクルートがやりたいことに使えそうだろうか？
	- Taobao: https://tianchi.aliyun.com/dataset/649?lang=en-us → 9日間
	- Kuaishou: 2022/04/08 ~ 2022/05/08
	- RetailRocket (kaggle): https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset/data → 
- やりたいことってなんだっけ？
- この手法(CLSR)は取り入れることが出来るか？
	- CLSR：https://github.com/tsinghua-fib-lab/CLSR/blob/main/tests/resources/deeprec/sequential/README.md
	- DV365との関係性はどう？


---
###### taobaoデータセット

**基本情報**
- データ形状：(100,150,807, 5)
- メモリ使用量：7,942.66 MB

**カラム**
- user_id (987,994)
- item_id (4,162,024)
- category_id (9,439)
- behavior_type (pv, buy, cart, fav)
	- pv: 89.59%
	- cart: 5.52%
	- fav: 2.88%
	- buy: 2.01 %
- timestamp (UNIX)
	- 2017年11/25 ~ 12/03 のデータ

---
##### Retailrocket recommender system dataset
Ecommerce data: web events, item properties (with texts), category tree

行動データ（events.csv）、アイテムプロパティ（item_properties.сsv）、そしてカテゴリツリー（category_tree.сsv）を記述したファイル

- 4カ月半のデータ
- イベント
	- view: 2,664,312
	- addtocart: 69,332
	- transaction: 22,457
