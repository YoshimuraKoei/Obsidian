
第2回リクルートMTGから提案されたネタ
https://nakata-lab-2020.slack.com/archives/C03NSQVLL8N/p1755494508873879?thread_ts=1752491588.962969&cid=C03NSQVLL8N
---
## 論文詳細

👉 この論文は **学術誌 (journal)** ではなく、データマイニング分野のトップ国際会議 **KDD (ACM SIGKDD)** に採択された **会議論文 (conference paper)** です。

> [!NOTE] 
> 要約すると、「Meta × OpenAI × 独立研究者の共著」で、「KDD 2025 (Toronto) に発表された会議論文」である。

**📝CCS**
Information systems → Personalization; Recommender systems
↓
	情報システム (Information Systems) の分野に属し、その中でも **パーソナライゼーション** ./scriptや **レコメンダシステム** に関連する研究

**✍KW**
- ユーザーモデリング：User modeling
- 表現学習：Representation Learning
- ユーザー埋め込み：User Embedding
- 長期ユーザー系列モデリング：Long User Sequence Modeling
- 推薦システム：Recommender System

**📑 著者 (Authors)**
- Wenhan Lyu (Meta Platforms, Inc.)
- Devashish Tyagi† (OpenAI)
- Yihang Yang (Meta Platforms, Inc.)
- Ziwei Li (Meta Platforms, Inc.)
- Ajay Somani† (Independent, New York, USA)
- Karthikeyan Shanmugasundaram (Meta Platforms, Inc.)
- Nikola Andrejevic (Meta Platforms, Inc.)
- Ferdi Adeputra (Meta Platforms, Inc.)
- Curtis Zeng (Meta Platforms, Inc.)
- Arun K. Singh (Meta Platforms, Inc.)
- Maxime Ransan (Meta Platforms, Inc.)
- Sagar Jain†∗ (Independent, Menlo Park, USA)

**📚 ジャーナル / 出版情報**
- 会議 (Conference Proceedings):
    Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’25)
- 開催地: Toronto, ON, Canada
- 開催日程: August 3–7, 2025
- 出版社: ACM (Association for Computing Machinery)
- ISBN: 979-8-4007-1454-2/2025/08
- DOI: [10.1145/3711896.3737209](https://doi.org/10.1145/3711896.3737209)

---
## Abstract

長期的なユーザ履歴はレコメンダシステムにとって非常に価値のあるシグナルであるが、それを効果的に組み込むことは、**データセンターの電力消費**や**GPUコストの面で高額**になることが多い。本研究では、コスト効率の高い解決策として、エンドツーエンドの系列長最適化手法ではなくオフライン埋め込みを選択し、ユーザの長期的かつ安定した興味を高い汎化性で表現する新しいユーザ埋め込み学習戦略「マルチスライシング & サマリゼーション（multi-slicing and summarization）」を提案する。我々の埋め込みでは最大70,000件、平均40,000件の履歴を符号化できる。この埋め込み（DV365と命名）は、Instagramに導入されている高度な注意機構を用いたユーザ系列モデルの上でも大きな追加効果を示した。単一の上流基盤モデルによって生成され、InstagramおよびThreadsにおける15の異なるモデルに導入され、大きな影響を与えた。初回導入から1年以上の本番環境での運用実績があり、その有効性が証明されている。

> [!NOTE] 理想実現のための課題
> - **理想：長期的なユーザー履歴をレコメンドシステムに取り込みたい**
> - **課題：コストが高くなる**
> 	- データセンターの電力消費
> 	- GPUコスト

---
## 1. Introduction

大規模なレコメンデーションシステムは、強いビジネス上のニーズに駆動され、急速に進化している。ビジネス的に最も重要なレコメンデーションモデルは、長年にわたってスケールアップされてきたが、その多くは高コストな大規模モデルである。**これらのモデルは、学習時も推論時もリソースを大量に消費し、特徴量抽出のようなサポートシステムも含めて負担が大きい。** 組織はすべてリソースに制約があり、キャパシティ予算だけでなく、市場におけるGPU供給の限界にも縛られている。そのため、我々は**投資対効果**（ROI: return on investment）を意識しながら慎重にモデルを拡張する必要がある。

Alibaba [10] や Kuaishou [2] の先行研究が示したように、我々もまた、ユーザ履歴の長さを拡張することがレコメンデーション品質を改善する有力な方向性であると見出した。**現在Instagramにおいては、レコメンデーションモデルが利用できるユーザのエンゲージメント履歴は最大で2,000件に制限されており**、その制約は特徴量の保存・抽出・処理コストに起因している。我々の最も高度なモデルでは、最大500件のユーザ履歴を強力ではあるが高コストな注意機構ベースの系列エンコーダ HSTU [16] によって符号化している。しかし、このアプローチは学習および推論時のGPUコストがボトルネックになっている。

既存モデルにおいて単純に系列長を拡張することは選択肢にならない。なぜなら、長年の改良を経てすでにROIの限界に達しているうえ、HSTUのような注意機構ベースの系列モデルは系列長のスケーリングに関してよく知られた課題を抱えているからである。我々の前に残された選択肢は2つある：

1. 系列長最適化手法を用いたエンドツーエンド（E2E）モデルの再設計 [1][2][11][10][12]
2. 長期ユーザ履歴を事前学習によってユーザ埋め込みへと変換し、それを下流モデルに特徴量として転移すること


> [!NOTE] **なぜ 2 が課題解決に繋がるのか？**
　直接「70,000件の系列」をHSTUに入れるのではなく、  長期履歴を「圧縮ベクトル（ユーザ埋め込み）」にまとめることで、**系列長のボトルネックを回避**できる。
> - HSTUに直接「70,000件」を突っ込むとGPUがパンクする。
> - でも「70,000件 → 埋め込み」にすれば、下流モデルが見るのは「数百次元の固定ベクトル」なので、  計算量は系列長に依存せず一定になる。


我々は以下の理由から、**オフライン埋め込みアプローチを採用する**ことにした：

1. **野心的な系列長スケーリングの実現**  
    推薦品質の向上をできる限り引き出すことを目標とし、最終的に最大70,000件、平均40,000件の結合系列長をスケーリングすることに成功した。
2. **安定的関心（Stable Interest）仮説**  
    ユーザの関心は **「新たに出現する関心（emerging interest）」と「安定した関心（stable interest）」から構成されると仮定** する。長期ユーザ履歴の主な増分価値は安定した関心にあり、これは時間とともに急激に変化するものではないため、オンライン学習を有効化した本番モデルに比べ、**更新頻度の低い再学習で十分**である。
3. **クロスドメインでの知識共有**
    Instagramでは、Reels、Feed、Explore、Stories といった多様なプロダクトサーフェスや、Retrieval、初期ランキング（ESR）、後期ランキング（LSR）など複数の推薦ステージに対応する20以上のモデルが稼働している。これは多くの組織に共通する状況である。高コストな長期履歴計算を一度だけ行い、その結果をすべてのモデルで共有できることは、ROIの観点で極めて重要である。
4. **特徴量インフラコストの削減** 
    E2E（エンドツーエンド）手法では、すべての推薦リクエストごとに極めて長い系列をリアルタイムで取得・処理する必要があり、これは高コストである。オフライン埋め込み手法ではこのコストを削減できる。

本研究では、**DV365** というコードネームの**オフラインユーザ埋め込み手法を導入**する。DV365は「マルチスライシング & サマリゼーション（Multi-slicing and Summarize, MSS）」戦略を用いて、ユーザの極めて長い履歴をユーザ埋め込みにエンコードする。我々が扱う規模を考慮すると、長系列に対して注意機構ベースのモデルは適用せず、マルチスライシングで長系列を複数のサブ系列に分割し、それらをプーリングする。マルチスライシングとプーリングによって200個のプーリング済み埋め込みを生成する。さらに、それらを凝縮した埋め込みに変換するために **Funnel Summarization Arch（FSA）** というユーザエンコーダを設計した。このユーザエンコーダモジュールは、Instagram本番のLSRモデルに類似したバックボーンシミュレーションネットワークに組み込まれており、E2Eユーザエンコーダの共同学習を模擬することで、プロダクションモデルにより一貫した埋め込みを提供できるようになっている。


> [!NOTE] E2Eとは
> - **定義（一般的な意味）**  
> 	- 入力（例：ユーザの行動履歴）から出力（例：推薦スコア）までを **1つの統合モデル** が直接学習する手法。  
> 	- 中間処理（特徴量設計・埋め込み生成など）を人間が別途やらず、モデルが「最初から最後まで」最適化する。
> - **DV365論文での意味**  
> 	- 「ユーザの長期履歴を、別に圧縮して埋め込みにせず、**そのままモデルに食わせて直接学習する**」やり方を指しています。  
> 	- つまり「RetrievalやRankingのモデルに、最初から70,000件の履歴を入力して最適化する」アプローチ。

我々の上流モデルは、新しい学習データを取り込むために定期的に学習・公開され、30億ユーザ分の「ユーザ → 埋め込み」ペアをキーバリューストアに保存し、下流モデルで利用される。すべてのオフライン埋め込み手法には以下の制約があるが、本研究では DV365 が実用的な解決策であることを示す。


> [!NOTE] Key-Value Store
> **データベースの一種**で、  「キー (Key)」と「値 (Value)」の組み合わせでデータを保存・検索する仕組み。
> ex. 
> - **キー** = ユーザID（例: user_123）
> - **値** = そのユーザの埋め込みベクトル（例: [0.12, -0.87, …]）


1. **鮮度（Freshness）**: 推薦品質においてモデルの鮮度は極めて重要であり、新しいデータ分布をタイムリーに捉える必要がある [4]。Instagram では、最も重要なモデルの多くがオンライン学習 [13] を有効化して鮮度を最大化している。E2E 学習と比較すると、オフライン埋め込みは不可避的に「ユーザ履歴がエンコードされる時点」と「推薦判断で信号として利用される時点」との間に遅延を伴う。この課題を軽減するために、**我々は埋め込みモデルの目的関数を「安定した関心（stable interest）」にフォーカスするよう設計**した。これは時間の経過で大きく変わらないため、鮮度が低くても頑健である。我々は実証的に、モデルの遅延が増加しても DV365 の埋め込み品質はほぼ劣化しないことを確認した。
    
2. **知識転移効率と汎化性（Knowledge Transfer Efficiency and Generalizability）**: 本番モデルで E2E に直接学習されたユーザエンコーダと比較すると、オフラインモデルから転移された知識には**不可避的に損失が伴う。** 我々の目標は、単一の基盤モデルから複数の下流モデルに埋め込みを提供することであるため、この知識損失は汎化性に課題をもたらす。我々はこの問題に対し、クロスサーフェスデータを用いた汎用的な方法で埋め込みを学習し、下流モデルにはドメイン適応のための適応モジュールを追加することで対応した。15 の下流モデルへの適用において大幅な品質改善を確認し、この方法の実現可能性を証明した。


> [!NOTE] オフライン埋め込みのよくある課題
> 1. 鮮度 → 安定した関心にフォーカスして学習することで問題ナシ
> 2. 損失 → クロスサーフェスデータを用いた汎用的な方法で埋め込みを学習


我々の貢献は以下の通りである。

- 第一に、マルチスライシング＆サマリゼーションに基づくユーザ埋め込み学習戦略を導入し、HSTU のような最先端のユーザモデリングコンポーネントを備えた本番モデルに対しても大きな付加価値をもたらす埋め込みを生成できることを示した。これにより、極めて長いユーザ履歴から知識を引き出したいレコメンデーションシステムにとって、**オフライン埋め込みが高 ROI の解決策であることを証明**した。
- 第二に、DV365 埋め込みを Instagram と Threads の 15 の本番モデルに単一の埋め込みとして導入し、顕著な効果を得た。この解決策は 2023 年 11 月の初回導入以来、時間をかけた運用と本番実績によりその有効性が裏付けられている。

---
## 2. Method

図1に示すように、我々のシステムの目的は、オフラインの基盤モデルを構築し、長期ユーザ系列の情報を事前に計算して共有可能なユーザ埋め込みに変換し、それを用いて複数の下流モデルの性能を向上させることである。この基盤モデルは下流モデルの目的やアーキテクチャに依存しない。

![[Pasted image 20250827105508.png]]

**ステップ1:** 上流の基盤モデルは定期的に学習・公開され、数時間ごとにユーザ埋め込みが更新される。この基盤モデルは以下の2つのコンポーネントから構成される。

1. **ユーザエンコーダ (User encoder):**  
    我々はマルチスライシング & サマリゼーション戦略を用いる。つまり、生のユーザインタラクション履歴を前処理して多数のスライス化されたサブ系列（カテゴリ特徴）に分割し、それらをニューラルネットワークでまとめてコンパクトなユーザ表現に要約する。このモジュールの出力が、下流モデルで用いられるユーザ埋め込みとなる。
    
2. **バックボーンシミュレーションネットワーク (Backbone Simulation Network):**  
    下流での利用ケースを模擬し、ユーザエンコーダの学習を推薦モデルの目的と整合させるために、ユーザエンコーダを通常のランキング目的やその他のランキング特徴を持つバックボーンシミュレーションネットワークに組み込む。
    

**ステップ2:** 下流モデルは、ユーザ埋め込みを取り込み、軽量なドメイン適応モジュールを通じて利用する。

### 2.1 Data Model and Preprocessing

我々は **Unified User Timeline（UniTi）** を設計した。これは、ユーザ履歴を「構造化されたユーザインタラクションの統一系列」としてモデリングするものである。各ユーザインタラクションには以下のフィールドが含まれる：

- 閲覧したメディアID
- 投稿者ID（author ID）
- イベントのタイムスタンプ
- アクションタイプ（いいね、シェア、コメントなど）
- 動画の長さ
- ユーザの視聴時間
- サーフェスタイプ（Reels, Feed など）
- メディアタイプ（動画 or 画像 など）

UniTi の形式は次のように表せる。  
メディアアイテムをベクトル **m = (e₁, e₂, e₃, …)** とし、その要素は「メディア属性（例: media id, author id, topic id, media type）」を表す。

ユーザの行動に基づいて、我々は2種類のユーザタイムラインを定義する：
- **Eₑ** = […, (mᵢ, action_typeᵢ, tᵢ), …], i = 0, 1, …  
    → ユーザの「明示的な行動」（いいね、シェアなど）を表すタイムライン
- **Eᵢ** = […, (mⱼ, video_durationⱼ, dwell_timeⱼ, tⱼ), …], j = 0, 1, …  
    → ユーザの「暗黙的な行動」（インプレッション履歴や滞在時間）を表すタイムライン

ここで i と j は、ログシステムからサンプリングされたユーザインタラクションのインデックスである。
ユーザ特徴量を「生のタイムライン」として整理することで、柔軟な特徴量エンジニアリングが可能になる。  
機械学習エンジニアは、モデル内の前処理段階で任意のフィルタリング条件を適用し、その場で特徴量を作成できる。

### 2.2 Feature Engineering

我々は UniTi 特徴量を、**HSTU のような学習可能な系列モデリング手法**（非常に高コスト）とは対照的に、**ルールベースの系列集約**に近い形で設計した。

##### 明示的タイムライン (Explicit timeline)

明示的行動系列については、アクションタイプごとに特徴量をスライスする。

$$
	f_{\text{action}=a}(E_e) = \text{select } E_e \text{ if } \text{action\_type} = a \tag{2}
$$

つまり、ユーザの「いいね」と「コメント」は別々の系列となる。同様に、**動画**と**写真**など異なるロギングソースにおけるエンゲージメントも、それぞれ別のサブ系列に分割される。

##### 暗黙的タイムライン(Implicit timeline)

暗黙的行動系列については、**滞在時間 (dwell time)** や **視聴した動画の長さ** に基づいてサブ系列特徴量を作成する。

- **視聴時間に基づく基準**:
$$
	f_{\text{watch\_time}}(E_i) = \text{select } E_i \text{ if } \text{dwell\_time} \in [T_{lb}, T_{ub}] \tag{3}
$$
- **視聴割合に基づく基準**:
$$
	f_{\text{watch\_ratio}}(E_i) = \text{select } E_i  \text{ if } \frac{\text{dwell\_time}}{(\text{video\_duration})^\beta} \in [\alpha_{lb}, \alpha_{ub}] \tag{4}
$$

ここで、$T_{lb}, T_{ub}, \alpha_{lb}, \alpha_{ub}$​ は上下限を表す閾値であり、$\beta$ は調整可能な指数である。  
$\beta = 1$ の場合は通常の視聴割合（watch percentage）となり、$\beta < 1$ とすることで短尺動画に対してより細かい粒度の分布を得ることができる。


##### 動画長に対するバイアス補正

通常、長い動画ほど滞在時間も長くなる傾向があるため、**動画長によるバイアスを補正した重み付き特徴量**を設計した：

$$
	s(E_i) = \frac{\ln(\text{dwell\_time} + 1)}{\ln(\gamma \cdot \text{video\_duration} + 1)} , \quad
$$

$$
	f_{\text{debiased\_wt\_score}}(E_i) = \text{select } (E_i, s(E_i)) \text{ if } s(E_i) > s_0 \tag{5}
$$

ここで $s(\cdot)$ はスコア計算式、$\gamma$ と $s_0$​ はハイパーパラメータである。


##### 時間スライシング (Time slicing)

重み付けされていないカテゴリ特徴については、**時間的なバケット分割**を行う：

$$
	g_{T_{ub}}(f(E)) = \text{select } f(E) \text{ if } \Delta t \in (0, T_{ub}] \tag{6}
$$

ここで、$f(E)$ は明示的系列 $(E_e​)$ または暗黙的系列 $(E_i​)$ から生成された任意の非加重カテゴリ特徴である。  $\Delta t$ は「推薦時刻 − ユーザ行動時刻」、$T_{ub}$ は時間バケットの上限である。

**本研究では「全期間」に加えて、追加で $T_{ub} \in \{3 \text{days}, 7 \text{days} \}$ のバケットを選び、すべてのアクションベースの明示的特徴（式2）と視聴時間ベースの暗黙的特徴（式3）に時間スライシングを適用した。**

我々は徹底的な実験を行い、**オフライン評価指標の改善に基づいて 200 個の派生特徴量を選択**した。 
非加重のカテゴリ特徴については、**平均プーリング**によってユーザごとに 1 つの埋め込みに集約した。  
一方、加重されたカテゴリ特徴については、**重み付き平均プーリング**（加重和を全重みの合計で割る）を用いて集約した。
さらに、**埋め込みテーブル共有（embedding table sharing）** を有効にするために、カテゴリ特徴を次の基準でグルーピングした：

- 正のエンゲージメント（例: watch_time > 15 秒） vs 負のエンゲージメント（例: watch_time < 3 秒）
- 暗黙的タイムライン vs 明示的タイムライン
- ID の種類（media id, author id, topic id）
- 非加重 vs 加重
- プロダクトタイプ

この設計によって、**各埋め込みテーブルは固有の学習フォーカスを持ちながら**、テーブル共有によってメモリ使用量を低コストに抑えることができる。


> [!NOTE] 200個の特徴量について
>- 「直近7日のlikeしたmedia_id」
>- 「全期間で15秒以上視聴したReels動画」
>- 「直近3日のcommentしたauthor_id」
>- …
>- といった **行動タイプ × サーフェス × 時間 × etc** などで特徴量を切り分ける。
>→ 論文中では「実験的に色んな組み合わせを作り、その中でオフライン評価指標（AUC, NDCG, Recallなど）が改善したものを選んだ」と説明されています。


> [!NOTE] プーリングについて
> 「重みなし」の場合、すべての要素を同じ扱いにして、単純平均を取る。$\mathbf{u} = \frac{1}{n} \sum_{i=1}^n \mathbf{v}_i$
> - 例: 「ユーザがlikeした動画10本」の埋め込みを全部平均 → 「like行動全体の特徴ベクトル」
> - 各要素に差をつけない。
> 
> 「重みあり」の場合、要素ごとに重要度（重み $w_i$​）を付けて平均を取る。
> $\mathbf{u} = \frac{\sum_{i=1}^n w_i \mathbf{v}_i}{\sum_{i=1}^n w_i}$
> - 例: 「ユーザが動画を視聴した」
> 	- 動画Aを 2秒見た → $w=2$
> 	- 動画Bを 30秒見た → $w=30$
> 	- 動画Cを 0.5秒でスキップ → $w=0.5$
> → 長く見た動画の埋め込みが、ユーザの特徴に強く反映される。


![[Pasted image 20250823232640.png]]


> [!NOTE] 埋め込みテーブルについて
> 埋め込みテーブルは **巨大な行列（パラメータの集まり）** です。
> - 行 = ID（例: media_id, author_id, topic_id）
> - 列 = ベクトル次元（例: 128）
> - 初期状態ではランダム値。
　👉 つまり、**埋め込みベクトルも他のモデルの重みと同じ「学習可能パラメータ」** です。
> 
> **埋め込みテーブル共有(embedding table sharing)**
> ex. 
> - 「media_id 系列の特徴量は全部同じ media_id テーブルを使う」  
> - 「author_id 系列の特徴量は全部同じ author_id テーブルを使う」  
> - 「topic_id 系列の特徴量は全部同じ topic_id テーブルを使う」


### 2.3 Model architecture

#### 2.3.1 Backbone Simulation Network

バックボーンシミュレーションネットワークの設計目標は、**ユーザエンコーダを監督する「学習ラッパー」を作ること**である。これにより、異種の下流モデルにおいても有効なユーザ埋め込みを生成できるモジュールを学習させる。

我々はバックボーンネットワークとして **DLRM [8]** を用いた。DLRM はマルチタスクランカー $\Phi$ であり、以下のタスクを実行する：  
ユーザの整理された UniTi タイムライン $E_i, E_e$​, ターゲットアイテム特徴 $x$、その他のユーザ特徴 $c$ が与えられたとき、次のようにスコアベクトルを生成する：

$$
	\hat{y} = \Phi(E_i, E_e, x, c)
$$
ここで $\hat{y}$​ の次元はタスクの数と同じである。目的は、すべてのタスクの合計損失を最小化すること。

**損失関数**

- **バイナリタスク**に対しては交差エントロピー損失を使用する：

$$
	l^{(k)}_{\text{binary}} = \text{BCEloss}(\hat{y}^{(k)}, y^{(k)}) = -\frac{1}{B}\sum_{j=1}^{B} \left[ y^{(k)}_j \ln(\hat{y}^{(k)}_j) + (1-y^{(k)}_j)\ln(1-\hat{y}^{(k)}_j) \right] \tag{7}
$$ 
ここで $y^{(k)}_j$​ は、バイナリタスク $k$ におけるミニバッチ中の $j$ 番目のアイテムの正解ラベルであり、$\hat{y}^{(k)}_j$​ はモデルの予測値である。


> [!NOTE] バイナリタスクの例
> - クリック予測
> - いいね予測
> - コメント予測
> - シェア予測
> - 保存予測
> - 視聴完了予測
> - フォロ―予測


我々のモデルには1つの回帰タスクがあり、ユーザの **視聴時間 (watch time)** を予測する。そのMSE損失は次の通り：

$$
	l_{\text{reg}} = \frac{1}{B}\sum_{j=1}^{B} (z_j - \hat{z}_j)^2
$$

ここで $z$ は正解の滞在時間（dwell time）、$\hat{z}$ は予測値。

**全体の損失関数**は次の通り：

$$
	L_{\text{total}} = \sum_{k} l^{(k)}_{\text{binary}} + \alpha \cdot l_{\text{reg}} \tag{8}
$$

ここで $\alpha$ は損失タイプのスケールを調整するハイパーパラメータ。


> [!NOTE] 下流モデルとバックボーンモデルの違い
> **下流モデル (downstream models)**
> - Instagram の本番で実際に動いている推薦モデルたち。
> - 例：
> 	- Reels のランキングモデル
> 	- Feed のランキングモデル
> 	- Stories のランキングモデル
> 	- Retrieval モデル、Early Stage Ranking (ESR)、Late Stage Ranking (LSR) など
> - これらは **ユーザ埋め込みを使って予測をする最終的な利用者**。
> 
> **Backbone Simulation Network**
> - **学習時にだけ使う疑似ネットワーク**。
> - 目的は「ユーザエンコーダ（DV365）が本番下流モデルに役立つ埋め込みを学習できるように監督する」こと。
> - DLRM をベースにして、クリック予測や視聴時間予測といった **擬似タスク**を解かせる。
> - これにより、ユーザエンコーダの出すベクトルが「下流モデルでも効く」ように調整される。


**遠隔興味予測目的 (Distant Interest Prediction Objective)**

ユーザ埋め込みを安定させるために、我々は UniTi タイムラインから **直近24時間分の情報を削除**する制約を加えた。すなわち、インタラクション時刻の直前24時間を除いたタイムライン

$$
	E^{-24h} = (E_i^{-24h}, E_e^{-24h})
$$

を用いる。この「24時間ギャップ」を導入することで、モデルにはより難しい予測タスクが課され、**長期的なユーザ興味**を学習するよう強制される。その結果、トレーニングやデータパイプラインの遅延に対しても頑健な埋め込みが得られる（詳細は付録B）。

学習目標は次のように定義される：

$$
	\hat{\Phi} = \arg\min_{\Phi} L_{\text{total}}(\Phi(E^{-24h}, x, c), y) \tag{9}
$$

バックボーンモデルは次のようにも書き換えられる：

$$
	\hat{y} = \Phi_{\phi}(\eta(E_{-24h}), x, c) \tag{10}
$$

ここで、

- $\eta(\cdot)$ は DV365 のユーザタイムラインのみを入力とする **ユーザタワーエンコーダ**
- $\phi$ は $\eta$ 以外の残りのパラメータ

$\eta$ と $\phi$ のパラメータは継続的に繰り返し学習され、ユーザ埋め込みは 6時間ごとにアクティブユーザ全体に対して $\eta(E_{-24h})$ を評価することで生成される。

#### 2.3.2 Funnel Summarization Arch (FSA)

DV365 のユーザエンコーダ $\eta(E)$ の設計目標は、**マルチスライスされた埋め込みを、よりコンパクトなユーザ埋め込みへとエンコードすること**であり、これは表現学習器であると同時に、インフラおよび下流での消費コストを抑えるための圧縮器として機能する。

まず、生の埋め込みに対してトークン単位のビューを適用する。スパースルックアップ後の生埋め込み数を $N$、埋め込み次元を $D$ とすると、ユーザ埋め込みテンソルのサイズは $[N, D]$ である。このテンソルを転置してサイズ $[D, N]$ の $U$ を得て、最次元（トークン次元）に対してニューラルネットワークを適用する。これを、MLP層で $[1, N \times D]$ とみなす伝統的な方法や、Transformer で $[N, D]$ とみなす方法と比較すると、この転置は生の（プーリングされた）トークン埋め込みの全ての次元にわたるパラメータ共有を可能にし、その結果として出力において埋め込みの意味的整合性を保持する。次に、このトークン単位ビューに対して Funnel Transformer [3] エンコーダを適用する。基本的な Transformer エンコーダ層は以下で表される。

$$
	\text{EncoderLayer}(U) := \text{Norm}(U + \text{FF}(\text{Norm}(U + \text{Att}(q, k, v = U)))) \tag{11}
$$


> [!NOTE] テンソル
> **多次元の配列（行列をもっと一般化したもの）** のことです。
> - スカラー（1つの数） = 0次元テンソル
> - ベクトル（1列の数の並び） = 1次元テンソル
> - 行列（縦×横） = 2次元テンソル
> - もっと次元が増えたもの（例: 画像データ = [高さ, 幅, チャンネル]）もテンソルと呼ぶ

> [!NOTE] sparse lookup
> - 行動ログには「media_id = 12345」といった **IDだけ** が並んでいます。
> - IDはただの整数なので、そのままでは使えない。
> - そこで「埋め込みテーブル」という巨大な行列から **そのIDに対応する行ベクトルを取り出す処理**をします。
> - これが **embedding lookup（スパースルックアップ）**。

> [!NOTE] トークン単位のビューを適用
> - 「トークン」= ユーザ行動の1要素（likeした1投稿、見た1動画など）。
> - 通常、埋め込みテンソルは $[N, D]$（N個のトークン、それぞれがD次元のベクトル）という形で扱います。
> - ここではこれを転置して $[D, N]$ にして、**トークン次元を強調してニューラルネットに渡す**。


ここで $\text{FF}$ は位置ごとのフィードフォワードネットワーク、$\text{Att}$ はマルチヘッド自己注意、$\text{Norm}$ はレイヤ正規化である。Funnel Transformer は複数のブロックを持ち、それぞれのブロックに複数の層を含む。各ブロックの間で、ストライドを伴う平均プーリングがトークン次元に対して適用され、結果として $U_{out}$​ のサイズは $[D, N_{out}]$ となり、$N_{out} < N$ となる。重要なのは、このプーリングはオリジナルの Funnel Transformer [3] における埋め込み次元ではなく、トークン次元に対して適用されるという点である。$n$ 個のブロックを持ち、各ブロックに $m$ 層を含む Funnel Transformer エンコーダはアルゴリズム1に記述されている。我々の実験では、Funnel Transformer はトークン単位の設定で通常の Transformer を用いた場合と比較して一貫して同等の NE 性能を達成しつつ、より少ないパラメータにより高い学習速度を実現した（3.4節）。

> [!NOTE] DV365の流れ
> 1. **70,000件の生履歴**
> 	- ユーザのすべての行動ログ（like, comment, watch …）。
> 2. **マルチスライシング (multi-slicing)** ← 恐らくルールベース
> 	- ログを行動タイプ、サーフェス、時間バケットなどで細かく切り分ける。
> 	- → 約200個の「部分系列（特徴量の候補）」ができる。
> 3.  **特徴量エンジニアリング (feature engineering)** ← ルールベース
> 	- 各部分系列に対して平均プーリング or 重み付き平均プーリングで1本の代表ベクトルにする。
> 	- 正/負のエンゲージメントや media_id / author_id / topic_id などをグルーピングして埋め込みテーブルを共有する。
> 	- 結果：**200個の代表ベクトル**が得られる。
> 4. **Funnel Summarization Arch (FSA)**
> 	- 200個のベクトルを Funnel Transformer と LCE の並列処理で圧縮。
> 	- → 「1つの最終ユーザ埋め込み」を生成。
> 5. **下流モデル (Retrieval, ESR, LSR, Reels/Feed/Stories etc.)**
> 	- このユーザ埋め込みを特徴量として利用することでFSAの部分を学習する。

![[Pasted image 20250824101108.png]]

我々は性能をさらに向上させるために、Funnel Transformer に並列して **線形圧縮エンコーダ（Linear Compression Encoder, LCE）** を追加した。学習時には、出力された埋め込みをスタックしてフラット化し、シミュレーションネットワークの入力の一部として用いる。公開時（実運用にデプロイする際）には、それらを **4ビット量子化** してから特徴量ストアに格納し、推論で利用する。全体として、DV365 のユーザタワー（FSA と 4ビット量子化を含む）は、200 × 256 の fp32（32ビット浮動小数点数）を **58 × 17 の long 整数** に圧縮し、**50倍の圧縮率**を達成した。


> [!NOTE] FS
> - **Funnel Transformer** と **LCE**
> 	- 入力：200本の代表ベクトル（例：200×256 fp32）
> 	- 出力：「ユーザを表す1本の埋め込みベクトル」
> 	- ここでの目的：**情報圧縮 ＆ 意味を保持した表現学習**
> - **4ビット量子化**
> 	- Funnel Transformer と LCE の出力をさらにコンパクトに変換
> 	- 保存や配布のための **データ圧縮** が目的


### 2.4 Downstream Integration

下流モデルと統合するためには、まず DV365 埋め込みを再び浮動小数点の埋め込みにデ量子化（de-quantize）し、さらに学習可能な射影を行って DV365 埋め込み（58個の256次元埋め込み）を生成する必要がある。我々が採用した方法は次の3種類に要約できる。

(1) **DLRM ランキングモデル**：線形射影の後、DV365 埋め込みを元々モデル内にあった他のスパース埋め込みと連結する。
(2) **HSTU モジュール**：DV365 埋め込みを、元の HSTU 入力系列（最新のユーザエンゲージメント）の先頭に付加する。
(3) **Retrieval（Siamese ネットワークまたは MoL [15]）**：経験的に、リトリーバル統合においては線形射影よりも **GateNet [6]** が効果的であることが分かった。


> [!NOTE] 量子化解除の必要性
> - 量子化の出力 = **超圧縮された整数表現（long int）**
> - 下流モデル（DLRMやHSTUなど）は普通の **浮動小数点ベクトル（fp32）** を入力に想定している
> - だから、まず **de-quantize（量子化解除）** して float に戻す

> [!NOTE] 射影の必要性
> - 復元しただけでは「サイズや空間が下流モデルの入力と揃わない」
> - 例：DV365から出てくるのは「58個の256次元埋め込み」だけど、
> 	- DLRM は「スパース特徴量の埋め込み」       
> 	- HSTU は「系列入力」
> 	- Retrieval は「ユーザ/アイテムを同じ空間に写す必要」
> - なので、**学習可能な射影層 (linear projection か GateNet)** をかけて、下流モデルが使いやすい形に変換する

> [!NOTE] Instagramにおける下流モデルの3系統
> - **DLRM 系ランキングモデル**
> 	- CTR予測やランキングに強い **Deep Learning Recommendation Model**。
> 	- 主に **Feed** や **Reels** のランキングで使われる。
> 	- ユーザ埋め込み＋アイテム特徴を結合して「スコア（クリック確率など）」を出す。
> - **HSTU 系モデル**
> 	- **直近のユーザ履歴（短期履歴）**を Transformer 系列で読む。
> 	- 長期履歴の要約（DV365）を「先頭トークン」として付け加えて強化。
> 	- 直近行動に敏感な推薦（トレンド・最近の興味）に適している。
> - **Retrieval 系モデル**
> 	- ユーザ埋め込みとアイテム埋め込みを同じ空間に写して、ANN（近似最近傍検索）で候補を取る。
> 	- **Explore タブ** や「候補集合を数百万件から数百件に絞るステージ」で使う。
> 	- DV365埋め込みは GateNet を通じて統合される。

### 2.5 Serving in Production

#### 2.5.1 Existing System

既存のレコメンデーションシステムは、ユーザが Instagram のフロントエンドアプリケーションを通じてリクエストを送信したときに開始される。このリクエストを受け取ると、バックエンドシステムは推薦候補とそれに関連する特徴量を準備する。これらの候補はモデル推論サービスに転送され、予測された関連性に基づいてランキングされる。ランキングされたコンテンツはバックエンドに返され、ユーザに配信される。

ユーザが推薦されたコンテンツとインタラクションすると、インタラクションイベントが生成され、それが記録されて、推論サービスにデプロイされているコアランキングモデルの学習データとなる。**コアランキングモデルはオンライン学習 [13] のアプローチを採用**しており、新しいデータで継続的にモデル重みを更新し、最小の遅延で鮮度を維持する。このシステムの構成要素は図2に示されており、薄緑色で強調されている。

![[Pasted image 20250824232548.png]]

#### 2.5.2 Embedding Precomputation and Serving System

ユーザの長期的な関心や行動パターンは、数時間から数日といった短期間では比較的安定している。そのため、生のインタラクションデータから頻繁にユーザ埋め込みを計算する必要はなく、それは計算コスト的にも高くつく。そこで我々は、図2に示すような **オフラインの埋め込み事前計算および提供システム** を提案する。このシステムは以下の主要なコンポーネントとプロセスで構成されている。

1. **Offline training data generation**: データパイプラインが長期的なユーザインタラクション履歴を集約し、オフラインのトレーニングデータと組み合わせ、DV365 基盤モデルの学習用に包括的なデータセットを形成する。
2. **Foundation model training**: DV365 基盤モデルは集約されたデータで定期的に学習される。この周期的な学習によって、モデルはデータ分布の変化に追従できるが、実運用のオンライン学習で消費されるデータに対して常に約2日遅れになる。
3. **Embedding precomputation and serving**: 学習済みモデルのユーザタワーから中間出力をエクスポートすることでユーザ埋め込みを生成する。これらの埋め込みはユーザIDでインデックスされ、データベースに保存され、さらにオンラインのキー・バリュー・ストアにキャッシュされて効率的に取得できるようにされる。埋め込みの精度削減や量子化といったストレージ最適化技術が適用され、リソース使用量を最小化しつつ埋め込み品質を保持する。
4. **Recurring job scheduler**: 定期ジョブスケジューラがデータ収集、モデル学習、埋め込み生成、キャッシュといったワークフロー全体を調整する。一定間隔で稼働することで、タイムリーな更新を保証し、計算効率と埋め込みの鮮度を両立させる。

このオフライン埋め込みシステムは、リアルタイム性を維持する必要が低いため、コスト効率の面で重要な強みを持つ。我々はモデルを頻繁に更新する必要がなく、長期のユーザ履歴データは高価なオンライン提供用ストレージに置くのではなく、**低コストなデータウェアハウスに保存**できる。さらに、ユーザのアクティビティレベルに基づいて埋め込みのリフレッシュを行い、ユーザ行動の変化を捉えるために増分更新を適用することで、電力消費も最適化される。


> [!NOTE] 
> - **下流モデル自体はオンライン学習モデル**
> - その入力には
> 	- **オンライン特徴量（リアルタイム行動）**
> 	- **オフライン特徴量（DV365ユーザ埋め込み）** の両方が必要
> - これによって「鮮度と安定性の両立」が可能になる

---
### 3. Experiments

我々は、DV365 ユーザタワーを用いたアップストリームのランカーモデルにおける DV365 埋め込みの性能、ならびにダウンストリームのランカーおよびリトリーバルモデルにおける性能を検証するために大規模な実験を行った。ランカーモデルについては、バイナリタスクにおけるモデル性能のオフライン評価指標として **正規化エントロピー（Normalized Entropy, NE）** を用いる。

$$
	NE_k = \frac{\text{BCEloss}(\hat{y}^{(k)}, y^{(k)})}{- \big[ p_k \ln(p_k) + (1 - p_k)\ln(1 - p_k) \big]} \tag{12}​
$$

ここで、$p_k$​ はタスク $k$ における平均CTR（click-through rate）である。分母での正規化によって、背景CTRが0や1に近いときにメトリクスが人工的に良く見えることを防いでいる [5]。我々は絶対的なNEスコアではなく、テスト群と対照群で同一の期間を用いて算出した **Relative NE Delta** を使用する。これはデータ分布や背景CTRが時間とともに変化するためである。**Meta社において、この指標はレコメンデーションや広告ランキング全般にわたってオンラインA/Bテスト結果と一貫した動きを示す、最も信頼できるオフライン評価指標の1つと広く認識されている。** NEが **0.1%以上** 向上すれば有意であり、A/Bテストでの改善を示唆する。

リトリーバルモデルについては、ユーザとアイテムの類似度関数として単純なドット積を用いたマルチタスク版 MoL [15] に基づき、**Hit Rate @1** および **Hit Rate @10** を評価指標として報告する。


> [!NOTE] BCEloss = Binary Cross Entropy loss
> - クリック予測（CTR予測）や「ユーザがいいねするか？」のような **2値分類タスク** に使われます。
> - 出力 $\hat{y}$​ が「確率（0〜1）」、教師データ $y$ が「0 or 1」というときの損失関数です。

### 3.1 Dataset & Experiment Setup

我々のデータセットは、Instagram の推薦ログから生成された社内の学習データである。既存のプロダクション学習テーブル（既存のプロダクションモデルを学習するために使用される、DV365 にとっては下流モデルと呼ばれるもの）では、各学習行はユーザエンゲージメントをラベルとし、ユーザ履歴およびアイテムの特徴量を含む。プロダクション学習テーブルにおけるユーザ履歴の長さは平均で約1500、最大で2000である。

DV365 を極めて長いユーザ系列で学習するために、我々はオフラインでプロダクション学習テーブルにさらに長い履歴を付加した別のテーブルを作成した。これは、リアルタイムで生成されるプロダクションテーブルに直接履歴を追加するよりも、計算コスト的に効率的である。**このテーブルにおけるユーザ履歴の長さは平均で約40,000、最大で70,000**である。

セクション2で述べた DV365 基盤モデルはこのオフライン長期履歴テーブルで学習され、我々は基盤モデルの NE 指標に基づいてモデル選択を行った。これは、基盤モデルでの改善が、エクスポートされたユーザ埋め込みを通じて下流モデルに転移すると仮定しているためである。

DV365 の下流モデル、すなわち実際のプロダクションモデルは、目的（リトリーバルまたはランキング）や対象領域（Reels、Feed、通知）において多様である。本節では、我々が最も大きな領域である **Reels** を対象に、ランキングとリトリーバルの両方でプロダクションテーブルで学習した下流性能を報告する。ランキングモデルのベースラインは DLRM モデルであり、リトリーバルモデルのベースラインは MoL [15] モデルである。両者とも**ユーザ系列エンコーダとして HSTU を使用**しており、当時のプロダクションモデルであった。これにより、既に長いユーザ系列（オーダー $10^3$）と注意機構ベースのエンコーダ HSTU を備えた実際のプロダクションモデルであるため、強力なベースラインが確立された。我々は、これらのベースラインに DV365 を特徴量として統合したときの追加的な性能向上を測定した。

### 3.2 Choice of Sequence Encoder

我々は、極めて長い系列を扱う際に他の手法が抱えるスケーラビリティの課題を考慮し、系列の集約方法として **平均プーリング（mean-pooling）** を選択した。我々は注意機構ベースの系列モデルについても実験を行ったが、我々の **マルチスライシング & サマリゼーション** ベースラインに比べて顕著な性能向上は見られなかった。詳細は付録Cで議論する。

### 3.3 Choice of Backbone Simulation Network

我々は、知識転移においてアップストリームモデルとダウンストリームモデルの一貫性が重要であると仮定した。そこで、2つのバックボーンモデルを比較した：すべてのプロダクションランキングモデルと一貫性のある **DLRM**、およびリトリーバルモデルと一貫性のある **Siamese ネットワーク** である。結果として、DLRM をバックボーンとしたアップストリームモデルはダウンストリームのリトリーバルモデルでも同等の性能を示したが、ダウンストリームのランキングモデルにおいては明確に優れており（NEデルタで 0.2%）、そのため我々はバックボーンとして DLRM を選択した。

また、シミュレーションネットワークにおいて他の要素も検証した：

1. **タスク**: 重要ではなかった。バックボーンに下流の予測タスクの一部の重要なものだけを含めることで DV365 埋め込みの効果が最大化され、重要でないタスクを追加しても NE の追加的な改善はほとんどなかった。    
2. **モデル規模**: 重要ではなかった。タスク固有モジュールやインタラクションアーキテクチャの複雑性を増やしても、DV365 埋め込みの下流性能に与える追加的な利益は限定的であった。    
3. **特徴量**: スパース特徴量とデンス特徴量の両方がシミュレーションには重要であった（完全に削除した場合、NEが0.2%以上低下した）。しかし予想通り、十分な特徴量を加えた後は、シミュレーション特徴をさらに増やしても埋め込み品質の向上は頭打ちとなった。


> [!NOTE] なぜバックボーンシミュレーションが必要か
> - ユーザ埋め込みを作るエンコーダ（$\eta$）は、単独で学習させると「どういう情報を持てば下流で役立つか」を理解できない
> - そこで **「下流モデルを模したバックボーン（simulation network）」を横に置いて、埋め込みが実際のランキング/リトリーバルで役立つように学習させる**
>👉 言い換えると：DV365の埋め込み学習は **下流をシミュレーションした“代理タスク”を通じて訓練している**


> [!NOTE] なぜ「バックボーン選び」で DLRM と Siamese を比べるのか？
> - DV365 の目的 = 「1つのユーザ埋め込みを作って、Retrieval でも Ranking でも使えるようにする」
> - そのため、どっちの下流を模倣して学習するか（＝バックボーン選び）が重要になる
> - 実験結果：    
> 	- **DLRM をバックボーンにした方が、ランキングモデルではもちろん強く、リトリーバルでもそこそこ良かった**
> 	- **Siamese をバックボーンにした場合、リトリーバルは問題ないがランキングでは弱かった**
> - なので、両方に効く DLRM を選んだ


> [!NOTE] DLRMとは
> - **DLRM (Deep Learning Recommendation Model)** は Meta が提案した **ランキング用の学習モデル**
> - ユーザ特徴（埋め込み＋デンス特徴）とアイテム特徴を組み合わせて CTR（クリック率）やエンゲージメントを直接予測する
> - つまり「**ランキング学習モデル**」として設計された


> [!NOTE] Siameseとは
> - 本来は顔認識や文書類似度でよく使われるモデル構造
> - **2つの入力（例：ユーザ、アイテム）をそれぞれ別のタワー（encoder）で埋め込みに変換し、最終的に内積（cosine類似度など）で距離を測る**
> - DV365文脈では：
> 	- **ユーザタワー**：ユーザ履歴を埋め込みにする
> 	- **アイテムタワー**：アイテム特徴を埋め込みにする
> 	- **dot product**：ユーザとアイテムの類似度を計算し、ランキングではなく「候補生成（retrieval）」に使う
> 	- 長期的なログデータの埋め込みはDV365によって行い、短期的なログデータに関してはSiameseが行う

### 3.4 Choice of DV365 User Encoder Architecture

ユーザエンコーダの目的は、**特徴量の相互作用を学習し、マルチスライスされた埋め込みをデプロイ可能なサイズに圧縮すること**である。我々はユーザエンコーダにおいて2つの設計上の選択肢を検討した：

1. **圧縮の観点**    
    - **次元単位 (dim-wise)**：$[1, N \times D]$ または $[N, D]$ の形でエンコーダを適用
    - **トークン単位 (token-wise)**：$[D, N]$ に転置してからエンコード

2. **エンコーダのアーキテクチャ**    
    - 線形圧縮エンコーダ (Linear Compression Encoder, LCE)
    - MLP
    - Vanilla Transformer（最後の $N_{out}$ 個の出力埋め込みを使用）
    - Funnel Transformer [3]

さらに実験では、圧縮を行わないベースラインも追加した。実験設定は表1に、結果は表2に示している。結果は、**トークン単位の圧縮が全てのエンコーダで次元単位の圧縮を大きく上回る**ことを示しており、これはモデルが1つのトークン埋め込み内でのパラメータ共有を好むことを示唆している。エンコーダの選択に関しては、Vanilla Transformer エンコーダと Funnel Summarization Arch (FSA) が圧縮候補の中で最も良い性能を示した。我々は、FSAの方がパラメータ数が少なく、さらに学習において **10%のQPS（クエリ毎秒）優位性** を持つため、FSAを選択した。

![[Pasted image 20250825143704.png]]
![[Pasted image 20250825143719.png]]

### 3.5 Downstream Integration & Product Launches

報告の便宜上、我々はオフライン結果を **Reels サーフェス**（最もエンゲージメントトラフィックが大きい）についてのみ示す。他のサーフェスでも同様の結果が得られている。ランキングモデルにおいては、DV365 はすべてのタスクで **NE を有意に改善**し（平均で 0.4%以上、表3）、さらに線形射影を用いた採用がより良い結果をもたらした。リトリーバルモデルにおいては、DV365 は **Hit Rate を 2%〜8% 向上**させ、採用モジュールとして GateNet を用いることで多くのタスクにおいてさらに大きな改善が得られた（表4）。

DV365 はすでに Instagram と Threads における **15種類の異なるプロダクトモデル**に広く導入され、ビジネス上大きなインパクトをもたらしている。すべての導入から得られた A/B テスト結果を累積すると、Instagram アプリにおける **ユーザ滞在時間が 0.7% 向上**し、その他の多くの重要なエンゲージメント指標も改善した。

また、DV365 は **高い汎用性**を持っている。下流モデルのアーキテクチャや目的が非常に異なるにもかかわらず、我々は **単一のアップストリームモデルから単一の埋め込みセットを生成するだけで、多様な下流ユースケース**に対応することができる。その中には、コンテンツ推薦の品質改善、通知のCTR改善、新しい事業である Threads の立ち上げ支援などが含まれる。

さらに我々は、DV365 がオフライン埋め込みであることによる「鮮度の不利」を克服したことも検証した。すなわち、**埋め込みの古さが増しても品質は安定している**（詳細は付録B）。これは、DV365 が Instagram 内の複数のプロダクトにとって重要な依存先であることを踏まえると、システム信頼性の観点からも大きな強みである。

> [!NOTE] 要するに
> - Reelsでのオフライン結果を代表として報告
> - ランキングでは NE が +0.4% 以上改善
> - リトリーバルでは Hit Rate が +2〜8% 改善
> - 実際に Instagram/Threads の15モデルに導入済み
> - アプリ滞在時間 +0.7% など実際のビジネス効果も大きい
> - 汎用性が高く、通知CTRや新規事業にも転用可能
> - 鮮度問題（オフライン埋め込みの遅延）も克服済み

![[Pasted image 20250825185208.png]]

> [!NOTE] GateNetとは
> - **ゲーティング（gating）機構**を持つ小さなニューラルネットワーク
> - 複数の入力ベクトルを受け取り、それぞれに「重み（ゲート）」を学習的に割り当ててから結合する仕組み
> - 簡単に言えば：
> 	- 単純な **線形射影（Linear Projection）** が「全部の入力を固定的に混ぜる」のに対して、
> 	- **GateNet** は「入力ごとに重要度を学習して重み付けしてから混ぜる」

> [!NOTE] DV365でのGateNetの使い方
> - リトリーバルモデル（Siamese系）に DV365 の長期埋め込みを統合するとき
> - 方法1：**線形射影** → そのまま次元を揃えて結合
> - 方法2：**GateNet** → 短期埋め込みとDV365長期埋め込みの「どっちをどれくらい信じるか」を学習的に調整して結合
>👉 実験では GateNet の方が線形射影より性能が良かった（Hit Rate の改善幅が大きかった）。

---
## 4. ROI Advantages of Offline Embedding

我々は、DV365 で用いた手法を **オフライン埋め込み** として実現する場合と、**E2E モデルの一部**として実現する場合のコストを比較した。Meta では、データセンターにおける電力使用量を Watt 単位に正規化することでコストを見積もっている。

### 4.1 Feature Infra Cost Saving

オンライン E2E の長系列モデリング手法と比べたとき、オフライン埋め込みの主要な利点は、モデル推論に必要となる **リアルタイムの特徴量抽出・処理コストを大幅に削減できること**、さらに **極めて長いユーザ履歴を低レイテンシのキー・バリュー・ストアに保存するコストを削減できること** である。

我々が詳細に測定したところ、この2つのアプローチの差分は、**特徴量抽出コストで約100 MW**、そして **低レイテンシキー・バリューストアで11 PB** に達することが分かった（付録 A.2.2）。この極めて高いコストこそが、Meta のリアルタイム推論インフラにおいて「極めて長いユーザ履歴」が現在アクセス不可能である理由である。

> [!NOTE] 要約
> - オンラインE2Eで長系列（7万件など）を直接処理すると、電力・ストレージコストが爆発する
> - DV365のオフライン埋め込み方式なら、その膨大なコストを避けられる
> - 実際に差分は **電力で100 MW・ストレージで11 PB** という巨大なもの

### 4.2 Model Training Cost Saving

モデル学習コストの削減は、**単一の基盤モデルがすべての下流モデル（我々の場合は15個）に対して計算を行う**ことから生じる。例えば Instagram Reels モデルにおいて、長期履歴のタイムラインからスライス特徴量を生成する追加的な前処理は **50 KW** と測定され、さらに追加で **338枚の A100 GPU を予約するコスト**が発生する。すべてのモデルで同じコストがかかるわけではないことを考慮し、15ではなく10倍の係数を用いて総コストを見積もると、**500 KW と 3380枚の A100 GPU 予約**が必要となる。

> [!NOTE] A100 GPU
> - 正式名：**NVIDIA A100 Tensor Core GPU**
> - 発売年：2020年（Ampere アーキテクチャ世代）
> - 主な用途：
> 	- 大規模なディープラーニングの学習（training）
> 	- 推論（inference）
> 	- 科学技術計算、シミュレーション


> [!NOTE] コスト比較
> - E2Eの場合
> 	- Reels で 338枚の A100 GPU
> 	- 15個の下流モデルで単純換算×10で3380枚の A100 GPU
> - DV365の場合
> 	- 単一の基盤モデルで十分

### 4.3 モデル提供コストの削減

モデル提供（推論）時には、タイムラインをスライスして特徴量に変換する前処理（オフライン埋め込みによって不要となる処理）に **6 MW** がかかり、さらにユーザエンコーダによる推論の追加的 GPU コストとして **78枚の H100 GPU** が必要となる（付録 A.4）。Instagram Reels モデル全体での数値であり、全体のシステムに拡張すると **追加で780枚の H100 GPU** が必要と推定される。

---
## 5. Related Works

### 5.1 Sequence User Modeling

ユーザ系列モデリングは推薦システムにおける古典的な課題であり、産業界の最先端手法は、**ユーザ系列内の各アイテムに対してアテンション重みを学習し、それらを集約してユーザの完全な興味表現を得る**という注意機構ベースの手法に収束してきた。代表的な例としては **DIN [18]、DIEN [17]、SASRec [7]、HSTU [16]** がある。そして HSTU は現在 Instagram のプロダクションモデルにおいて重要なモジュールとなっている。

これらの注意機構ベースの手法には **系列長のスケーラビリティ問題**がよく知られており、実際に導入されている多くの解法では系列長が **おおよそ O(100) レベル** にとどまっている。


> [!NOTE] HSTU
> - 論文に書かれている通り、**Instagramの従来のプロダクションモデルでは「HSTU」というモジュールを使ってユーザ系列をモデリング**していました。
> - ユーザの直近の履歴（クリック・いいね・視聴など数百〜2000件程度）を入力にして、**「ユーザ表現（ユーザ埋め込み）」を作る役割**を担っていたのが HSTU です。


> [!NOTE] HSTUとSiamese
> - **Retrieval段階**
> 	- 短期履歴を入力にして **Siameseのユーザタワー**がユーザ埋め込みを作る
> 	- ここは計算コストを抑えるためシンプル
> - **Ranking段階**
> 	- よりリッチに短期履歴を扱うために **HSTU** がユーザ埋め込みを作る
> 	- 注意機構で数百〜2000件程度の系列を処理

### 5.2 Long-term User Sequence Modeling

MIMN [10] や HPMN [12] はメモリネットワークを用いて、利用可能な履歴長を **O(1000)** まで拡張したが、それ以上のスケーリングは困難であることが分かった。  
もうひとつの研究テーマとしては（SIM [11]、SDIM [1]、TWIN [2]）、**二段階のエンドツーエンド型カスケードフレームワーク**を導入し、より長期の履歴モデリングを可能にするアプローチがある。この二段階とは以下の通りである：

1. 高速検索ユニットによって、数千件のユーザ行動履歴の中からターゲットアイテムに最も「関連性が高い」とされるアイテムを検索する
2. アテンションネットワークを用いて、第1段階で得られた候補群に対してターゲットアテンションを行う

これらの研究は、**1万件規模（10⁴）のユーザ系列をモデリングできる実運用システムをサポート可能**であると主張している。

大幅な改善ではあるものの、これらの手法は既存のプロダクションモデルにおけるコストと複雑性を大きく増加させてしまう。理由は以下の通りである：

- 学習と推論の両方において検索ユニットを導入する必要があり、GPUコストが増える
- さらに重要なのは、長期ユーザ履歴特徴にリアルタイムでアクセスできる推論インフラを整備する必要があり、これが大きな追加の特徴量インフラコストとな

加えて、エンドツーエンド手法であるがゆえに、学習された長期ユーザインタレストは **1つのモデルでしか活用できず、幅広い知識共有ができない** という制約もある。


> [!NOTE] 要約
> - MIMN/HPMN = メモリネットワークで O(100) から O(1000) まで拡張
> - SIM/SDIM/TWIN = 二段階E2Eで O(10000) まで
> - ただし両方とも **GPU・インフラコスト爆増**、さらに「1モデル専用」で汎用性がない
> - だから **DV365の「一回計算して全モデルに配布できる」方式の方がROIが高い**

### 5.3 User Embedding

**オフラインユーザ埋め込み** は、オンライン計算をオフラインのバッチ処理にオフロードすることでコスト効率を高めるもうひとつの方法である。

**Pinnerformer [9]** は、トランスフォーマーベースのアップストリームモデルを導入し、ユーザの長期的な興味をオフライン埋め込みとして事前計算する手法を提案した。この方法は **Pinterest において実際に導入され**、大きなビジネスインパクトをもたらした。しかし、この手法は高価なエンコーダを用いており、さらに**最大系列長 256 までしか扱えない**ことが報告されている。

**LURM [14]** は、長期履歴を「事前学習済みクラスタリング」を使って圧縮する **bag-of-interest 手法**を導入した。具体的には、長期履歴を各クラスタごとのカウントベクトルに変換し、さらに自己教師ありの学習目標を用いてユーザ埋め込みを学習し、汎化性能を持たせようとした。この **bag-of-interest** は非常にコスト効率の高い圧縮手法ではあるが、システム上「クラスタリング学習」という依存関係が新たに導入される。また、この論文では A/B テストや実際のデプロイ結果については共有されていない。


> [!NOTE] アップストリームモデル
> - **定義**：  
> 	- ほかのモデル（下流）に使われる **表現（embedding）や特徴量を作るモデル**

| 手法               | 系列長               | コスト                 | 実運用                    | 特徴                                 |
| ---------------- | ----------------- | ------------------- | ---------------------- | ---------------------------------- |
| **Pinnerformer** | 最大256             | 高コスト（Transformer重い） | Pinterestで導入済み         | Transformerで長期埋め込み事前計算             |
| **LURM**         | 数千まで想定            | 低コスト（クラスタ＋カウント）     | 実運用未報告                 | bag-of-interestで圧縮、クラスタ依存          |
| **DV365**        | 平均40,000、最大70,000 | 高ROI（数千GPU節約）       | Instagram/Threadsで導入済み | MSS＋FSA＋量子化で超長期履歴を埋め込み化、複数モデルで共有可能 |

---
## 6. Conclusion

我々は、新しい「長期ユーザ履歴に特化したユーザ埋め込み」が、**高い導入実績**と**強いROI（投資対効果）の根拠**を持つことを証明した。具体的には、我々の **マルチスライシングデータモデル** と **ユーザ埋め込み要約フレームワーク** は、長期ユーザ履歴から十分な情報を捉え、最先端のモデルアーキテクチャを備えた下流プロダクションモデルにおいて顕著な改善をもたらすことができた。

この戦略によって、我々は **DV365埋め込みをInstagram内の数十の下流モデルに展開**し、大きなトップラインインパクトを与えることに成功した。




