
## Abstract

最近の研究は、レコメンダーシステムがデータポイズニング攻撃に対して脆弱であることを示しています。この種の攻撃では、敵対者がレコメンダーの学習データに注意深く作成した偽のユーザーインタラクションを注入し、ターゲットアイテムを宣伝します 。現在の攻撃手法では、攻撃を最適化するために、最新の偽ユーザーを含むポイズニングされたデータで代理レコメンダーを反復的に再学習します 。**しかし、この反復的な再学習は非常に時間がかかり、偽ユーザーの効率的な評価と最適化を妨げています 。** この計算上のボトルネックを緩和し、より少ない時間でより効果的な攻撃を開発するために、我々は再学習プロセスを分析し、1つのユーザーやアイテムの表現の変化が、ユーザーとアイテムのインタラクショングラフを通じて連鎖的な効果を引き起こすことを発見しました 。この理論的ガイダンスのもと、我々はGradient Passing（GP）という新しい手法を導入しました 。これは、バックプロパゲーション中にインタラクションしたユーザーとアイテムのペア間で勾配を明示的にパスし、連鎖的な効果を近似して再学習を加速します 。たった1回の更新で、GPは複数の元の学習イテレーションに匹敵する効果を達成できます 。同じ数の再学習エポックのもとで、GPは代理レコメンダーをターゲットにより近づける近似を可能にします 。このより正確な近似は、偽ユーザーを最適化するためのより良いガイダンスを提供し、最終的にデータポイズニング攻撃を強化します 。実世界のデータセットに対する広範な実験は、我々が提案するGPの効率と有効性を証明しています 。

## Introduction

レコメンダーシステムは、現代のオンラインプラットフォームに不可欠な要素となり、様々なドメインでユーザーエクスペリエンスとエンゲージメントを向上させるパーソナライズされたレコメンデーションを提供しています 。協調フィルタリング（CF）は、広く採用されているレコメンデーションシナリオであり、広範な研究の注目を集めています 。レコメンダーシステムの開放性と協調的な性質は、ユーザーに利便性をもたらす一方で、これらのシステムを敵対的な攻撃や操作に対して脆弱にしています 。これにより、信頼性が高く安全なシステムの必要性が強調されます 。敵対者は、レコメンダーシステムの学習データに注意深く作成した偽ユーザーを注入することで、ポイズニング攻撃を実行します 。実際には、このような操作のために偽のアカウントが登録され、レコメンデーションが操作されます 。**偽のYouTube再生回数を販売するビジネスが報告されており、敵対者の実践が広く行われている**ことを示しています 。深刻な影響を考えると、レコメンダーシステムに対するポイズニング攻撃を調査することが不可欠です 。このような研究は、堅牢な防御を開発し、レコメンダーの信頼性を向上させるための基礎を提供します 。ヒューリスティックな攻撃戦略から発展し、最近の研究は最適化ベースの攻撃に焦点を移しています 。これらの攻撃は、代理レコメンダーと敵対的損失関数を利用して、偽ユーザーを反復的に最適化します 。**代理レコメンダーは、偽ユーザーの攻撃効果を評価し、敵対的損失を最小化するように最適化をガイドできます 。** 偽ユーザーが更新されるたびに、代理レコメンダーは、最新の偽ユーザーを含むポイズニングされたデータで再学習する必要があります（図1a） 。**この反復的な代理再学習は、既存の攻撃手法で最も時間がかかる部分です**（図1b） 。これは、より効率的で効果的な攻撃のために、代理再学習を加速することを調査する動機となります 。既存の研究は、再学習時間を制限することでこの問題を緩和しています 。しかし、これらのアプローチは、ターゲットとは異なる振る舞いをする未発達な代理レコメンダーのために、全体的な攻撃効果を低下させる可能性があります 。あるいは、影響関数を活用して再学習プロセスを回避する努力もなされています 。それにもかかわらず、影響関数は、データサンプルが学習中に遭遇したことを前提として、モデル学習に対する影響を計算するために設計されています 。したがって、再学習なしで新しく作成された敵対的サンプルの影響を計算することは不正確です 。**本研究では、CFモデルの再学習プロセスを分析し、レコメンデーション損失が、インタラクションしたユーザーとアイテムのペア間の表現の類似性を必要とすることを発見しました 。** その結果、現在のイテレーションでノードの表現を更新すると、ユーザーとアイテムのインタラクショングラフを通じて、後続のイテレーションで接続されたノードの表現に影響を与える連鎖的な効果が引き起こされます 。この連鎖的なダイナミクスに触発され、我々は代理再学習を加速し、ポイズニング攻撃を強化するためにGradient Passing（GP）を提案します 。再学習中、GPは勾配を介して表現の変化を捉え、1つのイテレーション内でインタラクションしたユーザーとアイテムのペア間で明示的にそれらをパスします 。これにより、連鎖的な効果を近似し、モデルの収束を加速します 。表現力を向上させるためにフォワード中にGNNベースのレコメンダーでメッセージパッシングを行う実践とは異なり、我々は革新的にバックワードで勾配をメッセージとして活用し、より速い再学習を可能にします 。理論的分析と実験の両方が、GPを使用した1回の学習イテレーションが、複数の元のイテレーションの効果を近似でき、代理再学習を大幅に加速することを示しています 。これにより、代理レコメンダーがターゲットにより近い近似を可能にし、攻撃効果の評価における精度を高め、偽ユーザーの最適化を改善し、最終的にポイズニング攻撃を強化します 。3つの実世界のデータセットに対する実験は、GPを最先端の攻撃手法に統合することで、平均的な効果を29.57%、18.02%、177.21%向上させると同時に、時間コストを43.27%、40.54%、26.67%削減できることを検証しています 。本論文では、以下の貢献をします 。

- 我々は、直感的かつ理論的な分析に基づいて、代理レコメンダーの再学習プロセスを加速する新しい手法であるGradient Passing（GP）を導入します 。
    
- 我々は、データポイズニング攻撃を強化するためのGPの使用を提示します 。これは、最先端の攻撃手法に統合し、他の技術と組み合わせることができます 。
    
- 3つの実世界のデータセットと6つのターゲットレコメンダーに対する広範な実験は、GPの効率と有効性を検証します 。
    

## Related Work

### 2.1 Recommender System

レコメンダーシステムは、近年、オンラインアプリケーションで遍在するようになり、ユーザーにパーソナライズされた提案を提供しています 。協調フィルタリング（CF）は、最も広く採用されているレコメンデーションタスクの1つです 。その主な目的は、各ユーザーに

k個のアイテムのパーソナライズされたランキングリストを生成する、トップ-kレコメンデーションです 。初期のCF手法は、ピアソン相関などの類似性尺度に依存していましたが、その後、より洗練された潜在因子モデルが開発されました 。最近の深層学習の進歩により、オートエンコーダー 、畳み込みニューラルネットワーク 、グラフニューラルネットワーク などのニューラルCFモデルの開発につながっています 。本論文は、2つの独立したタワーがユーザーとアイテムの表現を学習し、複雑なユーザーの好みとアイテムの特性を効果的に捉える、人気のある2タワーCFモデルに焦点を当てています 。潜在表現が学習されると、ドット積のような類似性関数を使用して、ユーザーとアイテムの好みのスコアを効率的に計算できます 。

### 2.2 Attack against Recommender System

ポイズニング攻撃に関する初期の研究は、ランダム攻撃 、バンドワゴン攻撃 、その他 のようなヒューリスティックなシリング攻撃に焦点を当てていました 。これらの攻撃は、CFの基本的な仮定に依存し、ヒューリスティックなルールによって偽ユーザーを生成します 。しかし、これらはレコメンデーションモデルや敵対的損失のために特別に最適化されていないため、攻撃効果が限定的です 。最近では、最適化ベースの攻撃が、選択された代理モデルを利用して攻撃フィードバックを取得し、敵対的損失を最小化しています 。最適化ベースの攻撃は、攻撃モデルが使用されるかどうかに基づいて2つのカテゴリに分けられます 。モデルベースの攻撃は、通常、強化学習（RL） または敵対的生成ネットワーク（GAN） を利用して偽ユーザーを生成します 。一方、モデルフリーのアプローチは、一般的に敵対的勾配 、影響関数 、またはその他の事前情報 を利用して、攻撃モデルを学習せずに偽ユーザーを最適化します 。代理レコメンダーの反復的な再学習は、現在のポイズニング攻撃で最も時間がかかる部分です 。本論文では、我々が提案するGP技術をRAPU-R およびDPA2DL に統合した場合を調査します 。これには2つの理由があります 。第一に、RLやGANのような攻撃モデルの学習は不安定であり、無関係な要因に影響される可能性があります 。対照的に、RAPU-RとDPA2DLは、GPの有効性をより良く示すことができるモデルフリーの攻撃です 。第二に、これらは最先端の攻撃性能を達成するだけでなく、大規模なデータセットにもうまくスケールします 。対照的に、高次の勾配や影響関数に依存する他の攻撃は、数百万のユーザーやアイテムを扱う場合にはほとんど実行できません 。

### 2.3 Retraining of Recommender System

ポイズニング攻撃では、代理再学習の時間を制限することが一般的な選択肢です 。しかし、これは、ターゲットとは異なる振る舞いをする未発達な代理レコメンダーのために、全体的な攻撃効果を低下させる可能性があります 。あるいは、影響関数を活用して反復的な代理再学習を回避する努力もなされています 。それでも、影響関数は、データサンプルが学習中に遭遇したことを前提として、モデル学習に対する影響を計算するために設計されています 。したがって、再学習なしで新しく作成された敵対的サンプルの影響を計算することは不正確です 。再学習の効率は、レコメンダーシステムのためのインクリメンタル学習の分野でも懸念事項です 。この分野では、新しいフィードバックが継続的に到着するシナリオが研究されています 。中核的な課題は、以前に学習されたレコメンダーを効率的に更新し、最新のデータで高い性能を維持することにあります 。インクリメンタル学習手法は、サンプルベースとモデルベースの2つの主要なタイプに分類できます 。サンプルベースの手法は、代表的な学習サンプルセットを維持し、大規模なデータセット全体で再学習する必要性を回避し、結果として再学習時間を短縮します 。モデルベースのアプローチは、メタ学習モデルを使用して、再学習なしでレコメンデーションモデルのパラメータを直接更新します 。インクリメンタル学習技術からインスピレーションを得ることで、より効率的で効果的なポイズニング攻撃を開発する可能性があります 。